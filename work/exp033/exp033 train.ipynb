{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20825,"status":"ok","timestamp":1693199303721,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"MM4dTYOWdrrK","outputId":"8f5b0f74-e6d1-4adf-d643-df52b6c82061"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"],"metadata":{"id":"CD_RBZ2zbgMk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693199326097,"user_tz":-540,"elapsed":22379,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"23544701-52dc-414b-d6f7-d0898adb42fc"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m63.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m121.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m82.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0\n","Collecting datasets\n","  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.4 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"JK8PEmITblft","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693199326719,"user_tz":-540,"elapsed":626,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"3591fda4-9e49-4592-e557-43a320b0bdac"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Aug 28 05:08:46 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    43W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gqVuaXRJeCOe","executionInfo":{"status":"ok","timestamp":1693199334029,"user_tz":-540,"elapsed":7312,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score, recall_score, accuracy_score, precision_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jm5aYY3Qd6kO","executionInfo":{"status":"ok","timestamp":1693199335061,"user_tz":-540,"elapsed":1035,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["import os\n","\n","DIR = \"/content/drive/MyDrive/Competitions/Signate/MUFG2023\"\n","INPUT_DIR = os.path.join(DIR,\"input\")\n","OUTPUT_DIR = os.path.join(DIR,\"output\")\n","\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n","\n","\n","OUTPUT_EXP_DIR = DIR + '/output/EXP033/'\n","if not os.path.exists(OUTPUT_EXP_DIR):\n","    os.makedirs(OUTPUT_EXP_DIR)"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1693199335061,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"cang6GVBAu94"},"outputs":[],"source":["\n","\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-base\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    # model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=64\n","    fc_dropout=0.2\n","    target=\"is_fraud?\"\n","    target_size=1\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = False\n","    freezing = False\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]"]},{"cell_type":"code","source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    f_score = f1_score(y_true, (y_pred>thresh).astype(int))\n","    r_score = recall_score(y_true, (y_pred>thresh).astype(int))\n","    p_score = precision_score(y_true, (y_pred>thresh).astype(int))\n","    print(f\"f1 score : {f_score}\")\n","    print(f\"recall score : {r_score}\")\n","    print(f\"precision score : {p_score}\")\n","    return f1_score(y_true, (y_pred>thresh).astype(int))\n","\n","def get_f1_score(labels, outputs):\n","    y_pred = outputs\n","    y_true = labels\n","    best_score = 0\n","    best_thresh = 0.5\n","    for thresh in np.arange(0.1, 0.80, 0.01):\n","        thresh = np.round(thresh, 2)\n","        score = f1_score(y_true, (y_pred>thresh).astype(int))\n","        #print(\"Accuracy score at threshold {0} is {1}\".format(thresh, score))\n","        if score > best_score:\n","          best_score = score\n","          best_thresh = thresh\n","    return f1_score(y_true, (y_pred>best_thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_EXP_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"lOI-vnq5cDJP","executionInfo":{"status":"ok","timestamp":1693199335658,"user_tz":-540,"elapsed":600,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","\n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","\n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","\n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","\n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","\n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","\n","        if hasattr(embeddings_path, attr_name):\n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"3vZWA_5rcVEo","executionInfo":{"status":"ok","timestamp":1693199335658,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":950},"executionInfo":{"elapsed":4630,"status":"ok","timestamp":1693199340285,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"alfdMdcXeaGI","outputId":"c18cb1c4-746f-4250-99f7-bc69ce35be6a"},"outputs":[{"output_type":"stream","name":"stdout","text":["(471283, 12)\n"]},{"output_type":"display_data","data":{"text/plain":["   index  user_id  card_id  amount errors?  is_fraud?  merchant_id  \\\n","0      0     1721        0  $2.623      OK          0       209237   \n","1      1     1629        3    $6.4      OK          0         2568   \n","2      2      655        3  $123.5      OK          0       345310   \n","\n","  merchant_city merchant_state      zip   mcc           use_chip  \n","0        Joliet             IL  60436.0  5541  Swipe Transaction  \n","1      Edgerton             WI  53534.0  5814  Swipe Transaction  \n","2    Ridgefield             WA  98642.0  7538  Swipe Transaction  "],"text/html":["\n","  <div id=\"df-f963a02b-1de2-40d9-a504-a3c8894c6097\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>user_id</th>\n","      <th>card_id</th>\n","      <th>amount</th>\n","      <th>errors?</th>\n","      <th>is_fraud?</th>\n","      <th>merchant_id</th>\n","      <th>merchant_city</th>\n","      <th>merchant_state</th>\n","      <th>zip</th>\n","      <th>mcc</th>\n","      <th>use_chip</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1721</td>\n","      <td>0</td>\n","      <td>$2.623</td>\n","      <td>OK</td>\n","      <td>0</td>\n","      <td>209237</td>\n","      <td>Joliet</td>\n","      <td>IL</td>\n","      <td>60436.0</td>\n","      <td>5541</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1629</td>\n","      <td>3</td>\n","      <td>$6.4</td>\n","      <td>OK</td>\n","      <td>0</td>\n","      <td>2568</td>\n","      <td>Edgerton</td>\n","      <td>WI</td>\n","      <td>53534.0</td>\n","      <td>5814</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>655</td>\n","      <td>3</td>\n","      <td>$123.5</td>\n","      <td>OK</td>\n","      <td>0</td>\n","      <td>345310</td>\n","      <td>Ridgefield</td>\n","      <td>WA</td>\n","      <td>98642.0</td>\n","      <td>7538</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f963a02b-1de2-40d9-a504-a3c8894c6097')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-f963a02b-1de2-40d9-a504-a3c8894c6097 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-f963a02b-1de2-40d9-a504-a3c8894c6097');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(457958, 11)\n"]},{"output_type":"display_data","data":{"text/plain":["    index  user_id  card_id    amount errors?  merchant_id      merchant_city  \\\n","0  471283      541        3  $113.278      OK       324189            Orlando   \n","1  471284      655        1  $293.944      OK        81219         Ridgefield   \n","2  471285      492        0     $47.4      OK       274755  Arlington Heights   \n","\n","  merchant_state      zip   mcc           use_chip  \n","0             FL  32821.0  4814  Swipe Transaction  \n","1             WA  98642.0  7538   Chip Transaction  \n","2             IL  60004.0  5719  Swipe Transaction  "],"text/html":["\n","  <div id=\"df-597c9cd3-1c3b-491a-ad43-ef11d6ee5070\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>user_id</th>\n","      <th>card_id</th>\n","      <th>amount</th>\n","      <th>errors?</th>\n","      <th>merchant_id</th>\n","      <th>merchant_city</th>\n","      <th>merchant_state</th>\n","      <th>zip</th>\n","      <th>mcc</th>\n","      <th>use_chip</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>471283</td>\n","      <td>541</td>\n","      <td>3</td>\n","      <td>$113.278</td>\n","      <td>OK</td>\n","      <td>324189</td>\n","      <td>Orlando</td>\n","      <td>FL</td>\n","      <td>32821.0</td>\n","      <td>4814</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>471284</td>\n","      <td>655</td>\n","      <td>1</td>\n","      <td>$293.944</td>\n","      <td>OK</td>\n","      <td>81219</td>\n","      <td>Ridgefield</td>\n","      <td>WA</td>\n","      <td>98642.0</td>\n","      <td>7538</td>\n","      <td>Chip Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>471285</td>\n","      <td>492</td>\n","      <td>0</td>\n","      <td>$47.4</td>\n","      <td>OK</td>\n","      <td>274755</td>\n","      <td>Arlington Heights</td>\n","      <td>IL</td>\n","      <td>60004.0</td>\n","      <td>5719</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-597c9cd3-1c3b-491a-ad43-ef11d6ee5070')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-597c9cd3-1c3b-491a-ad43-ef11d6ee5070 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-597c9cd3-1c3b-491a-ad43-ef11d6ee5070');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(416, 10)\n"]},{"output_type":"display_data","data":{"text/plain":["   user_id  card_id card_brand card_type  expires has_chip  cards_issued  \\\n","0       39        0       Visa     Debit  09/2021      YES             1   \n","1       39        1       Amex    Credit  11/2024      YES             2   \n","2       41        0   Discover    Credit  03/2022      YES             2   \n","\n","  credit_limit acct_open_date  year_pin_last_changed  \n","0       $17117        05/2007                   2010  \n","1        $5400        10/2015                   2015  \n","2       $14800        12/2010                   2011  "],"text/html":["\n","  <div id=\"df-3565c991-af3d-4e67-afc6-44b046860bf1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>card_id</th>\n","      <th>card_brand</th>\n","      <th>card_type</th>\n","      <th>expires</th>\n","      <th>has_chip</th>\n","      <th>cards_issued</th>\n","      <th>credit_limit</th>\n","      <th>acct_open_date</th>\n","      <th>year_pin_last_changed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>Visa</td>\n","      <td>Debit</td>\n","      <td>09/2021</td>\n","      <td>YES</td>\n","      <td>1</td>\n","      <td>$17117</td>\n","      <td>05/2007</td>\n","      <td>2010</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>Amex</td>\n","      <td>Credit</td>\n","      <td>11/2024</td>\n","      <td>YES</td>\n","      <td>2</td>\n","      <td>$5400</td>\n","      <td>10/2015</td>\n","      <td>2015</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>Discover</td>\n","      <td>Credit</td>\n","      <td>03/2022</td>\n","      <td>YES</td>\n","      <td>2</td>\n","      <td>$14800</td>\n","      <td>12/2010</td>\n","      <td>2011</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3565c991-af3d-4e67-afc6-44b046860bf1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3565c991-af3d-4e67-afc6-44b046860bf1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3565c991-af3d-4e67-afc6-44b046860bf1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(97, 17)\n"]},{"output_type":"display_data","data":{"text/plain":["   user_id  current_age  retirement_age  birth_year  birth_month  gender  \\\n","0       39           57              64        1962           12  Female   \n","1       41           39              66        1980           10  Female   \n","2       47           40              67        1979            5  Female   \n","\n","               address       city state  zipcode  latitude  longitude  \\\n","0  442 Burns Boulevard  Mansfield    MA     2048     42.02     -71.21   \n","1    3863 River Avenue    Lincoln    CA    95648     38.93    -121.25   \n","2      8799 Elm Avenue   Mckinney    TX    75069     33.20     -96.65   \n","\n","  per_capita_income_zipcode yearly_income_person total_debt  fico_score  \\\n","0                    $37407               $76274    $102611         698   \n","1                    $21829               $44506     $57994         849   \n","2                    $24684               $50329     $76759         625   \n","\n","   num_credit_cards  \n","0                 2  \n","1                 3  \n","2                 4  "],"text/html":["\n","  <div id=\"df-695d248d-a6d9-460f-9ad0-6dcb36ada7e3\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>current_age</th>\n","      <th>retirement_age</th>\n","      <th>birth_year</th>\n","      <th>birth_month</th>\n","      <th>gender</th>\n","      <th>address</th>\n","      <th>city</th>\n","      <th>state</th>\n","      <th>zipcode</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>per_capita_income_zipcode</th>\n","      <th>yearly_income_person</th>\n","      <th>total_debt</th>\n","      <th>fico_score</th>\n","      <th>num_credit_cards</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>57</td>\n","      <td>64</td>\n","      <td>1962</td>\n","      <td>12</td>\n","      <td>Female</td>\n","      <td>442 Burns Boulevard</td>\n","      <td>Mansfield</td>\n","      <td>MA</td>\n","      <td>2048</td>\n","      <td>42.02</td>\n","      <td>-71.21</td>\n","      <td>$37407</td>\n","      <td>$76274</td>\n","      <td>$102611</td>\n","      <td>698</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>41</td>\n","      <td>39</td>\n","      <td>66</td>\n","      <td>1980</td>\n","      <td>10</td>\n","      <td>Female</td>\n","      <td>3863 River Avenue</td>\n","      <td>Lincoln</td>\n","      <td>CA</td>\n","      <td>95648</td>\n","      <td>38.93</td>\n","      <td>-121.25</td>\n","      <td>$21829</td>\n","      <td>$44506</td>\n","      <td>$57994</td>\n","      <td>849</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>47</td>\n","      <td>40</td>\n","      <td>67</td>\n","      <td>1979</td>\n","      <td>5</td>\n","      <td>Female</td>\n","      <td>8799 Elm Avenue</td>\n","      <td>Mckinney</td>\n","      <td>TX</td>\n","      <td>75069</td>\n","      <td>33.20</td>\n","      <td>-96.65</td>\n","      <td>$24684</td>\n","      <td>$50329</td>\n","      <td>$76759</td>\n","      <td>625</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-695d248d-a6d9-460f-9ad0-6dcb36ada7e3')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-695d248d-a6d9-460f-9ad0-6dcb36ada7e3 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-695d248d-a6d9-460f-9ad0-6dcb36ada7e3');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(457958, 2)\n"]},{"output_type":"display_data","data":{"text/plain":["        0  1\n","0  471283  0\n","1  471284  1\n","2  471285  0"],"text/html":["\n","  <div id=\"df-5c967087-f5df-4a76-aeb0-a104a6c60ed5\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>471283</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>471284</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>471285</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5c967087-f5df-4a76-aeb0-a104a6c60ed5')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-5c967087-f5df-4a76-aeb0-a104a6c60ed5 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-5c967087-f5df-4a76-aeb0-a104a6c60ed5');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}}],"source":["import pandas as pd\n","import numpy as np\n","\n","\n","train = pd.read_csv(os.path.join(INPUT_DIR,\"train.csv\"))\n","test = pd.read_csv(os.path.join(INPUT_DIR,\"test.csv\"))\n","card = pd.read_csv(os.path.join(INPUT_DIR, \"card.csv\"))\n","user = pd.read_csv(os.path.join(INPUT_DIR, \"user.csv\"))\n","sub = pd.read_csv(os.path.join(INPUT_DIR, \"sample_submit.csv\"), header=None)\n","\n","print(train.shape)\n","display(train.head(3))\n","\n","print(test.shape)\n","display(test.head(3))\n","\n","print(card.shape)\n","display(card.head(3))\n","\n","print(user.shape)\n","display(user.head(3))\n","\n","print(sub.shape)\n","display(sub.head(3))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"i83_oAMoA1LW","executionInfo":{"status":"ok","timestamp":1693199340732,"user_tz":-540,"elapsed":450,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["train = train.merge(card, how=\"left\", on=[\"user_id\", \"card_id\"]).merge(user, how=\"left\", on=\"user_id\")"]},{"cell_type":"code","source":["month_dict = {\n","   \"01\": \"January\",\n","   \"02\": \"February\",\n","   \"03\": \"March\",\n","   \"04\": \"April\",\n","   \"05\": \"May\",\n","   \"06\": \"June\",\n","   \"07\": \"July\",\n","   \"08\": \"August\",\n","   \"09\": \"September\",\n","   \"10\": \"October\",\n","   \"11\": \"November\",\n","   \"12\": \"December\"\n","}\n","\n","def get_expires_values(df):\n","  _df = df[\"expires\"].str.split('/').apply(pd.Series)\n","  _df.columns = [\"month\",\"years\"]\n","  df[\"expires_month\"] = _df[\"month\"].astype(str)\n","  df[\"expires_years\"] = _df[\"years\"].astype(str)\n","  return df\n","\n","def get_acct_open_date_values(df):\n","  _df = df[\"acct_open_date\"].str.split('/').apply(pd.Series)\n","  _df.columns = [\"month\",\"years\"]\n","  df[\"acct_open_date_month\"] = _df[\"month\"].astype(str)\n","  df[\"acct_open_date_years\"] = _df[\"years\"].astype(str)\n","  return df\n","\n","train = get_expires_values(train)\n","train = get_acct_open_date_values(train)\n","train[\"expires_month\"] = train[\"expires_month\"].map(month_dict)\n","train[\"acct_open_date_month\"] = train[\"acct_open_date_month\"].map(month_dict)"],"metadata":{"id":"fA0Gj3oTfYow","executionInfo":{"status":"ok","timestamp":1693199446777,"user_tz":-540,"elapsed":106048,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train.fillna('unknown', inplace = True)\n","\n","train[\"texts\"] = \"[MERCHANT]\" + train[\"amount\"] + \"[SEP]\" + train[\"errors?\"] + \"[SEP]\" + train[\"merchant_city\"] + \"[SEP]\" + train[\"merchant_state\"] + \"[SEP]\" + train[\"use_chip\"] + \"[SEP]\" \\\n","+ \"[CARD]\"  + train[\"card_brand\"] + \"[SEP]\" + train[\"card_type\"] + \"[SEP]\" + train[\"expires_month\"] + \" \" + train[\"expires_years\"] + \"[SEP]\" + train[\"has_chip\"] + \"[SEP]\" + train[\"acct_open_date_month\"] + \" \" + train[\"acct_open_date_years\"] + \"[SEP]\" + train[\"year_pin_last_changed\"].astype(str) + \"[SEP]\" \\\n","\"[USER]\" + train[\"current_age\"].astype(str) + \" year old \" + train[\"gender\"] + \"[SEP]\" + \"retired at age \" + train[\"retirement_age\"].astype(str) + \"[SEP]\" + train[\"address\"] + \"[SEP]\" + train[\"city\"] + \"[SEP]\" + train[\"state\"] + \"[SEP]\" + train[\"per_capita_income_zipcode\"] + \"[SEP]\" + train[\"yearly_income_person\"] + \"[SEP]\" + train[\"total_debt\"]"],"metadata":{"id":"ZYevLBPI7-FT","executionInfo":{"status":"ok","timestamp":1693199451429,"user_tz":-540,"elapsed":4655,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train[CFG.target])):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","\n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=500, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"],"metadata":{"id":"ZSX1VrbRlwwt","executionInfo":{"status":"ok","timestamp":1693199451429,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","special_tokens_dict = {'additional_special_tokens': [\"[MERCHANT]\"] + [\"[CARD]\"] + [\"[USER]\"]}\n","tokenizer.add_special_tokens(special_tokens_dict)\n","tokenizer.save_pretrained(OUTPUT_EXP_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["9acb63c8c9a64667857802260d2114d2","b9e6dc791de8475fa36b1f95a57a26a2","e3d9f19d00c0428d9d699006863d0eac","ed025355237f4aebb1d74beb9778e57c","e8eb34aaeaf34493a04b7f55d119f007","7a02177be6b84f689b0dbca0ee32c626","9cf1552ed41f4ed98046cf78871c6e51","d03d6c1eae944463b4563cae1a46af07","cba7124a8bce45a48bada108b4eec8ca","7afddeb8cc8c4cdba2f0ba1bd475a9d6","f8d484da0d4e4e2fbaa5a6256c0bee5c","ad877098f5614e58959a2c7160c39707","097fd25dd6fc45768cbf96f4c212bc2f","4d30c56233504397b94fb548e9de58b6","4c299d144a284b89b11feb9708df7b7f","25a6dc0b9be342ebb3e9966352b248d6","6aef6285f0ee40948757ebbe0bfe9ce2","e4fd48e1eb6c4ca8af77d2709b5e031d","e0a48121d36748f29409c4661c509e44","a373b6f113284beba120dbdd5c82daf9","1476027af64543de9ede9c9274a140de","5e3c073892a345c9b5ed0bd8e23683b4","f6c335937fc249ad8c6765e1eba617bb","e30befba94014e64826404db0b6fe29b","3f419e4f950940d8b273406eb7ca6988","7f7039a00c9e44d49d3aa4889b7fd5f9","105b594db3b942238f41b909b66efee0","e93ceb0b0394420d848b4be3e4b6078d","38b3e82646914a58bfdd3c2079094a3b","f4e21345216342acaca1d2d6a9379386","55acf4daf0bc4eb299f8aa4765743f1e","1aa4959267cc4f9c9af50b752002fdd3","3718227fe84a4987a924b0eb9c683b03"]},"id":"J8ohdOJCmB4m","executionInfo":{"status":"ok","timestamp":1693199458087,"user_tz":-540,"elapsed":6660,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"4a53a008-c66c-4733-81a5-ae470e6b6413"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9acb63c8c9a64667857802260d2114d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad877098f5614e58959a2c7160c39707"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6c335937fc249ad8c6765e1eba617bb"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['texts'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 23 # cls\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZyGX8bXmFgI","executionInfo":{"status":"ok","timestamp":1693199547545,"user_tz":-540,"elapsed":89462,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"9d7ac2c7-5e43-435c-db1d-8397da57e4a0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 471283/471283 [01:28<00:00, 5311.63it/s]\n","max_len: 94\n","INFO:__main__:max_len: 94\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","# def prepare_input(cfg, text):\n","#     inputs = cfg.tokenizer(text,\n","#                            add_special_tokens=True,\n","#                            max_length=cfg.max_len,\n","#                            padding=\"max_length\",\n","#                            return_offsets_mapping=False,\n","#                            truncation=True)\n","#     for k, v in inputs.items():\n","#         inputs[k] = torch.tensor(v, dtype=torch.long)\n","#     return inputs\n","\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer.encode_plus(\n","        text,\n","        return_tensors=None,\n","        add_special_tokens=True,\n","        max_length=CFG.max_len,\n","        pad_to_max_length=True,\n","        truncation=True\n","    )\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df[CFG.target].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.half)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","class ValidDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df[CFG.target].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"HOhlEza3o2pR","executionInfo":{"status":"ok","timestamp":1693199547545,"user_tz":-540,"elapsed":8,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        self.sig = nn.Sigmoid()\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        feature = self.layer_norm1(feature)\n","        output = self.fc(feature)\n","        #output = self.sig(output)\n","        return output"],"metadata":{"id":"bhk-PK8Mo-ia","executionInfo":{"status":"ok","timestamp":1693199547545,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        #print(y_preds.sigmoid().squeeze().view(1, -1))\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        scaler.unscale_(optimizer)\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader),\n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"vA_8DWfOpFRu","executionInfo":{"status":"ok","timestamp":1693199547546,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target].values\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = ValidDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_EXP_DIR+'config.pth')\n","    model.to(device)\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr,\n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss()\n","\n","    best_score = -1.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","\n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","        f1_score = get_f1_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","\n","        if best_score < f1_score:\n","            best_score = f1_score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds"],"metadata":{"id":"Au28-HoKpISb","executionInfo":{"status":"ok","timestamp":1693199547546,"user_tz":-540,"elapsed":4,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","\n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        f1_score = get_f1_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","        LOGGER.info(f'F1 BEST Score: {f1_score:<.4f}')\n","\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","            #break\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_EXP_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["48fd7fdcf7084bb3ab4336f4c78379ad","7ad00761c8944735bfe8004b952454ed","7af9b7340b59495aa231e3c16b856718","34ef042217764fff9decdd7891f14b9c","2322cc117b8f481f9f916041ff58169d","38e12e0c881e4472b7302e7a25bf6eb0","50c1589c193c42b9915c132d08f46ea4","69fce6982c124bed86de400ad1cfc302","3a505d8eb34f46acac5ab0f18a553b01","39e0145a8e5745f296ff6d2edc4317bb","061f5e1c20cc4fe7bd08f331a87de7fd"]},"id":"cDCGpigkpcaI","outputId":"71b4340d-0719-487e-e835-b31ad3f14e83","executionInfo":{"status":"ok","timestamp":1693212071494,"user_tz":-540,"elapsed":12523952,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"48fd7fdcf7084bb3ab4336f4c78379ad"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 3s (remain 373m 44s) Loss: 0.8848(0.8848) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 12s (remain 12m 3s) Loss: 0.2393(0.2644) Grad: 0.8625  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 21s (remain 10m 6s) Loss: 0.2352(0.2489) Grad: 0.7933  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 30s (remain 9m 22s) Loss: 0.2239(0.2399) Grad: 1.1491  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 0m 39s (remain 8m 55s) Loss: 0.1743(0.2362) Grad: 0.9238  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 0m 47s (remain 8m 35s) Loss: 0.2489(0.2325) Grad: 1.0065  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 0m 56s (remain 8m 18s) Loss: 0.1338(0.2310) Grad: 0.8067  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 5s (remain 8m 4s) Loss: 0.2568(0.2297) Grad: 1.0734  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 1m 14s (remain 7m 51s) Loss: 0.2959(0.2297) Grad: 0.7678  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 1m 22s (remain 7m 39s) Loss: 0.2646(0.2269) Grad: 1.0519  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 1m 31s (remain 7m 27s) Loss: 0.2805(0.2243) Grad: 1.3990  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 1m 40s (remain 7m 16s) Loss: 0.1913(0.2230) Grad: 0.5067  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 1m 49s (remain 7m 6s) Loss: 0.1445(0.2221) Grad: 0.4404  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 1m 57s (remain 6m 56s) Loss: 0.0562(0.2206) Grad: 0.8608  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 2m 6s (remain 6m 46s) Loss: 0.2242(0.2192) Grad: 0.4958  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 2m 15s (remain 6m 37s) Loss: 0.2450(0.2188) Grad: 0.7650  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 2m 24s (remain 6m 28s) Loss: 0.4963(0.2173) Grad: 2.2854  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 2m 33s (remain 6m 18s) Loss: 0.1858(0.2157) Grad: 0.5133  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 2m 42s (remain 6m 8s) Loss: 0.1323(0.2152) Grad: 1.1051  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 2m 51s (remain 5m 59s) Loss: 0.1644(0.2144) Grad: 0.4858  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 2m 59s (remain 5m 49s) Loss: 0.0964(0.2135) Grad: 0.7358  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 3m 8s (remain 5m 40s) Loss: 0.1311(0.2129) Grad: 0.5612  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 3m 17s (remain 5m 31s) Loss: 0.1700(0.2119) Grad: 0.5044  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 3m 26s (remain 5m 21s) Loss: 0.2465(0.2113) Grad: 1.0061  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 3m 35s (remain 5m 12s) Loss: 0.1226(0.2100) Grad: 0.5421  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 3m 43s (remain 5m 3s) Loss: 0.3535(0.2094) Grad: 1.8031  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 3m 52s (remain 4m 54s) Loss: 0.2527(0.2088) Grad: 0.9478  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 4m 1s (remain 4m 45s) Loss: 0.2491(0.2076) Grad: 1.6060  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 4m 10s (remain 4m 36s) Loss: 0.1829(0.2069) Grad: 0.4832  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 4m 19s (remain 4m 27s) Loss: 0.0929(0.2063) Grad: 0.8527  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 4m 28s (remain 4m 18s) Loss: 0.1079(0.2054) Grad: 1.2103  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 4m 36s (remain 4m 9s) Loss: 0.0874(0.2048) Grad: 0.6771  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 4m 45s (remain 4m 0s) Loss: 0.1104(0.2045) Grad: 1.5249  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 4m 54s (remain 3m 51s) Loss: 0.0731(0.2040) Grad: 0.4288  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 5m 3s (remain 3m 42s) Loss: 0.1598(0.2033) Grad: 1.0684  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 5m 12s (remain 3m 33s) Loss: 0.1866(0.2027) Grad: 0.7538  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 5m 20s (remain 3m 24s) Loss: 0.2260(0.2021) Grad: 0.6148  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 5m 29s (remain 3m 15s) Loss: 0.3022(0.2016) Grad: 2.0384  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 5m 38s (remain 3m 6s) Loss: 0.2173(0.2013) Grad: 0.8579  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 5m 47s (remain 2m 57s) Loss: 0.1309(0.2005) Grad: 0.5000  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 5m 56s (remain 2m 48s) Loss: 0.1862(0.2001) Grad: 0.6065  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 6m 4s (remain 2m 39s) Loss: 0.2871(0.1999) Grad: 0.9260  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 6m 13s (remain 2m 30s) Loss: 0.1254(0.1992) Grad: 0.6857  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 6m 22s (remain 2m 21s) Loss: 0.1730(0.1987) Grad: 0.8371  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 6m 31s (remain 2m 12s) Loss: 0.1487(0.1982) Grad: 1.0558  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 6m 39s (remain 2m 3s) Loss: 0.2465(0.1980) Grad: 0.7972  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 6m 48s (remain 1m 54s) Loss: 0.1814(0.1976) Grad: 1.1738  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 6m 57s (remain 1m 45s) Loss: 0.0972(0.1969) Grad: 0.8052  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 7m 6s (remain 1m 36s) Loss: 0.1493(0.1966) Grad: 0.7673  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 7m 14s (remain 1m 27s) Loss: 0.1389(0.1960) Grad: 0.3979  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 7m 23s (remain 1m 18s) Loss: 0.2874(0.1957) Grad: 1.5400  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 7m 32s (remain 1m 10s) Loss: 0.2805(0.1953) Grad: 1.0557  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 7m 41s (remain 1m 1s) Loss: 0.1147(0.1952) Grad: 0.6811  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 7m 50s (remain 0m 52s) Loss: 0.0916(0.1947) Grad: 0.5738  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 7m 58s (remain 0m 43s) Loss: 0.3472(0.1947) Grad: 1.8167  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 8m 7s (remain 0m 34s) Loss: 0.1628(0.1943) Grad: 0.7384  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 8m 16s (remain 0m 25s) Loss: 0.0911(0.1942) Grad: 0.7580  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 8m 25s (remain 0m 16s) Loss: 0.2028(0.1940) Grad: 0.5801  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 8m 33s (remain 0m 7s) Loss: 0.1417(0.1936) Grad: 1.5840  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 8m 41s (remain 0m 0s) Loss: 0.2773(0.1932) Grad: 1.8251  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 29s) Loss: 0.1559(0.1559) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.2601(0.1419) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.2551(0.1662) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.1815(0.1774) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.2399(0.1805) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.2057(0.1832) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1877(0.1828) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1069(0.1786) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0365(0.1767) \n","f1 score : 0.3457054484891744\n","recall score : 0.22264787005822861\n","precision score : 0.7728723404255319\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.1932  avg_val_loss: 0.1767  time: 621s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.1932  avg_val_loss: 0.1767  time: 621s\n","Epoch 1 - Score: 0.3457\n","INFO:__main__:Epoch 1 - Score: 0.3457\n","Epoch 1 - Save Best Score: 0.4912 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4912 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 34m 32s) Loss: 0.2262(0.2262) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 9s (remain 8m 48s) Loss: 0.0773(0.1576) Grad: 1.3671  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 18s (remain 8m 34s) Loss: 0.1340(0.1688) Grad: 0.9092  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 26s (remain 8m 20s) Loss: 0.1851(0.1671) Grad: 1.1504  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 0m 35s (remain 8m 8s) Loss: 0.0538(0.1667) Grad: 1.0122  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 0m 44s (remain 7m 58s) Loss: 0.1209(0.1687) Grad: 0.4834  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 0m 53s (remain 7m 48s) Loss: 0.2646(0.1671) Grad: 1.0370  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 1s (remain 7m 38s) Loss: 0.1476(0.1677) Grad: 0.5801  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 1m 10s (remain 7m 29s) Loss: 0.2115(0.1672) Grad: 1.2820  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 1m 19s (remain 7m 20s) Loss: 0.2406(0.1673) Grad: 1.1608  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.1663(0.1677) Grad: 0.4820  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 1m 37s (remain 7m 2s) Loss: 0.1858(0.1662) Grad: 0.8958  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 1m 45s (remain 6m 53s) Loss: 0.1798(0.1673) Grad: 1.0899  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 1m 54s (remain 6m 45s) Loss: 0.2402(0.1672) Grad: 1.1006  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.0970(0.1670) Grad: 1.2268  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0654(0.1671) Grad: 1.4763  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.2158(0.1675) Grad: 1.0777  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 2m 29s (remain 6m 9s) Loss: 0.0422(0.1677) Grad: 0.5896  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.2876(0.1680) Grad: 1.1391  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 2m 47s (remain 5m 51s) Loss: 0.1021(0.1676) Grad: 0.6239  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 2m 56s (remain 5m 43s) Loss: 0.1015(0.1675) Grad: 0.9289  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 3m 5s (remain 5m 34s) Loss: 0.1896(0.1680) Grad: 0.7813  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 3m 14s (remain 5m 25s) Loss: 0.3081(0.1682) Grad: 0.9212  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.2114(0.1686) Grad: 1.4011  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.2720(0.1684) Grad: 1.5150  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.0996(0.1683) Grad: 0.7307  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.1204(0.1678) Grad: 0.6657  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.1462(0.1679) Grad: 0.5332  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 4m 6s (remain 4m 32s) Loss: 0.1697(0.1679) Grad: 0.4600  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.1324(0.1678) Grad: 0.5128  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.1564(0.1678) Grad: 0.5198  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 4m 33s (remain 4m 5s) Loss: 0.1516(0.1674) Grad: 0.7903  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.3298(0.1674) Grad: 1.6284  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 4m 50s (remain 3m 48s) Loss: 0.1256(0.1672) Grad: 0.6701  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.1114(0.1671) Grad: 1.0245  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.2242(0.1670) Grad: 0.8003  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 5m 17s (remain 3m 21s) Loss: 0.1627(0.1668) Grad: 0.6039  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 5m 25s (remain 3m 12s) Loss: 0.1545(0.1668) Grad: 1.5636  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 5m 34s (remain 3m 4s) Loss: 0.1744(0.1667) Grad: 0.6198  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.2285(0.1666) Grad: 1.5079  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.0736(0.1660) Grad: 0.6208  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 6m 1s (remain 2m 37s) Loss: 0.1664(0.1658) Grad: 0.7837  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 6m 9s (remain 2m 28s) Loss: 0.2211(0.1657) Grad: 1.3878  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 6m 18s (remain 2m 19s) Loss: 0.1573(0.1655) Grad: 0.7303  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 6m 27s (remain 2m 11s) Loss: 0.1699(0.1653) Grad: 0.7339  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.1376(0.1652) Grad: 0.5772  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 6m 45s (remain 1m 53s) Loss: 0.1283(0.1652) Grad: 0.7750  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.1501(0.1650) Grad: 0.6529  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 7m 2s (remain 1m 35s) Loss: 0.0942(0.1647) Grad: 0.5368  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.0967(0.1647) Grad: 0.6177  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.1967(0.1647) Grad: 0.9927  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 7m 28s (remain 1m 9s) Loss: 0.2404(0.1646) Grad: 0.9916  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.2467(0.1646) Grad: 1.1613  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 7m 46s (remain 0m 51s) Loss: 0.0970(0.1643) Grad: 0.7765  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 7m 55s (remain 0m 43s) Loss: 0.2234(0.1643) Grad: 1.4606  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 8m 3s (remain 0m 34s) Loss: 0.0936(0.1642) Grad: 0.3821  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 8m 12s (remain 0m 25s) Loss: 0.1284(0.1642) Grad: 0.7028  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 8m 21s (remain 0m 16s) Loss: 0.0983(0.1641) Grad: 0.6098  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 8m 30s (remain 0m 7s) Loss: 0.1207(0.1640) Grad: 0.8456  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 8m 38s (remain 0m 0s) Loss: 0.2744(0.1641) Grad: 1.4484  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 44s) Loss: 0.1766(0.1766) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.2318(0.1300) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.2090(0.1486) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.1690(0.1578) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.2132(0.1623) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1671(0.1653) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1878(0.1648) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.0917(0.1612) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0292(0.1593) \n","f1 score : 0.4641645462256149\n","recall score : 0.33542752068648485\n","precision score : 0.7532690984170681\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.1641  avg_val_loss: 0.1593  time: 617s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1641  avg_val_loss: 0.1593  time: 617s\n","Epoch 2 - Score: 0.4642\n","INFO:__main__:Epoch 2 - Score: 0.4642\n","Epoch 2 - Save Best Score: 0.5380 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5380 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 36m 39s) Loss: 0.2107(0.2107) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 9s (remain 8m 48s) Loss: 0.1272(0.1436) Grad: 0.7240  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 18s (remain 8m 38s) Loss: 0.1620(0.1477) Grad: 0.7011  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 27s (remain 8m 22s) Loss: 0.2480(0.1499) Grad: 1.2341  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 0m 35s (remain 8m 11s) Loss: 0.1383(0.1544) Grad: 0.7264  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 0m 44s (remain 8m 1s) Loss: 0.0699(0.1545) Grad: 0.7444  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 0m 53s (remain 7m 50s) Loss: 0.1860(0.1532) Grad: 1.0439  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 2s (remain 7m 41s) Loss: 0.2294(0.1543) Grad: 1.1175  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 1m 11s (remain 7m 31s) Loss: 0.1454(0.1538) Grad: 0.5740  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 1m 19s (remain 7m 21s) Loss: 0.2318(0.1534) Grad: 0.8001  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.1462(0.1542) Grad: 0.4662  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 1m 37s (remain 7m 3s) Loss: 0.1205(0.1537) Grad: 0.8634  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.1021(0.1536) Grad: 0.8357  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 1m 54s (remain 6m 45s) Loss: 0.1000(0.1537) Grad: 0.9307  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.1060(0.1531) Grad: 0.6829  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0773(0.1531) Grad: 0.5746  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.1229(0.1535) Grad: 0.4964  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 2m 29s (remain 6m 9s) Loss: 0.1661(0.1533) Grad: 0.7838  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.0711(0.1540) Grad: 1.0055  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 2m 47s (remain 5m 52s) Loss: 0.0721(0.1538) Grad: 0.7299  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 2m 56s (remain 5m 43s) Loss: 0.1720(0.1541) Grad: 0.7866  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 3m 5s (remain 5m 34s) Loss: 0.1681(0.1544) Grad: 0.4849  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 3m 14s (remain 5m 25s) Loss: 0.0922(0.1540) Grad: 0.5803  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.2148(0.1543) Grad: 0.8392  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0851(0.1541) Grad: 0.6024  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.0514(0.1536) Grad: 0.6752  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.1781(0.1534) Grad: 1.8805  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.0565(0.1533) Grad: 1.1116  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 4m 6s (remain 4m 32s) Loss: 0.1433(0.1530) Grad: 1.1834  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.2021(0.1529) Grad: 1.2511  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.2336(0.1531) Grad: 1.2481  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 4m 33s (remain 4m 5s) Loss: 0.0875(0.1532) Grad: 1.0683  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 4m 41s (remain 3m 56s) Loss: 0.1194(0.1531) Grad: 1.5665  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 4m 50s (remain 3m 48s) Loss: 0.1077(0.1530) Grad: 0.8612  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.1569(0.1532) Grad: 0.8268  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0573(0.1535) Grad: 0.8288  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 5m 17s (remain 3m 21s) Loss: 0.0870(0.1532) Grad: 0.9889  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 5m 25s (remain 3m 12s) Loss: 0.3723(0.1529) Grad: 2.0139  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 5m 34s (remain 3m 3s) Loss: 0.1146(0.1530) Grad: 1.0678  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.1406(0.1529) Grad: 0.5643  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.1147(0.1526) Grad: 1.2066  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 6m 0s (remain 2m 37s) Loss: 0.0889(0.1525) Grad: 1.3714  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 6m 9s (remain 2m 28s) Loss: 0.1682(0.1524) Grad: 0.7995  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 6m 18s (remain 2m 19s) Loss: 0.0627(0.1524) Grad: 0.6861  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 6m 26s (remain 2m 11s) Loss: 0.2203(0.1522) Grad: 1.0165  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 6m 35s (remain 2m 2s) Loss: 0.0688(0.1522) Grad: 0.6059  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 6m 44s (remain 1m 53s) Loss: 0.0916(0.1522) Grad: 0.7246  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.1869(0.1522) Grad: 0.7145  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 7m 1s (remain 1m 35s) Loss: 0.1143(0.1523) Grad: 0.7442  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 7m 10s (remain 1m 27s) Loss: 0.1068(0.1521) Grad: 0.7685  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 7m 19s (remain 1m 18s) Loss: 0.0467(0.1521) Grad: 1.1211  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 7m 28s (remain 1m 9s) Loss: 0.1915(0.1524) Grad: 0.6166  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.1854(0.1524) Grad: 0.6381  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 7m 45s (remain 0m 51s) Loss: 0.0829(0.1523) Grad: 0.4731  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 7m 54s (remain 0m 43s) Loss: 0.2260(0.1524) Grad: 1.0745  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 8m 3s (remain 0m 34s) Loss: 0.1846(0.1521) Grad: 0.8069  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 8m 12s (remain 0m 25s) Loss: 0.1295(0.1521) Grad: 1.2292  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 8m 21s (remain 0m 16s) Loss: 0.1261(0.1519) Grad: 0.6192  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 8m 29s (remain 0m 7s) Loss: 0.2081(0.1519) Grad: 0.9759  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 8m 37s (remain 0m 0s) Loss: 0.2157(0.1519) Grad: 1.0840  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 21s) Loss: 0.1748(0.1748) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.2412(0.1283) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.2005(0.1464) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.1643(0.1549) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.2259(0.1592) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1683(0.1616) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1767(0.1610) \n","EVAL: [700/737] Elapsed 1m 31s (remain 0m 4s) Loss: 0.0781(0.1576) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0243(0.1559) \n","f1 score : 0.4872346970163027\n","recall score : 0.36408213300643577\n","precision score : 0.7362875735977689\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1519  avg_val_loss: 0.1559  time: 616s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1519  avg_val_loss: 0.1559  time: 616s\n","Epoch 3 - Score: 0.4872\n","INFO:__main__:Epoch 3 - Score: 0.4872\n","Epoch 3 - Save Best Score: 0.5536 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5536 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 37m 22s) Loss: 0.0459(0.0459) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 9s (remain 8m 51s) Loss: 0.1970(0.1495) Grad: 1.0647  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 18s (remain 8m 39s) Loss: 0.1027(0.1422) Grad: 0.5164  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 27s (remain 8m 26s) Loss: 0.1041(0.1445) Grad: 0.6739  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 0m 36s (remain 8m 14s) Loss: 0.2598(0.1409) Grad: 1.2162  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 0m 44s (remain 8m 3s) Loss: 0.2125(0.1419) Grad: 0.8632  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 0m 53s (remain 7m 53s) Loss: 0.1005(0.1426) Grad: 1.6105  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 2s (remain 7m 42s) Loss: 0.1749(0.1430) Grad: 1.4150  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 1m 11s (remain 7m 32s) Loss: 0.1542(0.1434) Grad: 0.8561  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 1m 19s (remain 7m 22s) Loss: 0.0490(0.1433) Grad: 0.7381  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 1m 28s (remain 7m 13s) Loss: 0.0989(0.1431) Grad: 1.2929  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 1m 37s (remain 7m 4s) Loss: 0.0560(0.1429) Grad: 1.3458  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 1m 46s (remain 6m 55s) Loss: 0.1053(0.1428) Grad: 0.7032  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 1m 55s (remain 6m 46s) Loss: 0.1669(0.1425) Grad: 0.7987  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 2m 3s (remain 6m 37s) Loss: 0.0978(0.1421) Grad: 0.8170  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 2m 12s (remain 6m 28s) Loss: 0.1486(0.1420) Grad: 1.0630  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 2m 21s (remain 6m 19s) Loss: 0.0760(0.1427) Grad: 0.9534  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 2m 30s (remain 6m 10s) Loss: 0.0962(0.1421) Grad: 0.5073  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 2m 39s (remain 6m 2s) Loss: 0.2832(0.1420) Grad: 1.3840  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 2m 48s (remain 5m 53s) Loss: 0.1810(0.1422) Grad: 0.7379  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 2m 57s (remain 5m 44s) Loss: 0.0487(0.1416) Grad: 1.0712  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 3m 5s (remain 5m 35s) Loss: 0.1582(0.1417) Grad: 0.7689  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 3m 14s (remain 5m 26s) Loss: 0.1985(0.1420) Grad: 0.8322  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 3m 23s (remain 5m 17s) Loss: 0.1567(0.1419) Grad: 1.1431  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.1531(0.1418) Grad: 1.0840  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 3m 40s (remain 4m 59s) Loss: 0.3596(0.1418) Grad: 1.9329  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.1753(0.1418) Grad: 1.1271  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.1685(0.1418) Grad: 1.6522  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 4m 7s (remain 4m 32s) Loss: 0.1732(0.1412) Grad: 1.1226  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0553(0.1417) Grad: 0.7072  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.1234(0.1419) Grad: 1.5247  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 4m 33s (remain 4m 5s) Loss: 0.1246(0.1417) Grad: 0.9361  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0963(0.1417) Grad: 1.6636  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 4m 50s (remain 3m 48s) Loss: 0.1577(0.1417) Grad: 0.9194  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.1707(0.1417) Grad: 0.6833  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.2397(0.1419) Grad: 1.7420  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 5m 17s (remain 3m 21s) Loss: 0.1149(0.1418) Grad: 1.0598  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 5m 26s (remain 3m 12s) Loss: 0.1611(0.1418) Grad: 1.1156  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 5m 34s (remain 3m 4s) Loss: 0.1043(0.1419) Grad: 0.7900  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.2257(0.1418) Grad: 1.7128  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.1782(0.1419) Grad: 0.9411  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 6m 1s (remain 2m 37s) Loss: 0.0831(0.1420) Grad: 0.8420  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 6m 10s (remain 2m 28s) Loss: 0.2532(0.1421) Grad: 1.1200  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 6m 18s (remain 2m 20s) Loss: 0.1311(0.1422) Grad: 0.8523  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 6m 27s (remain 2m 11s) Loss: 0.1068(0.1424) Grad: 0.6929  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.1558(0.1425) Grad: 0.9893  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 6m 45s (remain 1m 53s) Loss: 0.1816(0.1427) Grad: 1.1327  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.1716(0.1425) Grad: 0.7510  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 7m 2s (remain 1m 35s) Loss: 0.2415(0.1428) Grad: 1.4802  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.1256(0.1429) Grad: 0.5588  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.1428(0.1426) Grad: 1.8651  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 7m 29s (remain 1m 9s) Loss: 0.2323(0.1427) Grad: 1.5975  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.1236(0.1426) Grad: 0.6368  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 7m 46s (remain 0m 51s) Loss: 0.1455(0.1425) Grad: 1.7369  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 7m 55s (remain 0m 43s) Loss: 0.1005(0.1424) Grad: 0.7115  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 8m 4s (remain 0m 34s) Loss: 0.1481(0.1423) Grad: 1.2022  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 8m 13s (remain 0m 25s) Loss: 0.1328(0.1423) Grad: 0.8203  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 8m 21s (remain 0m 16s) Loss: 0.1096(0.1423) Grad: 0.6531  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 8m 30s (remain 0m 7s) Loss: 0.2235(0.1422) Grad: 1.4549  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 8m 38s (remain 0m 0s) Loss: 0.1192(0.1421) Grad: 0.9828  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 19s) Loss: 0.1861(0.1861) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.2300(0.1292) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.1966(0.1461) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.1646(0.1543) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.2227(0.1589) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1704(0.1612) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1752(0.1608) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.0768(0.1576) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0220(0.1560) \n","f1 score : 0.5130931285686159\n","recall score : 0.39932577382776585\n","precision score : 0.7175110132158591\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1421  avg_val_loss: 0.1560  time: 618s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1421  avg_val_loss: 0.1560  time: 618s\n","Epoch 4 - Score: 0.5131\n","INFO:__main__:Epoch 4 - Score: 0.5131\n","========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.4872346970163027\n","recall score : 0.36408213300643577\n","precision score : 0.7362875735977689\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.4872\n","INFO:__main__:Score: 0.4872\n","F1 BEST Score: 0.5536\n","INFO:__main__:F1 BEST Score: 0.5536\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 0s (remain 40m 45s) Loss: 0.6865(0.6865) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 9s (remain 8m 59s) Loss: 0.2625(0.2731) Grad: 1.1978  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 18s (remain 8m 35s) Loss: 0.1688(0.2532) Grad: 0.4189  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 27s (remain 8m 24s) Loss: 0.1315(0.2407) Grad: 0.7211  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 0m 36s (remain 8m 15s) Loss: 0.2771(0.2329) Grad: 1.0342  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 0m 45s (remain 8m 4s) Loss: 0.2830(0.2290) Grad: 0.8104  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 0m 53s (remain 7m 53s) Loss: 0.1339(0.2219) Grad: 0.7344  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 2s (remain 7m 43s) Loss: 0.3621(0.2192) Grad: 1.1331  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 1m 11s (remain 7m 34s) Loss: 0.1576(0.2168) Grad: 1.0213  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 1m 20s (remain 7m 25s) Loss: 0.1765(0.2141) Grad: 0.5598  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 1m 29s (remain 7m 16s) Loss: 0.1780(0.2132) Grad: 0.3459  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 1m 38s (remain 7m 6s) Loss: 0.1268(0.2108) Grad: 0.9812  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 1m 46s (remain 6m 57s) Loss: 0.3167(0.2101) Grad: 1.0009  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 1m 55s (remain 6m 48s) Loss: 0.3191(0.2101) Grad: 1.3153  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 2m 4s (remain 6m 39s) Loss: 0.1710(0.2090) Grad: 1.5373  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 2m 13s (remain 6m 30s) Loss: 0.2330(0.2076) Grad: 1.2346  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 2m 22s (remain 6m 21s) Loss: 0.1843(0.2071) Grad: 1.0267  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 2m 31s (remain 6m 12s) Loss: 0.1471(0.2068) Grad: 0.7655  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 2m 39s (remain 6m 3s) Loss: 0.1787(0.2062) Grad: 0.7783  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 2m 48s (remain 5m 54s) Loss: 0.1510(0.2052) Grad: 0.6249  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 2m 57s (remain 5m 45s) Loss: 0.1627(0.2043) Grad: 1.6025  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 3m 6s (remain 5m 36s) Loss: 0.1565(0.2041) Grad: 1.1824  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 3m 15s (remain 5m 27s) Loss: 0.1998(0.2037) Grad: 0.8589  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 3m 24s (remain 5m 18s) Loss: 0.1396(0.2031) Grad: 1.0430  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 3m 33s (remain 5m 9s) Loss: 0.1981(0.2026) Grad: 0.7612  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 3m 41s (remain 5m 0s) Loss: 0.1979(0.2023) Grad: 0.8341  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 3m 50s (remain 4m 51s) Loss: 0.3291(0.2020) Grad: 1.2019  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 3m 59s (remain 4m 42s) Loss: 0.2595(0.2014) Grad: 1.0877  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 4m 8s (remain 4m 34s) Loss: 0.1729(0.2006) Grad: 0.4502  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 4m 17s (remain 4m 25s) Loss: 0.1780(0.2002) Grad: 0.6699  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 4m 26s (remain 4m 16s) Loss: 0.0934(0.1994) Grad: 0.8547  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 4m 35s (remain 4m 7s) Loss: 0.1213(0.1989) Grad: 1.1697  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 4m 43s (remain 3m 58s) Loss: 0.2681(0.1982) Grad: 1.1606  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 4m 52s (remain 3m 49s) Loss: 0.1791(0.1978) Grad: 0.8505  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 5m 1s (remain 3m 40s) Loss: 0.1102(0.1973) Grad: 0.4731  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 5m 10s (remain 3m 31s) Loss: 0.2035(0.1967) Grad: 0.6208  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 5m 19s (remain 3m 23s) Loss: 0.2993(0.1964) Grad: 1.5500  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 5m 28s (remain 3m 14s) Loss: 0.0755(0.1957) Grad: 0.9197  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 5m 36s (remain 3m 5s) Loss: 0.1492(0.1952) Grad: 0.6092  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 5m 45s (remain 2m 56s) Loss: 0.1378(0.1948) Grad: 1.4280  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 5m 54s (remain 2m 47s) Loss: 0.1464(0.1943) Grad: 0.7279  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 6m 3s (remain 2m 38s) Loss: 0.1686(0.1937) Grad: 1.0416  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 6m 12s (remain 2m 29s) Loss: 0.1802(0.1932) Grad: 0.6237  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 6m 21s (remain 2m 21s) Loss: 0.2371(0.1929) Grad: 1.3568  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 6m 30s (remain 2m 12s) Loss: 0.1840(0.1926) Grad: 0.9447  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 6m 39s (remain 2m 3s) Loss: 0.0632(0.1924) Grad: 1.0230  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 6m 48s (remain 1m 54s) Loss: 0.2075(0.1922) Grad: 1.2656  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 6m 56s (remain 1m 45s) Loss: 0.2391(0.1918) Grad: 1.3265  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 7m 5s (remain 1m 36s) Loss: 0.1208(0.1916) Grad: 1.8275  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 7m 14s (remain 1m 27s) Loss: 0.1802(0.1915) Grad: 1.0627  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 7m 23s (remain 1m 18s) Loss: 0.2605(0.1913) Grad: 0.8059  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 7m 32s (remain 1m 10s) Loss: 0.0902(0.1910) Grad: 0.5173  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 7m 41s (remain 1m 1s) Loss: 0.4192(0.1906) Grad: 2.5179  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 7m 50s (remain 0m 52s) Loss: 0.1785(0.1900) Grad: 0.7660  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 7m 59s (remain 0m 43s) Loss: 0.2500(0.1897) Grad: 1.2026  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 8m 8s (remain 0m 34s) Loss: 0.4192(0.1894) Grad: 2.2809  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 8m 16s (remain 0m 25s) Loss: 0.1438(0.1892) Grad: 0.5299  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 8m 25s (remain 0m 16s) Loss: 0.1292(0.1887) Grad: 0.7974  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 8m 34s (remain 0m 7s) Loss: 0.0819(0.1886) Grad: 1.1417  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 8m 42s (remain 0m 0s) Loss: 0.2839(0.1882) Grad: 0.9156  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 39s) Loss: 0.1631(0.1631) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1049(0.1395) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.2425(0.1580) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.1138(0.1667) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.2064(0.1720) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1764(0.1734) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1568(0.1735) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1218(0.1704) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1072(0.1689) \n","f1 score : 0.43512423019749413\n","recall score : 0.3139748697517622\n","precision score : 0.7085062240663901\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.1882  avg_val_loss: 0.1689  time: 622s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.1882  avg_val_loss: 0.1689  time: 622s\n","Epoch 1 - Score: 0.4351\n","INFO:__main__:Epoch 1 - Score: 0.4351\n","Epoch 1 - Save Best Score: 0.5114 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5114 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 41m 37s) Loss: 0.1236(0.1236) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 9s (remain 8m 54s) Loss: 0.1635(0.1599) Grad: 1.4350  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 18s (remain 8m 34s) Loss: 0.1113(0.1637) Grad: 0.6017  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 27s (remain 8m 22s) Loss: 0.0909(0.1647) Grad: 0.4736  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 0m 35s (remain 8m 11s) Loss: 0.2600(0.1620) Grad: 0.7906  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 0m 44s (remain 8m 1s) Loss: 0.1187(0.1626) Grad: 0.6261  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 0m 53s (remain 7m 51s) Loss: 0.0698(0.1643) Grad: 0.8030  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 2s (remain 7m 41s) Loss: 0.1182(0.1644) Grad: 0.4200  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 1m 11s (remain 7m 32s) Loss: 0.2878(0.1655) Grad: 1.4307  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 1m 20s (remain 7m 23s) Loss: 0.0881(0.1649) Grad: 0.6741  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 1m 28s (remain 7m 13s) Loss: 0.1744(0.1655) Grad: 0.6132  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 1m 37s (remain 7m 4s) Loss: 0.0639(0.1651) Grad: 0.8411  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 1m 46s (remain 6m 55s) Loss: 0.1439(0.1651) Grad: 0.5753  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 1m 55s (remain 6m 46s) Loss: 0.1194(0.1649) Grad: 0.5567  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 2m 3s (remain 6m 37s) Loss: 0.0912(0.1657) Grad: 0.9198  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 2m 12s (remain 6m 28s) Loss: 0.1504(0.1663) Grad: 0.8847  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 2m 21s (remain 6m 19s) Loss: 0.1299(0.1659) Grad: 0.8189  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 2m 30s (remain 6m 10s) Loss: 0.1807(0.1658) Grad: 0.6901  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 2m 39s (remain 6m 2s) Loss: 0.0376(0.1652) Grad: 0.8407  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 2m 48s (remain 5m 53s) Loss: 0.2157(0.1649) Grad: 0.9023  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 2m 57s (remain 5m 44s) Loss: 0.1962(0.1652) Grad: 0.9658  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 3m 6s (remain 5m 35s) Loss: 0.1885(0.1650) Grad: 0.9155  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 3m 14s (remain 5m 26s) Loss: 0.1599(0.1653) Grad: 1.3361  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 3m 23s (remain 5m 17s) Loss: 0.1266(0.1648) Grad: 0.5972  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.0578(0.1650) Grad: 0.8157  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 3m 41s (remain 4m 59s) Loss: 0.0840(0.1646) Grad: 0.7322  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 3m 50s (remain 4m 51s) Loss: 0.1534(0.1651) Grad: 0.9944  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 3m 58s (remain 4m 42s) Loss: 0.1964(0.1649) Grad: 0.7548  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 4m 7s (remain 4m 33s) Loss: 0.2169(0.1648) Grad: 1.1272  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 4m 16s (remain 4m 24s) Loss: 0.1484(0.1650) Grad: 0.6973  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 4m 25s (remain 4m 15s) Loss: 0.1956(0.1649) Grad: 0.7383  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 4m 34s (remain 4m 6s) Loss: 0.1420(0.1645) Grad: 1.0804  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.1827(0.1645) Grad: 1.2654  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.1162(0.1642) Grad: 0.7557  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 5m 0s (remain 3m 40s) Loss: 0.2678(0.1643) Grad: 1.4297  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 5m 9s (remain 3m 31s) Loss: 0.2844(0.1644) Grad: 1.2611  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 5m 18s (remain 3m 22s) Loss: 0.1753(0.1643) Grad: 0.7606  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 5m 27s (remain 3m 13s) Loss: 0.1390(0.1645) Grad: 0.6283  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0610(0.1643) Grad: 0.7747  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 5m 44s (remain 2m 55s) Loss: 0.2220(0.1644) Grad: 1.4589  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 5m 53s (remain 2m 47s) Loss: 0.2307(0.1645) Grad: 0.8618  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 6m 2s (remain 2m 38s) Loss: 0.2319(0.1644) Grad: 0.7665  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 6m 11s (remain 2m 29s) Loss: 0.1342(0.1643) Grad: 0.6458  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.1086(0.1641) Grad: 1.0835  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.2029(0.1642) Grad: 0.8765  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 6m 37s (remain 2m 2s) Loss: 0.2424(0.1639) Grad: 1.0805  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 6m 46s (remain 1m 53s) Loss: 0.1274(0.1638) Grad: 0.7324  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 6m 55s (remain 1m 45s) Loss: 0.1871(0.1634) Grad: 1.3140  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 7m 3s (remain 1m 36s) Loss: 0.0409(0.1632) Grad: 0.6480  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 7m 13s (remain 1m 27s) Loss: 0.1171(0.1630) Grad: 0.7196  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 7m 21s (remain 1m 18s) Loss: 0.2529(0.1631) Grad: 1.5042  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 7m 31s (remain 1m 9s) Loss: 0.2145(0.1629) Grad: 0.9827  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 7m 40s (remain 1m 1s) Loss: 0.0683(0.1629) Grad: 0.7815  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 7m 48s (remain 0m 52s) Loss: 0.1874(0.1630) Grad: 0.6588  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 7m 57s (remain 0m 43s) Loss: 0.1026(0.1629) Grad: 0.7496  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 8m 6s (remain 0m 34s) Loss: 0.1301(0.1628) Grad: 1.3426  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 8m 15s (remain 0m 25s) Loss: 0.1198(0.1626) Grad: 0.5649  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 8m 24s (remain 0m 16s) Loss: 0.2173(0.1626) Grad: 0.7974  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 8m 33s (remain 0m 7s) Loss: 0.0490(0.1624) Grad: 1.2127  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 8m 41s (remain 0m 0s) Loss: 0.2463(0.1624) Grad: 0.7711  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 36s) Loss: 0.1722(0.1722) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1027(0.1304) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.2258(0.1487) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.1102(0.1585) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.1793(0.1635) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1624(0.1652) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1548(0.1646) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.0960(0.1613) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1120(0.1598) \n","f1 score : 0.46402877697841727\n","recall score : 0.3360404535703341\n","precision score : 0.7494873547505126\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.1624  avg_val_loss: 0.1598  time: 620s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1624  avg_val_loss: 0.1598  time: 620s\n","Epoch 2 - Score: 0.4640\n","INFO:__main__:Epoch 2 - Score: 0.4640\n","Epoch 2 - Save Best Score: 0.5389 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5389 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 41m 34s) Loss: 0.1956(0.1956) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 9s (remain 8m 54s) Loss: 0.0668(0.1565) Grad: 0.9570  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 18s (remain 8m 38s) Loss: 0.1880(0.1521) Grad: 0.8088  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 27s (remain 8m 25s) Loss: 0.2062(0.1536) Grad: 0.9529  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 0m 36s (remain 8m 13s) Loss: 0.1175(0.1531) Grad: 0.8823  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 0m 44s (remain 8m 2s) Loss: 0.1276(0.1512) Grad: 1.0819  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 0m 53s (remain 7m 51s) Loss: 0.2700(0.1521) Grad: 1.8190  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 2s (remain 7m 42s) Loss: 0.2693(0.1512) Grad: 1.8018  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 1m 11s (remain 7m 32s) Loss: 0.1161(0.1502) Grad: 0.6138  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 1m 19s (remain 7m 22s) Loss: 0.0535(0.1510) Grad: 0.9187  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 1m 28s (remain 7m 13s) Loss: 0.2018(0.1513) Grad: 1.2125  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 1m 37s (remain 7m 4s) Loss: 0.1625(0.1517) Grad: 0.6906  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.1786(0.1514) Grad: 0.7149  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 1m 55s (remain 6m 45s) Loss: 0.1245(0.1520) Grad: 1.3804  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.2330(0.1530) Grad: 1.3067  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.1881(0.1527) Grad: 0.6737  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.0902(0.1524) Grad: 1.0544  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 2m 30s (remain 6m 9s) Loss: 0.2367(0.1518) Grad: 1.1569  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.0831(0.1518) Grad: 0.8807  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 2m 47s (remain 5m 51s) Loss: 0.1869(0.1513) Grad: 1.0501  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 2m 56s (remain 5m 43s) Loss: 0.2703(0.1511) Grad: 1.3131  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 3m 5s (remain 5m 34s) Loss: 0.1746(0.1514) Grad: 0.9781  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 3m 13s (remain 5m 25s) Loss: 0.2262(0.1517) Grad: 2.1830  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.0856(0.1516) Grad: 0.7221  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.1610(0.1514) Grad: 0.7485  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.2081(0.1515) Grad: 0.8013  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 3m 49s (remain 4m 49s) Loss: 0.3035(0.1515) Grad: 1.1222  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 3m 57s (remain 4m 40s) Loss: 0.1161(0.1517) Grad: 0.3685  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 4m 6s (remain 4m 31s) Loss: 0.3708(0.1520) Grad: 1.9965  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.2316(0.1526) Grad: 0.7791  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.1184(0.1525) Grad: 0.8741  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 4m 32s (remain 4m 5s) Loss: 0.2135(0.1523) Grad: 0.7747  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 4m 41s (remain 3m 56s) Loss: 0.0701(0.1523) Grad: 1.4858  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 4m 50s (remain 3m 47s) Loss: 0.1846(0.1525) Grad: 1.4824  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.1655(0.1526) Grad: 0.7802  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 5m 7s (remain 3m 30s) Loss: 0.1792(0.1524) Grad: 0.8064  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 5m 16s (remain 3m 21s) Loss: 0.1014(0.1523) Grad: 1.2440  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 5m 25s (remain 3m 12s) Loss: 0.0964(0.1524) Grad: 0.9656  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 5m 34s (remain 3m 3s) Loss: 0.2498(0.1522) Grad: 0.6853  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.1631(0.1520) Grad: 0.7777  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 5m 51s (remain 2m 46s) Loss: 0.1941(0.1519) Grad: 1.2731  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 6m 0s (remain 2m 37s) Loss: 0.1903(0.1519) Grad: 1.0671  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 6m 9s (remain 2m 28s) Loss: 0.0824(0.1518) Grad: 0.7140  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 6m 18s (remain 2m 19s) Loss: 0.0663(0.1519) Grad: 0.6550  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 6m 27s (remain 2m 11s) Loss: 0.1071(0.1520) Grad: 1.1382  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.0786(0.1516) Grad: 0.5852  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 6m 44s (remain 1m 53s) Loss: 0.2142(0.1516) Grad: 0.9684  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.1573(0.1516) Grad: 0.9248  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 7m 2s (remain 1m 35s) Loss: 0.0256(0.1516) Grad: 0.6673  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.0353(0.1514) Grad: 0.6807  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.1274(0.1516) Grad: 0.6729  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 7m 28s (remain 1m 9s) Loss: 0.0883(0.1515) Grad: 0.8154  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.1718(0.1516) Grad: 1.5544  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 7m 46s (remain 0m 51s) Loss: 0.0714(0.1517) Grad: 0.5527  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 7m 55s (remain 0m 43s) Loss: 0.0473(0.1515) Grad: 0.5537  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 8m 4s (remain 0m 34s) Loss: 0.2693(0.1511) Grad: 1.2287  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 8m 13s (remain 0m 25s) Loss: 0.0875(0.1510) Grad: 1.6017  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 8m 21s (remain 0m 16s) Loss: 0.1786(0.1511) Grad: 0.9368  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 8m 30s (remain 0m 7s) Loss: 0.1364(0.1510) Grad: 0.7398  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 8m 38s (remain 0m 0s) Loss: 0.2642(0.1510) Grad: 0.9280  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 37s) Loss: 0.1641(0.1641) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1043(0.1266) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.2104(0.1449) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.1035(0.1540) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.2025(0.1589) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1632(0.1606) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1553(0.1602) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.0911(0.1574) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1122(0.1559) \n","f1 score : 0.4991418475517415\n","recall score : 0.37879252221881704\n","precision score : 0.7315773897602841\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1510  avg_val_loss: 0.1559  time: 618s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1510  avg_val_loss: 0.1559  time: 618s\n","Epoch 3 - Score: 0.4991\n","INFO:__main__:Epoch 3 - Score: 0.4991\n","Epoch 3 - Save Best Score: 0.5532 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5532 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 37m 57s) Loss: 0.0837(0.0837) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 9s (remain 8m 49s) Loss: 0.1224(0.1424) Grad: 1.0889  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 18s (remain 8m 36s) Loss: 0.0731(0.1390) Grad: 0.6585  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 27s (remain 8m 25s) Loss: 0.1285(0.1411) Grad: 0.6558  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 0m 35s (remain 8m 12s) Loss: 0.1453(0.1427) Grad: 0.8279  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 0m 44s (remain 8m 2s) Loss: 0.2289(0.1433) Grad: 1.0996  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 0m 53s (remain 7m 52s) Loss: 0.2335(0.1451) Grad: 1.5236  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 2s (remain 7m 42s) Loss: 0.0936(0.1444) Grad: 0.8700  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 1m 11s (remain 7m 33s) Loss: 0.1094(0.1444) Grad: 0.9235  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 1m 20s (remain 7m 23s) Loss: 0.1992(0.1439) Grad: 1.0978  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 1m 29s (remain 7m 14s) Loss: 0.1055(0.1435) Grad: 1.0628  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 1m 37s (remain 7m 5s) Loss: 0.0765(0.1436) Grad: 0.7131  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 1m 46s (remain 6m 56s) Loss: 0.0893(0.1432) Grad: 1.0105  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 1m 55s (remain 6m 47s) Loss: 0.1774(0.1432) Grad: 1.0233  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 2m 4s (remain 6m 38s) Loss: 0.1129(0.1432) Grad: 0.9525  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 2m 12s (remain 6m 28s) Loss: 0.0778(0.1435) Grad: 0.7173  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 2m 21s (remain 6m 19s) Loss: 0.3376(0.1435) Grad: 2.0757  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 2m 30s (remain 6m 11s) Loss: 0.0609(0.1436) Grad: 0.7967  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 2m 39s (remain 6m 1s) Loss: 0.1148(0.1438) Grad: 0.7873  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 2m 48s (remain 5m 53s) Loss: 0.1632(0.1441) Grad: 0.8334  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 2m 57s (remain 5m 44s) Loss: 0.1482(0.1439) Grad: 1.0726  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 3m 5s (remain 5m 35s) Loss: 0.1313(0.1440) Grad: 0.7022  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 3m 14s (remain 5m 26s) Loss: 0.1898(0.1439) Grad: 1.0299  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 3m 23s (remain 5m 17s) Loss: 0.0938(0.1439) Grad: 0.5429  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.2112(0.1434) Grad: 0.8559  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 3m 41s (remain 4m 59s) Loss: 0.1595(0.1436) Grad: 1.1560  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 3m 50s (remain 4m 50s) Loss: 0.1965(0.1436) Grad: 0.9781  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 3m 58s (remain 4m 42s) Loss: 0.1908(0.1430) Grad: 1.2259  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 4m 7s (remain 4m 33s) Loss: 0.0928(0.1431) Grad: 0.7334  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 4m 16s (remain 4m 24s) Loss: 0.1990(0.1429) Grad: 1.0146  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 4m 25s (remain 4m 15s) Loss: 0.1372(0.1428) Grad: 0.7501  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 4m 34s (remain 4m 6s) Loss: 0.1348(0.1428) Grad: 1.0990  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0318(0.1425) Grad: 0.8234  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.1538(0.1424) Grad: 1.4289  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 5m 0s (remain 3m 40s) Loss: 0.0908(0.1424) Grad: 1.4621  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 5m 9s (remain 3m 31s) Loss: 0.1957(0.1423) Grad: 0.8926  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 5m 18s (remain 3m 22s) Loss: 0.1560(0.1419) Grad: 0.6944  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 5m 27s (remain 3m 13s) Loss: 0.1372(0.1420) Grad: 0.7486  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 5m 36s (remain 3m 4s) Loss: 0.0739(0.1421) Grad: 0.6969  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 5m 45s (remain 2m 56s) Loss: 0.2788(0.1419) Grad: 1.2041  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 5m 54s (remain 2m 47s) Loss: 0.0611(0.1417) Grad: 0.6247  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 6m 3s (remain 2m 38s) Loss: 0.4460(0.1419) Grad: 2.9603  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 6m 12s (remain 2m 29s) Loss: 0.1509(0.1418) Grad: 1.0050  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 6m 21s (remain 2m 20s) Loss: 0.1232(0.1420) Grad: 0.6573  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 6m 30s (remain 2m 12s) Loss: 0.2666(0.1420) Grad: 1.5823  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 6m 39s (remain 2m 3s) Loss: 0.2361(0.1419) Grad: 1.5520  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 6m 48s (remain 1m 54s) Loss: 0.0789(0.1418) Grad: 0.6922  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 6m 57s (remain 1m 45s) Loss: 0.2942(0.1418) Grad: 2.1049  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 7m 6s (remain 1m 36s) Loss: 0.0799(0.1417) Grad: 0.7041  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 7m 14s (remain 1m 27s) Loss: 0.1918(0.1416) Grad: 0.8550  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 7m 23s (remain 1m 18s) Loss: 0.0581(0.1415) Grad: 0.5861  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 7m 32s (remain 1m 10s) Loss: 0.0911(0.1414) Grad: 1.1416  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 7m 41s (remain 1m 1s) Loss: 0.3037(0.1415) Grad: 1.6747  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 7m 50s (remain 0m 52s) Loss: 0.0998(0.1415) Grad: 0.8773  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 7m 59s (remain 0m 43s) Loss: 0.1587(0.1415) Grad: 1.2025  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 8m 8s (remain 0m 34s) Loss: 0.0614(0.1416) Grad: 0.4869  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 8m 17s (remain 0m 25s) Loss: 0.0773(0.1416) Grad: 0.6320  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 8m 26s (remain 0m 16s) Loss: 0.1456(0.1415) Grad: 1.3896  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 8m 35s (remain 0m 7s) Loss: 0.0626(0.1417) Grad: 0.8050  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 8m 42s (remain 0m 0s) Loss: 0.1177(0.1415) Grad: 0.8165  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 38s) Loss: 0.1679(0.1679) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1091(0.1286) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.2053(0.1461) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.1029(0.1548) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.1981(0.1596) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1653(0.1614) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1598(0.1610) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.0822(0.1583) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1121(0.1568) \n","f1 score : 0.5090444357058592\n","recall score : 0.39672080907140667\n","precision score : 0.7100932528798684\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1415  avg_val_loss: 0.1568  time: 622s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1415  avg_val_loss: 0.1568  time: 622s\n","Epoch 4 - Score: 0.5090\n","INFO:__main__:Epoch 4 - Score: 0.5090\n","Epoch 4 - Save Best Score: 0.5537 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.5537 Model\n","========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.5090444357058592\n","recall score : 0.39672080907140667\n","precision score : 0.7100932528798684\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.5090\n","INFO:__main__:Score: 0.5090\n","F1 BEST Score: 0.5537\n","INFO:__main__:F1 BEST Score: 0.5537\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 0s (remain 41m 31s) Loss: 0.4429(0.4429) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 9s (remain 9m 0s) Loss: 0.2064(0.2514) Grad: 0.5387  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 18s (remain 8m 41s) Loss: 0.1268(0.2405) Grad: 0.7900  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 27s (remain 8m 29s) Loss: 0.3472(0.2296) Grad: 1.5889  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 0m 36s (remain 8m 16s) Loss: 0.2114(0.2262) Grad: 0.3918  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 0m 45s (remain 8m 5s) Loss: 0.0967(0.2212) Grad: 1.5708  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 0m 53s (remain 7m 55s) Loss: 0.1389(0.2218) Grad: 0.8548  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 2s (remain 7m 45s) Loss: 0.0706(0.2203) Grad: 0.8289  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 1m 11s (remain 7m 35s) Loss: 0.2278(0.2173) Grad: 1.5615  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 1m 20s (remain 7m 25s) Loss: 0.2710(0.2156) Grad: 1.4985  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 1m 29s (remain 7m 15s) Loss: 0.1403(0.2143) Grad: 0.4683  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 1m 38s (remain 7m 6s) Loss: 0.2715(0.2128) Grad: 1.2772  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 1m 46s (remain 6m 57s) Loss: 0.1531(0.2119) Grad: 1.5763  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 1m 55s (remain 6m 48s) Loss: 0.1858(0.2115) Grad: 1.2689  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 2m 4s (remain 6m 39s) Loss: 0.0835(0.2108) Grad: 2.0299  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 2m 13s (remain 6m 29s) Loss: 0.1779(0.2106) Grad: 0.9078  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 2m 22s (remain 6m 20s) Loss: 0.3342(0.2095) Grad: 1.7434  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 2m 30s (remain 6m 11s) Loss: 0.2112(0.2094) Grad: 0.9434  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 2m 39s (remain 6m 3s) Loss: 0.1731(0.2087) Grad: 0.3076  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 2m 48s (remain 5m 54s) Loss: 0.3464(0.2079) Grad: 1.5986  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 2m 57s (remain 5m 45s) Loss: 0.3208(0.2076) Grad: 1.1756  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 3m 6s (remain 5m 36s) Loss: 0.1100(0.2073) Grad: 1.1182  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 3m 15s (remain 5m 27s) Loss: 0.1470(0.2063) Grad: 1.1588  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 3m 24s (remain 5m 18s) Loss: 0.1335(0.2057) Grad: 1.0169  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 3m 33s (remain 5m 9s) Loss: 0.1622(0.2051) Grad: 1.6412  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 3m 41s (remain 5m 0s) Loss: 0.1683(0.2039) Grad: 0.4782  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 3m 50s (remain 4m 51s) Loss: 0.0314(0.2035) Grad: 0.8354  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 3m 59s (remain 4m 42s) Loss: 0.1504(0.2027) Grad: 0.4297  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 4m 8s (remain 4m 34s) Loss: 0.1952(0.2022) Grad: 1.3589  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 4m 17s (remain 4m 25s) Loss: 0.2498(0.2018) Grad: 1.1140  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 4m 26s (remain 4m 16s) Loss: 0.2678(0.2007) Grad: 1.0618  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 4m 35s (remain 4m 7s) Loss: 0.0994(0.2002) Grad: 0.9879  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 4m 43s (remain 3m 58s) Loss: 0.2156(0.1996) Grad: 1.3342  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 4m 52s (remain 3m 49s) Loss: 0.1885(0.1991) Grad: 0.6167  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 5m 1s (remain 3m 40s) Loss: 0.1088(0.1982) Grad: 1.0907  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 5m 10s (remain 3m 31s) Loss: 0.1884(0.1977) Grad: 0.6155  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 5m 19s (remain 3m 22s) Loss: 0.2976(0.1973) Grad: 0.8265  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 5m 28s (remain 3m 14s) Loss: 0.1171(0.1966) Grad: 0.7359  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 5m 36s (remain 3m 5s) Loss: 0.1493(0.1962) Grad: 0.6958  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 5m 45s (remain 2m 56s) Loss: 0.1753(0.1957) Grad: 0.4587  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 5m 54s (remain 2m 47s) Loss: 0.1938(0.1950) Grad: 0.6694  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 6m 3s (remain 2m 38s) Loss: 0.1716(0.1947) Grad: 0.7588  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 6m 12s (remain 2m 29s) Loss: 0.0930(0.1942) Grad: 1.8413  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 6m 21s (remain 2m 20s) Loss: 0.2174(0.1937) Grad: 0.8707  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 6m 30s (remain 2m 12s) Loss: 0.1893(0.1932) Grad: 0.7485  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 6m 38s (remain 2m 3s) Loss: 0.1359(0.1928) Grad: 0.3540  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 6m 47s (remain 1m 54s) Loss: 0.1744(0.1921) Grad: 0.5402  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 6m 56s (remain 1m 45s) Loss: 0.2191(0.1914) Grad: 1.0597  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 7m 5s (remain 1m 36s) Loss: 0.2465(0.1909) Grad: 0.8455  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 7m 14s (remain 1m 27s) Loss: 0.2001(0.1906) Grad: 0.8532  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 7m 23s (remain 1m 18s) Loss: 0.2372(0.1905) Grad: 0.6522  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 7m 32s (remain 1m 10s) Loss: 0.3037(0.1903) Grad: 1.3786  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 7m 41s (remain 1m 1s) Loss: 0.0885(0.1900) Grad: 0.7331  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 7m 49s (remain 0m 52s) Loss: 0.2261(0.1898) Grad: 0.5289  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 7m 58s (remain 0m 43s) Loss: 0.1586(0.1897) Grad: 0.6897  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 8m 7s (remain 0m 34s) Loss: 0.1174(0.1896) Grad: 1.1383  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 8m 16s (remain 0m 25s) Loss: 0.1039(0.1893) Grad: 0.7985  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 8m 25s (remain 0m 16s) Loss: 0.2307(0.1890) Grad: 0.6617  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 8m 34s (remain 0m 7s) Loss: 0.2681(0.1889) Grad: 1.3916  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 8m 42s (remain 0m 0s) Loss: 0.0891(0.1886) Grad: 0.7604  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 45s) Loss: 0.1042(0.1042) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1602(0.1377) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.1818(0.1593) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.2587(0.1653) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.1865(0.1683) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 31s) Loss: 0.1529(0.1707) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1613(0.1725) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1676(0.1699) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1659(0.1685) \n","f1 score : 0.43702676762290715\n","recall score : 0.3139267657423012\n","precision score : 0.7189473684210527\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.1886  avg_val_loss: 0.1685  time: 621s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.1886  avg_val_loss: 0.1685  time: 621s\n","Epoch 1 - Score: 0.4370\n","INFO:__main__:Epoch 1 - Score: 0.4370\n","Epoch 1 - Save Best Score: 0.5106 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5106 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 38m 15s) Loss: 0.0867(0.0867) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 9s (remain 8m 51s) Loss: 0.1879(0.1729) Grad: 1.0137  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 18s (remain 8m 35s) Loss: 0.1044(0.1698) Grad: 0.4768  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 27s (remain 8m 24s) Loss: 0.0679(0.1673) Grad: 0.6711  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 0m 36s (remain 8m 14s) Loss: 0.1185(0.1658) Grad: 0.5835  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 0m 44s (remain 8m 3s) Loss: 0.1780(0.1665) Grad: 0.9377  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 0m 53s (remain 7m 53s) Loss: 0.1353(0.1664) Grad: 1.0990  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 2s (remain 7m 44s) Loss: 0.1884(0.1659) Grad: 1.2226  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 1m 11s (remain 7m 34s) Loss: 0.0671(0.1653) Grad: 0.7581  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 1m 20s (remain 7m 25s) Loss: 0.2664(0.1661) Grad: 0.9815  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 1m 29s (remain 7m 16s) Loss: 0.1625(0.1666) Grad: 0.5571  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 1m 38s (remain 7m 7s) Loss: 0.0800(0.1660) Grad: 0.5291  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 1m 46s (remain 6m 57s) Loss: 0.1945(0.1667) Grad: 1.0272  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 1m 55s (remain 6m 48s) Loss: 0.0857(0.1670) Grad: 0.7577  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 2m 4s (remain 6m 39s) Loss: 0.1410(0.1678) Grad: 0.4738  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 2m 13s (remain 6m 30s) Loss: 0.0667(0.1673) Grad: 0.7128  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 2m 22s (remain 6m 21s) Loss: 0.0732(0.1669) Grad: 1.1785  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 2m 31s (remain 6m 12s) Loss: 0.2026(0.1669) Grad: 0.9612  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 2m 40s (remain 6m 3s) Loss: 0.0735(0.1670) Grad: 1.0180  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 2m 48s (remain 5m 54s) Loss: 0.1726(0.1668) Grad: 0.7417  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 2m 57s (remain 5m 45s) Loss: 0.0993(0.1667) Grad: 0.5429  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 3m 6s (remain 5m 36s) Loss: 0.1401(0.1668) Grad: nan  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 3m 15s (remain 5m 27s) Loss: 0.2169(0.1670) Grad: 0.6849  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 3m 24s (remain 5m 18s) Loss: 0.2156(0.1671) Grad: 1.0391  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 3m 33s (remain 5m 10s) Loss: 0.0925(0.1671) Grad: 0.5045  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 3m 42s (remain 5m 1s) Loss: 0.0643(0.1670) Grad: 0.9258  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 3m 51s (remain 4m 52s) Loss: 0.2534(0.1670) Grad: 1.1288  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 3m 59s (remain 4m 43s) Loss: 0.0671(0.1666) Grad: 0.6962  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 4m 8s (remain 4m 34s) Loss: 0.2211(0.1668) Grad: 0.9043  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 4m 17s (remain 4m 25s) Loss: 0.0778(0.1671) Grad: 0.9092  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 4m 26s (remain 4m 16s) Loss: 0.1750(0.1669) Grad: 0.7353  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 4m 35s (remain 4m 7s) Loss: 0.1266(0.1668) Grad: 0.4303  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 4m 44s (remain 3m 58s) Loss: 0.1508(0.1664) Grad: 0.6503  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 4m 53s (remain 3m 50s) Loss: 0.2400(0.1667) Grad: 1.4858  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 5m 2s (remain 3m 41s) Loss: 0.0742(0.1663) Grad: 0.6454  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 5m 10s (remain 3m 32s) Loss: 0.1510(0.1662) Grad: 0.7490  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 5m 19s (remain 3m 23s) Loss: 0.1477(0.1659) Grad: 0.5508  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 5m 28s (remain 3m 14s) Loss: 0.1111(0.1658) Grad: 0.7159  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 5m 37s (remain 3m 5s) Loss: 0.0471(0.1657) Grad: 0.4585  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 5m 46s (remain 2m 56s) Loss: 0.0676(0.1655) Grad: 1.4130  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 5m 55s (remain 2m 47s) Loss: 0.2104(0.1653) Grad: 1.3690  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 6m 4s (remain 2m 38s) Loss: 0.1924(0.1651) Grad: 0.8921  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 6m 12s (remain 2m 30s) Loss: 0.1555(0.1649) Grad: 0.8856  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 6m 21s (remain 2m 21s) Loss: 0.0616(0.1647) Grad: 0.9316  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 6m 30s (remain 2m 12s) Loss: 0.1450(0.1646) Grad: 0.7911  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 6m 39s (remain 2m 3s) Loss: 0.1414(0.1643) Grad: 1.3192  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 6m 48s (remain 1m 54s) Loss: 0.1936(0.1640) Grad: 1.2632  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 6m 57s (remain 1m 45s) Loss: 0.1099(0.1641) Grad: 0.4995  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 7m 5s (remain 1m 36s) Loss: 0.1732(0.1640) Grad: 1.0571  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 7m 14s (remain 1m 27s) Loss: 0.0455(0.1635) Grad: 0.6600  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 7m 23s (remain 1m 18s) Loss: 0.2183(0.1635) Grad: 0.9646  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 7m 32s (remain 1m 10s) Loss: 0.1278(0.1633) Grad: 0.5457  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 7m 41s (remain 1m 1s) Loss: 0.1021(0.1632) Grad: 0.4079  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 7m 49s (remain 0m 52s) Loss: 0.2408(0.1631) Grad: 0.8513  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 7m 58s (remain 0m 43s) Loss: 0.1948(0.1632) Grad: 1.0533  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 8m 7s (remain 0m 34s) Loss: 0.1908(0.1632) Grad: 0.5703  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 8m 16s (remain 0m 25s) Loss: 0.1538(0.1632) Grad: 1.3183  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 8m 25s (remain 0m 16s) Loss: 0.2150(0.1628) Grad: 0.7917  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 8m 34s (remain 0m 7s) Loss: 0.0883(0.1626) Grad: 0.6145  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 8m 42s (remain 0m 0s) Loss: 0.1061(0.1623) Grad: 0.6210  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 48s) Loss: 0.1129(0.1129) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1440(0.1282) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.1700(0.1500) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.2663(0.1566) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.1729(0.1595) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1264(0.1623) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1549(0.1641) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1705(0.1609) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1301(0.1593) \n","f1 score : 0.44140969162995597\n","recall score : 0.3070323272560135\n","precision score : 0.7849588719153937\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.1623  avg_val_loss: 0.1593  time: 621s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1623  avg_val_loss: 0.1593  time: 621s\n","Epoch 2 - Score: 0.4414\n","INFO:__main__:Epoch 2 - Score: 0.4414\n","Epoch 2 - Save Best Score: 0.5352 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5352 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 40m 23s) Loss: 0.0698(0.0698) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 9s (remain 8m 48s) Loss: 0.1174(0.1446) Grad: 0.8527  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 18s (remain 8m 42s) Loss: 0.1876(0.1507) Grad: 1.4889  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 27s (remain 8m 34s) Loss: 0.1210(0.1478) Grad: 1.0454  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 0m 36s (remain 8m 20s) Loss: 0.2415(0.1527) Grad: 0.7968  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 0m 45s (remain 8m 8s) Loss: 0.3384(0.1529) Grad: 1.5579  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 0m 54s (remain 7m 57s) Loss: 0.0978(0.1537) Grad: 0.7124  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 3s (remain 7m 47s) Loss: 0.1279(0.1554) Grad: 1.0416  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 1m 12s (remain 7m 39s) Loss: 0.1315(0.1559) Grad: 1.2481  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 1m 21s (remain 7m 30s) Loss: 0.0799(0.1550) Grad: 1.0003  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 1m 30s (remain 7m 20s) Loss: 0.1573(0.1539) Grad: 0.7870  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 1m 38s (remain 7m 10s) Loss: 0.0492(0.1532) Grad: 0.8369  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 1m 47s (remain 7m 1s) Loss: 0.2015(0.1518) Grad: 0.7888  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 1m 56s (remain 6m 51s) Loss: 0.1875(0.1511) Grad: 0.8174  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 2m 5s (remain 6m 42s) Loss: 0.2529(0.1514) Grad: 1.2347  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 2m 14s (remain 6m 33s) Loss: 0.1311(0.1517) Grad: 0.9655  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 2m 23s (remain 6m 23s) Loss: 0.2067(0.1514) Grad: 0.7254  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 2m 32s (remain 6m 14s) Loss: 0.1150(0.1514) Grad: 0.4162  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 2m 41s (remain 6m 5s) Loss: 0.0644(0.1512) Grad: 1.0566  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 2m 49s (remain 5m 56s) Loss: 0.2766(0.1513) Grad: 1.2679  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 2m 58s (remain 5m 47s) Loss: 0.1421(0.1520) Grad: 0.6882  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 3m 7s (remain 5m 38s) Loss: 0.2756(0.1520) Grad: 0.9827  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 3m 16s (remain 5m 29s) Loss: 0.1014(0.1515) Grad: 0.5700  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 3m 25s (remain 5m 20s) Loss: 0.1957(0.1523) Grad: 0.9499  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 3m 34s (remain 5m 11s) Loss: 0.2183(0.1522) Grad: 1.1964  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 3m 43s (remain 5m 2s) Loss: 0.1566(0.1519) Grad: 0.6116  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 3m 51s (remain 4m 53s) Loss: 0.1508(0.1517) Grad: 0.9038  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 4m 0s (remain 4m 44s) Loss: 0.0881(0.1516) Grad: 0.9165  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 4m 9s (remain 4m 35s) Loss: 0.2759(0.1518) Grad: 1.2725  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 4m 18s (remain 4m 26s) Loss: 0.0841(0.1516) Grad: 0.4007  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 4m 27s (remain 4m 17s) Loss: 0.0819(0.1514) Grad: 0.5440  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 4m 35s (remain 4m 8s) Loss: 0.2083(0.1513) Grad: 0.9941  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 4m 44s (remain 3m 59s) Loss: 0.1194(0.1513) Grad: 0.6609  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 4m 53s (remain 3m 50s) Loss: 0.2925(0.1511) Grad: 1.5738  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 5m 2s (remain 3m 41s) Loss: 0.2520(0.1515) Grad: 1.2334  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 5m 11s (remain 3m 32s) Loss: 0.1581(0.1515) Grad: 0.8124  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 5m 20s (remain 3m 23s) Loss: 0.2200(0.1517) Grad: 0.8516  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 5m 29s (remain 3m 14s) Loss: 0.1158(0.1517) Grad: 0.5692  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 5m 38s (remain 3m 5s) Loss: 0.0776(0.1516) Grad: 1.2232  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 5m 46s (remain 2m 56s) Loss: 0.2251(0.1517) Grad: 1.1303  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 5m 55s (remain 2m 48s) Loss: 0.0906(0.1517) Grad: 0.8992  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 6m 4s (remain 2m 39s) Loss: 0.1379(0.1517) Grad: 1.1081  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 6m 13s (remain 2m 30s) Loss: 0.2698(0.1516) Grad: 1.1519  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 6m 22s (remain 2m 21s) Loss: 0.1129(0.1518) Grad: 0.7447  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 6m 30s (remain 2m 12s) Loss: 0.0755(0.1519) Grad: 0.6628  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 6m 39s (remain 2m 3s) Loss: 0.2976(0.1521) Grad: 1.9323  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 6m 48s (remain 1m 54s) Loss: 0.0990(0.1520) Grad: 0.6354  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 6m 57s (remain 1m 45s) Loss: 0.0539(0.1517) Grad: 0.9880  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 7m 6s (remain 1m 36s) Loss: 0.1874(0.1518) Grad: 0.8121  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 7m 15s (remain 1m 27s) Loss: 0.2112(0.1516) Grad: 0.9791  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 7m 24s (remain 1m 19s) Loss: 0.0792(0.1518) Grad: 1.1662  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 7m 32s (remain 1m 10s) Loss: 0.2313(0.1517) Grad: 1.0248  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 7m 41s (remain 1m 1s) Loss: 0.0613(0.1516) Grad: 0.5351  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 7m 50s (remain 0m 52s) Loss: 0.1160(0.1514) Grad: 0.3652  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 7m 59s (remain 0m 43s) Loss: 0.2056(0.1515) Grad: 1.6452  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 8m 8s (remain 0m 34s) Loss: 0.0914(0.1515) Grad: 0.6470  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 8m 17s (remain 0m 25s) Loss: 0.0975(0.1515) Grad: 0.9705  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 8m 26s (remain 0m 16s) Loss: 0.2188(0.1513) Grad: 1.0594  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 8m 35s (remain 0m 7s) Loss: 0.2303(0.1514) Grad: 1.0482  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 8m 43s (remain 0m 0s) Loss: 0.1812(0.1514) Grad: 0.6825  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 46s) Loss: 0.1166(0.1166) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1533(0.1270) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.1680(0.1465) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.2521(0.1518) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.1764(0.1548) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1187(0.1569) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1636(0.1586) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1520(0.1559) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1348(0.1544) \n","f1 score : 0.480891388107883\n","recall score : 0.3537612992186303\n","precision score : 0.7506501950585176\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1514  avg_val_loss: 0.1544  time: 622s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1514  avg_val_loss: 0.1544  time: 622s\n","Epoch 3 - Score: 0.4809\n","INFO:__main__:Epoch 3 - Score: 0.4809\n","Epoch 3 - Save Best Score: 0.5502 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5502 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 39m 43s) Loss: 0.1405(0.1405) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 9s (remain 9m 10s) Loss: 0.1536(0.1445) Grad: 0.9814  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 18s (remain 8m 57s) Loss: 0.1387(0.1491) Grad: 0.8059  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 28s (remain 8m 42s) Loss: 0.1721(0.1486) Grad: 0.7292  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 0m 37s (remain 8m 27s) Loss: 0.1946(0.1467) Grad: 1.2900  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 0m 45s (remain 8m 13s) Loss: 0.0979(0.1452) Grad: 0.4940  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 0m 54s (remain 8m 2s) Loss: 0.1467(0.1439) Grad: 1.0415  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 3s (remain 7m 51s) Loss: 0.1636(0.1440) Grad: 1.0207  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 1m 12s (remain 7m 40s) Loss: 0.1350(0.1419) Grad: 8.1935  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 1m 21s (remain 7m 30s) Loss: 0.1998(0.1414) Grad: 1.3594  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 1m 30s (remain 7m 20s) Loss: 0.1614(0.1417) Grad: 0.9115  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 1m 39s (remain 7m 11s) Loss: 0.0560(0.1420) Grad: 0.7100  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 1m 48s (remain 7m 2s) Loss: 0.1520(0.1413) Grad: 0.8948  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 1m 57s (remain 6m 53s) Loss: 0.1869(0.1411) Grad: 1.0543  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 2m 5s (remain 6m 43s) Loss: 0.1401(0.1411) Grad: 0.7573  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 2m 14s (remain 6m 34s) Loss: 0.1732(0.1411) Grad: 0.8257  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 2m 23s (remain 6m 25s) Loss: 0.0573(0.1410) Grad: 0.5843  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 2m 32s (remain 6m 15s) Loss: 0.1270(0.1405) Grad: 0.9049  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 2m 41s (remain 6m 6s) Loss: 0.1241(0.1402) Grad: 0.9561  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 2m 50s (remain 5m 57s) Loss: 0.1327(0.1403) Grad: 1.7278  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 2m 58s (remain 5m 47s) Loss: 0.2666(0.1404) Grad: 1.8842  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 3m 7s (remain 5m 38s) Loss: 0.2272(0.1405) Grad: 1.8929  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 3m 16s (remain 5m 29s) Loss: 0.2405(0.1403) Grad: 1.7013  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 3m 25s (remain 5m 20s) Loss: 0.1339(0.1405) Grad: 1.2160  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 3m 34s (remain 5m 11s) Loss: 0.0588(0.1404) Grad: 0.9218  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 3m 43s (remain 5m 2s) Loss: 0.2340(0.1408) Grad: 1.3679  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 3m 52s (remain 4m 53s) Loss: 0.1101(0.1413) Grad: 1.3017  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 4m 1s (remain 4m 44s) Loss: 0.0925(0.1416) Grad: 0.7033  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 4m 10s (remain 4m 35s) Loss: 0.1797(0.1416) Grad: 0.9728  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 4m 18s (remain 4m 26s) Loss: 0.1429(0.1418) Grad: 0.6909  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 4m 27s (remain 4m 17s) Loss: 0.2544(0.1418) Grad: 0.9576  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 4m 36s (remain 4m 8s) Loss: 0.0978(0.1420) Grad: 1.4179  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 4m 45s (remain 3m 59s) Loss: 0.1411(0.1425) Grad: 1.0934  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 4m 54s (remain 3m 50s) Loss: 0.1696(0.1423) Grad: 1.2770  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 5m 3s (remain 3m 41s) Loss: 0.2340(0.1425) Grad: 0.9261  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 5m 12s (remain 3m 33s) Loss: 0.1412(0.1425) Grad: 0.7111  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 5m 20s (remain 3m 24s) Loss: 0.1084(0.1425) Grad: 1.1626  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 5m 29s (remain 3m 15s) Loss: 0.0732(0.1429) Grad: 0.5262  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 5m 38s (remain 3m 6s) Loss: 0.1517(0.1429) Grad: 0.8157  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 5m 47s (remain 2m 57s) Loss: 0.1206(0.1429) Grad: 0.6073  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 5m 56s (remain 2m 48s) Loss: 0.0460(0.1428) Grad: 1.1878  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 6m 5s (remain 2m 39s) Loss: 0.0594(0.1429) Grad: 0.7231  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 6m 14s (remain 2m 30s) Loss: 0.0716(0.1427) Grad: 1.0624  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 6m 22s (remain 2m 21s) Loss: 0.1495(0.1423) Grad: 0.6397  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 6m 31s (remain 2m 12s) Loss: 0.1324(0.1425) Grad: 1.2068  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 6m 40s (remain 2m 3s) Loss: 0.1781(0.1426) Grad: 1.0875  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 6m 49s (remain 1m 54s) Loss: 0.0562(0.1426) Grad: 1.1417  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 6m 58s (remain 1m 45s) Loss: 0.1104(0.1425) Grad: 0.7405  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 7m 6s (remain 1m 36s) Loss: 0.1127(0.1423) Grad: 0.7418  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 7m 15s (remain 1m 28s) Loss: 0.0328(0.1423) Grad: 0.7429  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 7m 24s (remain 1m 19s) Loss: 0.2209(0.1423) Grad: 1.6890  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 7m 33s (remain 1m 10s) Loss: 0.1338(0.1423) Grad: 0.6601  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 7m 42s (remain 1m 1s) Loss: 0.1846(0.1426) Grad: 0.9438  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 7m 51s (remain 0m 52s) Loss: 0.3445(0.1426) Grad: 2.3870  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 8m 0s (remain 0m 43s) Loss: 0.1970(0.1427) Grad: 0.9588  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 8m 8s (remain 0m 34s) Loss: 0.1272(0.1427) Grad: 0.9251  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 8m 17s (remain 0m 25s) Loss: 0.0633(0.1426) Grad: 1.5177  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 8m 26s (remain 0m 16s) Loss: 0.0621(0.1425) Grad: 0.7851  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 8m 35s (remain 0m 8s) Loss: 0.1986(0.1424) Grad: 0.9211  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 8m 43s (remain 0m 0s) Loss: 0.1580(0.1424) Grad: 0.8743  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 43s) Loss: 0.1082(0.1082) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1435(0.1266) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.1813(0.1459) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.2605(0.1512) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.1731(0.1545) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1160(0.1568) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1695(0.1587) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1522(0.1563) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1363(0.1549) \n","f1 score : 0.5079022283302248\n","recall score : 0.3963536080894745\n","precision score : 0.7068306010928962\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1424  avg_val_loss: 0.1549  time: 623s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1424  avg_val_loss: 0.1549  time: 623s\n","Epoch 4 - Score: 0.5079\n","INFO:__main__:Epoch 4 - Score: 0.5079\n","Epoch 4 - Save Best Score: 0.5539 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.5539 Model\n","========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.5079022283302248\n","recall score : 0.3963536080894745\n","precision score : 0.7068306010928962\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.5079\n","INFO:__main__:Score: 0.5079\n","F1 BEST Score: 0.5539\n","INFO:__main__:F1 BEST Score: 0.5539\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 0s (remain 41m 38s) Loss: 0.5479(0.5479) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 9s (remain 9m 16s) Loss: 0.3242(0.2608) Grad: 1.2394  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 19s (remain 9m 1s) Loss: 0.1287(0.2391) Grad: 1.8245  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 28s (remain 8m 40s) Loss: 0.1863(0.2317) Grad: 0.8837  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 0m 36s (remain 8m 26s) Loss: 0.2483(0.2284) Grad: 1.0017  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 0m 45s (remain 8m 13s) Loss: 0.3113(0.2246) Grad: 0.8633  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 0m 54s (remain 8m 2s) Loss: 0.1897(0.2224) Grad: 0.3128  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 3s (remain 7m 51s) Loss: 0.1852(0.2217) Grad: 0.9894  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 1m 12s (remain 7m 41s) Loss: 0.1954(0.2194) Grad: 0.3461  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 1m 21s (remain 7m 31s) Loss: 0.2107(0.2189) Grad: 0.7844  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 1m 30s (remain 7m 22s) Loss: 0.2418(0.2183) Grad: 0.6999  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 1m 39s (remain 7m 12s) Loss: 0.4348(0.2159) Grad: 2.2117  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 1m 48s (remain 7m 2s) Loss: 0.1526(0.2140) Grad: 0.6147  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 1m 57s (remain 6m 53s) Loss: 0.1130(0.2130) Grad: 0.8738  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 2m 6s (remain 6m 43s) Loss: 0.1781(0.2108) Grad: 0.6921  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 2m 15s (remain 6m 34s) Loss: 0.2134(0.2104) Grad: 0.5979  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 2m 23s (remain 6m 25s) Loss: 0.1000(0.2097) Grad: 1.0098  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 2m 32s (remain 6m 16s) Loss: 0.1904(0.2093) Grad: 0.8113  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 2m 41s (remain 6m 7s) Loss: 0.2145(0.2087) Grad: 0.9527  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 2m 50s (remain 5m 58s) Loss: 0.1527(0.2072) Grad: 0.4141  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 2m 59s (remain 5m 49s) Loss: 0.1931(0.2082) Grad: 0.6713  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 3m 8s (remain 5m 40s) Loss: 0.3579(0.2110) Grad: 1.2940  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 3m 17s (remain 5m 30s) Loss: 0.0625(0.2127) Grad: 1.7753  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 3m 26s (remain 5m 21s) Loss: 0.1447(0.2136) Grad: 0.6167  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 3m 35s (remain 5m 12s) Loss: 0.1903(0.2148) Grad: 0.2333  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 3m 44s (remain 5m 3s) Loss: 0.4011(0.2160) Grad: 1.7582  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 3m 52s (remain 4m 54s) Loss: 0.2338(0.2169) Grad: 0.0754  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 4m 1s (remain 4m 45s) Loss: 0.3208(0.2183) Grad: 1.0086  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 4m 10s (remain 4m 36s) Loss: 0.2783(0.2196) Grad: 0.6103  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 4m 19s (remain 4m 27s) Loss: 0.2349(0.2203) Grad: 0.2619  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 4m 28s (remain 4m 18s) Loss: 0.2352(0.2214) Grad: 0.4291  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 4m 37s (remain 4m 9s) Loss: 0.2340(0.2227) Grad: 0.0383  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 4m 46s (remain 4m 0s) Loss: 0.1179(0.2241) Grad: 1.6999  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 4m 55s (remain 3m 51s) Loss: 0.3574(0.2251) Grad: 1.1881  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 5m 3s (remain 3m 42s) Loss: 0.3210(0.2260) Grad: 1.0237  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 5m 12s (remain 3m 33s) Loss: 0.1921(0.2266) Grad: 0.4747  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 5m 21s (remain 3m 24s) Loss: 0.2751(0.2270) Grad: 0.3254  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 5m 30s (remain 3m 15s) Loss: 0.3174(0.2277) Grad: 0.7991  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 5m 39s (remain 3m 6s) Loss: 0.1215(0.2285) Grad: 1.8018  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 5m 48s (remain 2m 57s) Loss: 0.2749(0.2289) Grad: 0.3201  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 5m 57s (remain 2m 48s) Loss: 0.1108(0.2295) Grad: 1.4584  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 6m 6s (remain 2m 39s) Loss: 0.3525(0.2300) Grad: 0.9586  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 6m 15s (remain 2m 30s) Loss: 0.1013(0.2304) Grad: 1.1138  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 6m 24s (remain 2m 22s) Loss: 0.2742(0.2310) Grad: 0.0210  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 6m 33s (remain 2m 13s) Loss: 0.2343(0.2315) Grad: 0.2455  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 6m 42s (remain 2m 4s) Loss: 0.1115(0.2322) Grad: 1.4711  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 6m 51s (remain 1m 55s) Loss: 0.3149(0.2327) Grad: 0.6622  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 7m 0s (remain 1m 46s) Loss: 0.3521(0.2334) Grad: 0.9180  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 7m 8s (remain 1m 37s) Loss: 0.2751(0.2339) Grad: 0.3431  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 7m 17s (remain 1m 28s) Loss: 0.3564(0.2341) Grad: 1.1487  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 7m 26s (remain 1m 19s) Loss: 0.2339(0.2346) Grad: 0.1413  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 7m 35s (remain 1m 10s) Loss: 0.2744(0.2350) Grad: 0.1349  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 7m 44s (remain 1m 1s) Loss: 0.1531(0.2353) Grad: 1.0493  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 7m 53s (remain 0m 52s) Loss: 0.2749(0.2358) Grad: 0.2955  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 8m 2s (remain 0m 43s) Loss: 0.2340(0.2362) Grad: 0.0121  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 8m 11s (remain 0m 34s) Loss: 0.1517(0.2365) Grad: 1.0182  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 8m 20s (remain 0m 25s) Loss: 0.2343(0.2368) Grad: 0.2607  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 8m 29s (remain 0m 16s) Loss: 0.2773(0.2368) Grad: 0.5795  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 8m 38s (remain 0m 8s) Loss: 0.2346(0.2371) Grad: 0.3304  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 8m 46s (remain 0m 0s) Loss: 0.2338(0.2372) Grad: 0.0441  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 45s) Loss: 0.2338(0.2338) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.2548(0.1968) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.3599(0.2388) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.3599(0.2589) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.2338(0.2611) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.2758(0.2638) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.2128(0.2619) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1918(0.2549) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1217(0.2519) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.2372  avg_val_loss: 0.2519  time: 625s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.2372  avg_val_loss: 0.2519  time: 625s\n","Epoch 1 - Score: 0.0000\n","INFO:__main__:Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.0000 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 37m 24s) Loss: 0.2343(0.2343) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 9s (remain 8m 53s) Loss: 0.2764(0.2294) Grad: 0.4476  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 18s (remain 8m 37s) Loss: 0.1941(0.2379) Grad: 0.6678  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 27s (remain 8m 29s) Loss: 0.1514(0.2434) Grad: 0.9862  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 0m 36s (remain 8m 20s) Loss: 0.2343(0.2415) Grad: 0.0304  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 0m 45s (remain 8m 8s) Loss: 0.1921(0.2421) Grad: 0.4993  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 0m 54s (remain 7m 57s) Loss: 0.1503(0.2460) Grad: 0.9418  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 3s (remain 7m 47s) Loss: 0.2742(0.2472) Grad: 0.2179  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 1m 12s (remain 7m 37s) Loss: 0.4380(0.2474) Grad: 2.0036  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 1m 20s (remain 7m 28s) Loss: 0.1953(0.2485) Grad: 0.7625  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 1m 29s (remain 7m 18s) Loss: 0.3147(0.2485) Grad: 0.6369  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 1m 38s (remain 7m 9s) Loss: 0.2783(0.2472) Grad: 0.6108  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 1m 47s (remain 6m 59s) Loss: 0.1917(0.2471) Grad: 0.4510  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 1m 56s (remain 6m 50s) Loss: 0.2756(0.2463) Grad: 0.3918  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 2m 5s (remain 6m 41s) Loss: 0.2754(0.2467) Grad: 0.3493  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 2m 14s (remain 6m 32s) Loss: 0.1923(0.2459) Grad: 0.4949  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 2m 22s (remain 6m 23s) Loss: 0.3625(0.2458) Grad: 1.3744  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 2m 31s (remain 6m 13s) Loss: 0.1924(0.2450) Grad: 0.4917  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 2m 40s (remain 6m 4s) Loss: 0.1915(0.2448) Grad: 0.4884  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 2m 49s (remain 5m 55s) Loss: 0.1609(0.2456) Grad: 1.3965  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 2m 58s (remain 5m 46s) Loss: 0.4387(0.2456) Grad: 2.0321  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 3m 7s (remain 5m 37s) Loss: 0.2744(0.2454) Grad: 0.1817  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 3m 16s (remain 5m 28s) Loss: 0.3145(0.2459) Grad: 0.6169  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 3m 25s (remain 5m 19s) Loss: 0.3533(0.2468) Grad: 0.9674  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 3m 33s (remain 5m 10s) Loss: 0.1931(0.2471) Grad: 0.6002  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 3m 42s (remain 5m 1s) Loss: 0.2744(0.2472) Grad: 0.2674  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 3m 51s (remain 4m 53s) Loss: 0.3145(0.2476) Grad: 0.6167  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 4m 0s (remain 4m 44s) Loss: 0.1165(0.2478) Grad: 1.6254  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 4m 9s (remain 4m 35s) Loss: 0.2747(0.2478) Grad: 0.2903  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 4m 18s (remain 4m 26s) Loss: 0.2742(0.2480) Grad: 0.1920  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 4m 27s (remain 4m 17s) Loss: 0.1941(0.2480) Grad: 0.6665  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 4m 36s (remain 4m 8s) Loss: 0.2339(0.2482) Grad: 0.1136  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 4m 45s (remain 3m 59s) Loss: 0.1536(0.2485) Grad: 1.0659  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 4m 54s (remain 3m 50s) Loss: 0.1230(0.2491) Grad: 1.8356  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 5m 2s (remain 3m 41s) Loss: 0.3171(0.2493) Grad: 0.8040  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 5m 11s (remain 3m 32s) Loss: 0.2339(0.2494) Grad: 0.1408  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 5m 20s (remain 3m 23s) Loss: 0.1927(0.2494) Grad: 0.5120  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 5m 29s (remain 3m 14s) Loss: 0.1934(0.2495) Grad: 0.5896  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 5m 38s (remain 3m 5s) Loss: 0.3127(0.2501) Grad: 0.4289  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 5m 47s (remain 2m 57s) Loss: 0.2747(0.2503) Grad: 0.1624  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 5m 55s (remain 2m 48s) Loss: 0.2346(0.2503) Grad: 0.2239  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 6m 4s (remain 2m 39s) Loss: 0.2340(0.2502) Grad: 0.1375  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 6m 13s (remain 2m 30s) Loss: 0.1539(0.2502) Grad: 1.0980  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 6m 22s (remain 2m 21s) Loss: 0.2754(0.2500) Grad: 0.3072  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 6m 31s (remain 2m 12s) Loss: 0.2754(0.2500) Grad: 0.3038  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 6m 40s (remain 2m 3s) Loss: 0.1913(0.2500) Grad: 0.4623  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 6m 49s (remain 1m 54s) Loss: 0.3149(0.2504) Grad: 0.6419  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 6m 57s (remain 1m 45s) Loss: 0.2354(0.2505) Grad: 0.3638  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 7m 6s (remain 1m 36s) Loss: 0.1952(0.2506) Grad: 0.7644  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 7m 15s (remain 1m 27s) Loss: 0.2341(0.2508) Grad: 0.2111  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 7m 24s (remain 1m 19s) Loss: 0.3953(0.2509) Grad: 1.5087  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 7m 33s (remain 1m 10s) Loss: 0.2344(0.2509) Grad: 0.1271  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 7m 42s (remain 1m 1s) Loss: 0.1539(0.2508) Grad: 1.1005  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 7m 51s (remain 0m 52s) Loss: 0.1931(0.2508) Grad: 0.5660  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 8m 0s (remain 0m 43s) Loss: 0.2352(0.2509) Grad: 0.3686  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 8m 9s (remain 0m 34s) Loss: 0.3931(0.2512) Grad: 1.4360  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 8m 18s (remain 0m 25s) Loss: 0.2358(0.2514) Grad: 0.4332  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 8m 26s (remain 0m 16s) Loss: 0.1935(0.2516) Grad: 0.6524  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 8m 35s (remain 0m 8s) Loss: 0.2336(0.2515) Grad: 0.0967  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 8m 43s (remain 0m 0s) Loss: 0.1592(0.2518) Grad: 1.3300  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 35s) Loss: 0.2357(0.2357) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.2550(0.2019) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.3510(0.2403) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.3510(0.2587) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.2357(0.2607) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.2742(0.2632) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.2165(0.2614) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1973(0.2550) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1333(0.2523) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.2518  avg_val_loss: 0.2523  time: 623s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.2518  avg_val_loss: 0.2523  time: 623s\n","Epoch 2 - Score: 0.0000\n","INFO:__main__:Epoch 2 - Score: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 38m 3s) Loss: 0.1978(0.1978) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 9s (remain 8m 51s) Loss: 0.1080(0.2415) Grad: 1.3544  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 18s (remain 8m 34s) Loss: 0.3159(0.2467) Grad: 0.6948  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 27s (remain 8m 22s) Loss: 0.3137(0.2512) Grad: 0.5618  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 0m 35s (remain 8m 11s) Loss: 0.2345(0.2535) Grad: 0.3078  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 0m 44s (remain 8m 1s) Loss: 0.1129(0.2535) Grad: 1.5153  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 0m 53s (remain 7m 51s) Loss: 0.2744(0.2556) Grad: 0.1343  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 2s (remain 7m 42s) Loss: 0.2749(0.2541) Grad: 0.2734  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 1m 11s (remain 7m 32s) Loss: 0.2742(0.2561) Grad: 0.0862  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 1m 20s (remain 7m 23s) Loss: 0.1538(0.2557) Grad: 1.1039  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 1m 28s (remain 7m 14s) Loss: 0.1501(0.2551) Grad: 0.9036  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 1m 37s (remain 7m 5s) Loss: 0.2341(0.2546) Grad: 0.0831  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 1m 46s (remain 6m 56s) Loss: 0.3154(0.2547) Grad: 0.6492  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 1m 55s (remain 6m 47s) Loss: 0.1521(0.2537) Grad: 0.9969  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 2m 4s (remain 6m 39s) Loss: 0.3152(0.2535) Grad: 0.6460  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 2m 13s (remain 6m 30s) Loss: 0.1924(0.2534) Grad: 0.5588  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 2m 22s (remain 6m 21s) Loss: 0.2766(0.2519) Grad: 0.4492  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 2m 31s (remain 6m 12s) Loss: 0.3147(0.2521) Grad: 0.6521  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 2m 40s (remain 6m 3s) Loss: 0.1542(0.2521) Grad: 1.1326  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 2m 48s (remain 5m 54s) Loss: 0.1938(0.2518) Grad: 0.6066  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 2m 57s (remain 5m 45s) Loss: 0.2749(0.2516) Grad: 0.2942  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 3m 6s (remain 5m 36s) Loss: 0.1924(0.2515) Grad: 0.5587  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 3m 15s (remain 5m 28s) Loss: 0.1934(0.2514) Grad: 0.6235  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 3m 24s (remain 5m 19s) Loss: 0.1510(0.2511) Grad: 0.9562  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 3m 33s (remain 5m 10s) Loss: 0.2335(0.2507) Grad: 0.0726  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 3m 42s (remain 5m 1s) Loss: 0.1936(0.2507) Grad: 0.6162  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 3m 51s (remain 4m 52s) Loss: 0.2744(0.2509) Grad: 0.2205  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 3m 59s (remain 4m 43s) Loss: 0.2751(0.2508) Grad: 0.3245  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 4m 8s (remain 4m 34s) Loss: 0.3157(0.2508) Grad: 0.7247  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 4m 17s (remain 4m 25s) Loss: 0.1947(0.2510) Grad: 0.7099  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 4m 26s (remain 4m 16s) Loss: 0.3945(0.2511) Grad: 1.4856  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 4m 35s (remain 4m 7s) Loss: 0.1941(0.2512) Grad: 0.6314  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 4m 44s (remain 3m 58s) Loss: 0.1545(0.2515) Grad: 1.1158  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 4m 53s (remain 3m 49s) Loss: 0.1930(0.2514) Grad: 0.5691  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 5m 1s (remain 3m 41s) Loss: 0.1952(0.2517) Grad: 0.7313  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 5m 10s (remain 3m 32s) Loss: 0.2344(0.2517) Grad: 0.2309  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 5m 20s (remain 3m 23s) Loss: 0.3142(0.2519) Grad: 0.6098  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 5m 28s (remain 3m 14s) Loss: 0.3533(0.2522) Grad: 0.9659  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 5m 37s (remain 3m 5s) Loss: 0.3569(0.2521) Grad: 1.1639  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 5m 46s (remain 2m 56s) Loss: 0.2744(0.2519) Grad: 0.2430  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 5m 55s (remain 2m 47s) Loss: 0.2341(0.2521) Grad: 0.2884  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 6m 4s (remain 2m 39s) Loss: 0.1946(0.2523) Grad: 0.7168  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 6m 13s (remain 2m 30s) Loss: 0.1541(0.2523) Grad: 1.0899  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 6m 22s (remain 2m 21s) Loss: 0.2744(0.2524) Grad: 0.2236  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 6m 31s (remain 2m 12s) Loss: 0.1549(0.2526) Grad: 1.1476  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 6m 39s (remain 2m 3s) Loss: 0.1929(0.2524) Grad: 0.5722  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 6m 48s (remain 1m 54s) Loss: 0.1917(0.2519) Grad: 0.4500  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 6m 57s (remain 1m 45s) Loss: 0.2759(0.2518) Grad: 0.3580  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 7m 6s (remain 1m 36s) Loss: 0.1499(0.2515) Grad: 0.9136  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 7m 15s (remain 1m 27s) Loss: 0.2341(0.2514) Grad: 0.0832  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 7m 24s (remain 1m 19s) Loss: 0.1925(0.2512) Grad: 0.5179  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 7m 33s (remain 1m 10s) Loss: 0.3535(0.2516) Grad: 0.9886  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 7m 42s (remain 1m 1s) Loss: 0.2343(0.2516) Grad: 0.2341  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 7m 51s (remain 0m 52s) Loss: 0.2345(0.2515) Grad: 0.1711  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 8m 0s (remain 0m 43s) Loss: 0.2343(0.2516) Grad: 0.2070  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 8m 9s (remain 0m 34s) Loss: 0.2345(0.2516) Grad: 0.1990  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 8m 18s (remain 0m 25s) Loss: 0.3154(0.2517) Grad: 0.6703  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 8m 26s (remain 0m 16s) Loss: 0.3152(0.2517) Grad: 0.6809  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 8m 35s (remain 0m 8s) Loss: 0.3557(0.2517) Grad: 1.1137  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 8m 43s (remain 0m 0s) Loss: 0.3555(0.2517) Grad: 1.0974  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 42s) Loss: 0.2342(0.2342) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.2544(0.1986) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.3555(0.2391) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.3555(0.2584) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.2342(0.2605) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.2747(0.2631) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.2140(0.2613) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1938(0.2545) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1264(0.2517) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.2517  avg_val_loss: 0.2517  time: 623s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.2517  avg_val_loss: 0.2517  time: 623s\n","Epoch 3 - Score: 0.0000\n","INFO:__main__:Epoch 3 - Score: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 38m 5s) Loss: 0.2747(0.2747) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 9s (remain 8m 53s) Loss: 0.3145(0.2547) Grad: 0.6520  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 18s (remain 8m 36s) Loss: 0.3950(0.2560) Grad: 1.5049  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 27s (remain 8m 24s) Loss: 0.1528(0.2521) Grad: 1.0548  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 0m 36s (remain 8m 14s) Loss: 0.4407(0.2490) Grad: 2.0733  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 0m 45s (remain 8m 4s) Loss: 0.2345(0.2513) Grad: 0.1990  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 0m 53s (remain 7m 55s) Loss: 0.1136(0.2526) Grad: 1.5350  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 2s (remain 7m 45s) Loss: 0.3157(0.2523) Grad: 0.6747  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 1m 11s (remain 7m 36s) Loss: 0.3584(0.2499) Grad: 1.2318  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 1m 20s (remain 7m 26s) Loss: 0.2754(0.2504) Grad: 0.3036  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 1m 29s (remain 7m 17s) Loss: 0.1108(0.2500) Grad: 1.4486  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 1m 38s (remain 7m 8s) Loss: 0.3162(0.2495) Grad: 0.7519  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 1m 47s (remain 6m 59s) Loss: 0.1523(0.2495) Grad: 1.0276  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 1m 56s (remain 6m 49s) Loss: 0.3574(0.2490) Grad: 1.1864  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 2m 5s (remain 6m 40s) Loss: 0.3164(0.2488) Grad: 0.7382  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 2m 13s (remain 6m 31s) Loss: 0.2751(0.2498) Grad: 0.2398  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 2m 22s (remain 6m 22s) Loss: 0.2338(0.2494) Grad: 0.1678  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 2m 31s (remain 6m 13s) Loss: 0.3569(0.2497) Grad: 1.1321  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 2m 40s (remain 6m 4s) Loss: 0.2345(0.2499) Grad: 0.1990  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 2m 49s (remain 5m 55s) Loss: 0.1931(0.2497) Grad: 0.5994  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 2m 58s (remain 5m 46s) Loss: 0.1130(0.2502) Grad: 1.4994  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 3m 7s (remain 5m 37s) Loss: 0.1528(0.2501) Grad: 1.0581  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 3m 16s (remain 5m 28s) Loss: 0.3159(0.2501) Grad: 0.6927  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 3m 24s (remain 5m 19s) Loss: 0.1934(0.2503) Grad: 0.6251  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 3m 33s (remain 5m 10s) Loss: 0.3965(0.2506) Grad: 1.5396  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 3m 42s (remain 5m 1s) Loss: 0.3145(0.2508) Grad: 0.6521  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 3m 51s (remain 4m 52s) Loss: 0.2339(0.2509) Grad: 0.2173  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 4m 0s (remain 4m 43s) Loss: 0.3560(0.2508) Grad: 1.1050  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 4m 9s (remain 4m 35s) Loss: 0.1531(0.2504) Grad: 1.0411  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 4m 18s (remain 4m 26s) Loss: 0.2341(0.2506) Grad: 0.1826  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 4m 27s (remain 4m 17s) Loss: 0.2341(0.2507) Grad: 0.1855  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 4m 36s (remain 4m 8s) Loss: 0.2749(0.2509) Grad: 0.2356  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 4m 45s (remain 3m 59s) Loss: 0.3154(0.2507) Grad: 0.6846  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 4m 53s (remain 3m 50s) Loss: 0.0707(0.2503) Grad: 1.9072  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 5m 2s (remain 3m 41s) Loss: 0.2751(0.2506) Grad: 0.2597  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 5m 11s (remain 3m 32s) Loss: 0.2344(0.2507) Grad: 0.1782  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 5m 20s (remain 3m 23s) Loss: 0.3149(0.2510) Grad: 0.6776  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 5m 29s (remain 3m 15s) Loss: 0.2744(0.2514) Grad: 0.2236  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 5m 38s (remain 3m 6s) Loss: 0.3550(0.2516) Grad: 1.0893  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 5m 47s (remain 2m 57s) Loss: 0.3147(0.2516) Grad: 0.6535  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 5m 56s (remain 2m 48s) Loss: 0.1541(0.2518) Grad: 1.0934  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 6m 5s (remain 2m 39s) Loss: 0.1943(0.2520) Grad: 0.6585  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 6m 13s (remain 2m 30s) Loss: 0.3555(0.2521) Grad: 1.0807  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 6m 22s (remain 2m 21s) Loss: 0.3550(0.2519) Grad: 1.0867  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 6m 31s (remain 2m 12s) Loss: 0.2340(0.2518) Grad: 0.2142  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 6m 40s (remain 2m 3s) Loss: 0.2744(0.2520) Grad: 0.2205  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 6m 49s (remain 1m 54s) Loss: 0.1935(0.2521) Grad: 0.6521  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 6m 58s (remain 1m 45s) Loss: 0.3552(0.2521) Grad: 1.0899  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 7m 7s (remain 1m 36s) Loss: 0.2340(0.2520) Grad: 0.2142  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 7m 15s (remain 1m 28s) Loss: 0.2744(0.2520) Grad: 0.2205  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 7m 24s (remain 1m 19s) Loss: 0.2744(0.2519) Grad: 0.2214  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 7m 33s (remain 1m 10s) Loss: 0.1129(0.2518) Grad: 1.5149  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 7m 42s (remain 1m 1s) Loss: 0.1937(0.2519) Grad: 0.6456  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 7m 51s (remain 0m 52s) Loss: 0.2341(0.2518) Grad: 0.2110  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 8m 0s (remain 0m 43s) Loss: 0.1533(0.2516) Grad: 1.0803  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 8m 9s (remain 0m 34s) Loss: 0.4360(0.2516) Grad: 1.9620  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 8m 18s (remain 0m 25s) Loss: 0.2341(0.2516) Grad: 0.2110  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 8m 27s (remain 0m 16s) Loss: 0.2744(0.2516) Grad: 0.2236  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 8m 36s (remain 0m 8s) Loss: 0.4766(0.2519) Grad: 2.3968  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 8m 44s (remain 0m 0s) Loss: 0.3149(0.2517) Grad: 0.6583  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 46s) Loss: 0.2342(0.2342) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.2544(0.1986) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.3555(0.2391) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.3555(0.2584) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.2342(0.2605) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.2747(0.2631) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.2140(0.2613) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1938(0.2545) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.1265(0.2517) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.2517  avg_val_loss: 0.2517  time: 623s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.2517  avg_val_loss: 0.2517  time: 623s\n","Epoch 4 - Score: 0.0000\n","INFO:__main__:Epoch 4 - Score: 0.0000\n","========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.0000\n","INFO:__main__:Score: 0.0000\n","F1 BEST Score: 0.0000\n","INFO:__main__:F1 BEST Score: 0.0000\n","========== fold: 4 training ==========\n","INFO:__main__:========== fold: 4 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 0s (remain 41m 55s) Loss: 0.7554(0.7554) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 9s (remain 8m 53s) Loss: 0.3694(0.2707) Grad: 2.2052  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 18s (remain 8m 34s) Loss: 0.2903(0.2439) Grad: 2.1884  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 27s (remain 8m 23s) Loss: 0.2378(0.2327) Grad: 0.7689  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 0m 35s (remain 8m 12s) Loss: 0.2012(0.2298) Grad: 0.4638  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 0m 44s (remain 8m 3s) Loss: 0.2426(0.2274) Grad: 0.9667  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 0m 53s (remain 7m 54s) Loss: 0.1608(0.2238) Grad: 1.1020  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 2s (remain 7m 44s) Loss: 0.0923(0.2207) Grad: 1.2714  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 1m 11s (remain 7m 35s) Loss: 0.1227(0.2198) Grad: 1.4426  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 1m 20s (remain 7m 26s) Loss: 0.2250(0.2199) Grad: 0.4523  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 1m 29s (remain 7m 17s) Loss: 0.2322(0.2186) Grad: 1.2714  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 1m 38s (remain 7m 7s) Loss: 0.1148(0.2169) Grad: 1.0416  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 1m 47s (remain 6m 58s) Loss: 0.2812(0.2151) Grad: 1.8103  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 1m 56s (remain 6m 49s) Loss: 0.1081(0.2140) Grad: 0.6782  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 2m 4s (remain 6m 40s) Loss: 0.1587(0.2130) Grad: 0.6863  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 2m 13s (remain 6m 31s) Loss: 0.1681(0.2111) Grad: 0.5288  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 2m 22s (remain 6m 22s) Loss: 0.1107(0.2115) Grad: 0.5548  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 2m 31s (remain 6m 13s) Loss: 0.1552(0.2107) Grad: 0.5837  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 2m 40s (remain 6m 5s) Loss: 0.2881(0.2097) Grad: 0.9782  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 2m 49s (remain 5m 56s) Loss: 0.1527(0.2082) Grad: 0.7252  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 2m 58s (remain 5m 47s) Loss: 0.2125(0.2080) Grad: 0.6617  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 3m 7s (remain 5m 38s) Loss: 0.1283(0.2072) Grad: 0.5368  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 3m 16s (remain 5m 29s) Loss: 0.2720(0.2068) Grad: 0.6224  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 3m 25s (remain 5m 20s) Loss: 0.2004(0.2065) Grad: 1.0922  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 3m 34s (remain 5m 11s) Loss: 0.1901(0.2057) Grad: 0.6531  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 3m 43s (remain 5m 2s) Loss: 0.0851(0.2051) Grad: 1.8138  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 3m 52s (remain 4m 53s) Loss: 0.1854(0.2048) Grad: 0.5969  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 4m 1s (remain 4m 44s) Loss: 0.1515(0.2041) Grad: 0.6197  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 4m 10s (remain 4m 35s) Loss: 0.2096(0.2037) Grad: 0.4920  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 4m 18s (remain 4m 26s) Loss: 0.1781(0.2031) Grad: 0.9477  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 4m 27s (remain 4m 17s) Loss: 0.0986(0.2026) Grad: 0.6042  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 4m 36s (remain 4m 8s) Loss: 0.2505(0.2020) Grad: 0.8671  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 4m 45s (remain 4m 0s) Loss: 0.1031(0.2014) Grad: 0.4808  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 4m 54s (remain 3m 51s) Loss: 0.1309(0.2011) Grad: 0.5356  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 5m 3s (remain 3m 42s) Loss: 0.1617(0.2005) Grad: 0.8815  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 5m 12s (remain 3m 33s) Loss: 0.2424(0.1996) Grad: 0.6989  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 5m 21s (remain 3m 24s) Loss: 0.1747(0.1993) Grad: 0.6130  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 5m 30s (remain 3m 15s) Loss: 0.2981(0.1986) Grad: 1.6313  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 5m 39s (remain 3m 6s) Loss: 0.3059(0.1983) Grad: 1.9648  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 5m 47s (remain 2m 57s) Loss: 0.3074(0.1981) Grad: 1.1135  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 5m 56s (remain 2m 48s) Loss: 0.2261(0.1975) Grad: 1.6263  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 6m 5s (remain 2m 39s) Loss: 0.1060(0.1971) Grad: 1.2566  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 6m 14s (remain 2m 30s) Loss: 0.1486(0.1966) Grad: 1.0919  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 6m 23s (remain 2m 21s) Loss: 0.1533(0.1960) Grad: 0.5282  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 6m 32s (remain 2m 12s) Loss: 0.1492(0.1955) Grad: 1.0396  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 6m 41s (remain 2m 3s) Loss: 0.1370(0.1951) Grad: 0.6565  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 6m 49s (remain 1m 54s) Loss: 0.1034(0.1947) Grad: 0.7070  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 6m 58s (remain 1m 45s) Loss: 0.3254(0.1944) Grad: 0.9789  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 7m 7s (remain 1m 37s) Loss: 0.1781(0.1942) Grad: 0.7106  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 7m 16s (remain 1m 28s) Loss: 0.1147(0.1939) Grad: 0.4372  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 7m 25s (remain 1m 19s) Loss: 0.0793(0.1936) Grad: 1.0276  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 7m 34s (remain 1m 10s) Loss: 0.1200(0.1931) Grad: 0.6160  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 7m 43s (remain 1m 1s) Loss: 0.1018(0.1929) Grad: 1.2719  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 7m 52s (remain 0m 52s) Loss: 0.4104(0.1925) Grad: 1.6983  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 8m 0s (remain 0m 43s) Loss: 0.1743(0.1923) Grad: 1.4558  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 8m 9s (remain 0m 34s) Loss: 0.2903(0.1920) Grad: 1.6656  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 8m 18s (remain 0m 25s) Loss: 0.1411(0.1915) Grad: 1.0984  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 8m 27s (remain 0m 16s) Loss: 0.1763(0.1912) Grad: 0.4801  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 8m 36s (remain 0m 8s) Loss: 0.1271(0.1912) Grad: 0.6326  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 8m 44s (remain 0m 0s) Loss: 0.1949(0.1909) Grad: 0.6587  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 43s) Loss: 0.0785(0.0785) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1976(0.1392) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.1659(0.1644) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.2352(0.1740) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.1380(0.1757) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 30s) Loss: 0.1881(0.1787) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1616(0.1774) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1344(0.1743) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0980(0.1723) \n","f1 score : 0.38999329908420816\n","recall score : 0.2675452038001839\n","precision score : 0.7191103789126854\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.1909  avg_val_loss: 0.1723  time: 624s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.1909  avg_val_loss: 0.1723  time: 624s\n","Epoch 1 - Score: 0.3900\n","INFO:__main__:Epoch 1 - Score: 0.3900\n","Epoch 1 - Save Best Score: 0.4960 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4960 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 39m 11s) Loss: 0.1598(0.1598) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 9s (remain 8m 52s) Loss: 0.2207(0.1686) Grad: 0.7738  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 18s (remain 8m 42s) Loss: 0.1763(0.1711) Grad: 0.5409  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 27s (remain 8m 27s) Loss: 0.1218(0.1671) Grad: 0.8488  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 0m 36s (remain 8m 17s) Loss: 0.1371(0.1659) Grad: 0.6175  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 0m 45s (remain 8m 6s) Loss: 0.1876(0.1673) Grad: 0.8873  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 0m 53s (remain 7m 55s) Loss: 0.1906(0.1680) Grad: 1.3438  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 2s (remain 7m 44s) Loss: 0.1736(0.1687) Grad: 0.6384  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 1m 11s (remain 7m 36s) Loss: 0.1431(0.1695) Grad: 0.8246  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 1m 20s (remain 7m 26s) Loss: 0.2710(0.1689) Grad: 1.1082  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 1m 29s (remain 7m 17s) Loss: 0.1997(0.1690) Grad: 1.1885  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 1m 38s (remain 7m 7s) Loss: 0.0848(0.1686) Grad: 0.7991  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 1m 47s (remain 6m 58s) Loss: 0.1504(0.1684) Grad: 0.4512  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 1m 56s (remain 6m 49s) Loss: 0.2903(0.1689) Grad: 1.6169  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 2m 5s (remain 6m 41s) Loss: 0.3938(0.1688) Grad: 2.0538  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 2m 14s (remain 6m 32s) Loss: 0.0964(0.1684) Grad: 0.5223  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 2m 23s (remain 6m 23s) Loss: 0.1605(0.1677) Grad: 0.8463  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 2m 32s (remain 6m 14s) Loss: 0.2273(0.1676) Grad: 0.8728  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 2m 41s (remain 6m 5s) Loss: 0.1816(0.1667) Grad: 1.0856  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 2m 49s (remain 5m 56s) Loss: 0.1656(0.1667) Grad: 0.6501  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 2m 58s (remain 5m 47s) Loss: 0.1196(0.1666) Grad: 0.9248  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 3m 7s (remain 5m 38s) Loss: 0.0861(0.1665) Grad: 0.4613  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 3m 16s (remain 5m 29s) Loss: 0.1218(0.1658) Grad: 0.6059  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 3m 25s (remain 5m 20s) Loss: 0.1451(0.1660) Grad: 0.6955  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 3m 34s (remain 5m 11s) Loss: 0.1410(0.1656) Grad: 0.4995  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 3m 43s (remain 5m 2s) Loss: 0.2192(0.1651) Grad: 1.0097  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 3m 52s (remain 4m 53s) Loss: 0.2905(0.1649) Grad: 1.8915  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 4m 0s (remain 4m 44s) Loss: 0.1124(0.1649) Grad: 0.6052  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 4m 9s (remain 4m 35s) Loss: 0.1174(0.1651) Grad: 1.0358  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 4m 18s (remain 4m 26s) Loss: 0.0818(0.1652) Grad: 0.4767  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 4m 27s (remain 4m 17s) Loss: 0.1909(0.1650) Grad: 0.5220  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 4m 36s (remain 4m 8s) Loss: 0.0985(0.1652) Grad: 0.4860  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 4m 45s (remain 3m 59s) Loss: 0.1943(0.1654) Grad: 0.6883  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 4m 54s (remain 3m 50s) Loss: 0.0637(0.1653) Grad: 1.0049  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 5m 3s (remain 3m 42s) Loss: 0.1478(0.1656) Grad: 1.2418  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 5m 12s (remain 3m 33s) Loss: 0.1261(0.1656) Grad: 0.5823  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 5m 20s (remain 3m 24s) Loss: 0.0835(0.1656) Grad: 0.9867  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 5m 29s (remain 3m 15s) Loss: 0.1970(0.1659) Grad: 0.7639  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 5m 38s (remain 3m 6s) Loss: 0.0763(0.1658) Grad: 0.5725  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 5m 47s (remain 2m 57s) Loss: 0.2063(0.1657) Grad: 1.5983  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 5m 56s (remain 2m 48s) Loss: 0.2783(0.1658) Grad: 1.5807  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 6m 5s (remain 2m 39s) Loss: 0.2250(0.1655) Grad: 1.2175  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 6m 14s (remain 2m 30s) Loss: 0.1158(0.1653) Grad: 0.5747  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 6m 23s (remain 2m 21s) Loss: 0.2593(0.1651) Grad: 1.1535  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 6m 31s (remain 2m 12s) Loss: 0.1788(0.1649) Grad: 0.7598  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 6m 40s (remain 2m 3s) Loss: 0.1444(0.1649) Grad: 0.7104  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 6m 49s (remain 1m 54s) Loss: 0.2076(0.1648) Grad: 1.5146  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 6m 58s (remain 1m 45s) Loss: 0.0617(0.1645) Grad: 0.5799  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 7m 7s (remain 1m 37s) Loss: 0.1434(0.1642) Grad: 0.7453  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 7m 16s (remain 1m 28s) Loss: 0.1160(0.1641) Grad: 0.6300  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 7m 25s (remain 1m 19s) Loss: 0.1522(0.1641) Grad: 0.7810  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 7m 34s (remain 1m 10s) Loss: 0.0897(0.1637) Grad: 0.6448  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 7m 42s (remain 1m 1s) Loss: 0.1863(0.1635) Grad: 0.6691  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 7m 51s (remain 0m 52s) Loss: 0.1103(0.1638) Grad: 1.4720  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 8m 0s (remain 0m 43s) Loss: 0.1669(0.1639) Grad: 0.9586  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 8m 9s (remain 0m 34s) Loss: 0.2671(0.1635) Grad: 1.2404  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 8m 18s (remain 0m 25s) Loss: 0.0974(0.1635) Grad: 0.5069  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 8m 27s (remain 0m 16s) Loss: 0.1073(0.1637) Grad: 0.5849  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 8m 36s (remain 0m 8s) Loss: 0.1880(0.1637) Grad: 0.7251  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 8m 44s (remain 0m 0s) Loss: 0.0758(0.1635) Grad: 0.5660  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 47s) Loss: 0.0678(0.0678) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1691(0.1314) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.1479(0.1541) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.2024(0.1628) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.1069(0.1648) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 31s) Loss: 0.1630(0.1679) \n","EVAL: [600/737] Elapsed 1m 19s (remain 0m 17s) Loss: 0.1671(0.1669) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1460(0.1642) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0990(0.1624) \n","f1 score : 0.45628014258754457\n","recall score : 0.3334354888139749\n","precision score : 0.7224435590969456\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.1635  avg_val_loss: 0.1624  time: 624s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1635  avg_val_loss: 0.1624  time: 624s\n","Epoch 2 - Score: 0.4563\n","INFO:__main__:Epoch 2 - Score: 0.4563\n","Epoch 2 - Save Best Score: 0.5283 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5283 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 39m 2s) Loss: 0.1002(0.1002) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 9s (remain 8m 58s) Loss: 0.0443(0.1542) Grad: 0.4624  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 18s (remain 8m 46s) Loss: 0.1659(0.1519) Grad: 0.6900  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 27s (remain 8m 37s) Loss: 0.1026(0.1521) Grad: 0.4932  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 0m 36s (remain 8m 22s) Loss: 0.2433(0.1530) Grad: 1.5564  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 0m 45s (remain 8m 9s) Loss: 0.1833(0.1548) Grad: 1.6290  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 0m 54s (remain 7m 57s) Loss: 0.2048(0.1559) Grad: 0.8495  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 3s (remain 7m 47s) Loss: 0.2097(0.1552) Grad: 1.2535  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 1m 11s (remain 7m 36s) Loss: 0.2064(0.1553) Grad: 0.7726  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 1m 20s (remain 7m 27s) Loss: 0.2952(0.1547) Grad: 1.4038  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 1m 29s (remain 7m 18s) Loss: 0.0726(0.1536) Grad: 1.1643  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 1m 38s (remain 7m 9s) Loss: 0.1448(0.1546) Grad: 1.2205  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 1m 47s (remain 7m 0s) Loss: 0.1091(0.1543) Grad: 0.5893  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 1m 56s (remain 6m 51s) Loss: 0.1423(0.1547) Grad: 1.1273  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 2m 5s (remain 6m 42s) Loss: 0.2324(0.1545) Grad: 1.2279  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 2m 14s (remain 6m 33s) Loss: 0.0830(0.1538) Grad: 0.6117  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 2m 23s (remain 6m 24s) Loss: 0.3894(0.1533) Grad: 2.7798  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 2m 32s (remain 6m 14s) Loss: 0.1683(0.1539) Grad: 0.6877  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 2m 41s (remain 6m 5s) Loss: 0.0809(0.1534) Grad: 0.9224  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 2m 49s (remain 5m 56s) Loss: 0.0743(0.1531) Grad: 0.4094  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 2m 58s (remain 5m 47s) Loss: 0.2681(0.1529) Grad: 1.3147  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 3m 7s (remain 5m 38s) Loss: 0.1060(0.1523) Grad: 0.5878  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 3m 16s (remain 5m 29s) Loss: 0.1225(0.1523) Grad: 0.8420  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 3m 25s (remain 5m 20s) Loss: 0.0559(0.1527) Grad: 1.2037  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 3m 34s (remain 5m 11s) Loss: 0.2288(0.1527) Grad: 0.6498  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 3m 43s (remain 5m 2s) Loss: 0.1782(0.1532) Grad: 1.5697  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 3m 52s (remain 4m 53s) Loss: 0.0963(0.1528) Grad: 0.6045  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 4m 1s (remain 4m 44s) Loss: 0.2023(0.1524) Grad: 1.0312  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 4m 10s (remain 4m 35s) Loss: 0.2488(0.1526) Grad: 1.2361  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 4m 18s (remain 4m 26s) Loss: 0.1633(0.1524) Grad: 0.7614  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 4m 27s (remain 4m 17s) Loss: 0.0640(0.1520) Grad: 1.3351  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 4m 36s (remain 4m 8s) Loss: 0.1039(0.1522) Grad: 0.5793  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 4m 45s (remain 3m 59s) Loss: 0.1538(0.1523) Grad: 0.6050  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 4m 54s (remain 3m 50s) Loss: 0.1461(0.1523) Grad: 0.6138  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 5m 3s (remain 3m 41s) Loss: 0.3960(0.1525) Grad: 2.8620  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 5m 11s (remain 3m 32s) Loss: 0.2842(0.1528) Grad: 2.0965  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 5m 20s (remain 3m 24s) Loss: 0.1216(0.1526) Grad: 1.5036  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 5m 29s (remain 3m 15s) Loss: 0.1682(0.1525) Grad: 1.1655  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 5m 38s (remain 3m 6s) Loss: 0.1694(0.1524) Grad: 1.1736  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 5m 47s (remain 2m 57s) Loss: 0.1616(0.1523) Grad: 0.7759  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 5m 56s (remain 2m 48s) Loss: 0.1370(0.1523) Grad: 0.7525  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 6m 4s (remain 2m 39s) Loss: 0.0778(0.1520) Grad: 0.5889  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 6m 13s (remain 2m 30s) Loss: 0.1691(0.1519) Grad: 0.7676  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 6m 22s (remain 2m 21s) Loss: 0.1045(0.1518) Grad: 0.7634  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 6m 31s (remain 2m 12s) Loss: 0.2710(0.1516) Grad: 1.0144  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 6m 40s (remain 2m 3s) Loss: 0.1268(0.1517) Grad: 0.6347  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 6m 49s (remain 1m 54s) Loss: 0.3008(0.1519) Grad: 1.0937  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 6m 58s (remain 1m 45s) Loss: 0.1043(0.1518) Grad: 1.2975  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 7m 6s (remain 1m 36s) Loss: 0.0960(0.1518) Grad: 1.0867  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 7m 15s (remain 1m 28s) Loss: 0.2515(0.1519) Grad: 1.0716  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 7m 24s (remain 1m 19s) Loss: 0.1560(0.1519) Grad: 0.7432  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 7m 33s (remain 1m 10s) Loss: 0.1086(0.1519) Grad: 0.8929  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 7m 42s (remain 1m 1s) Loss: 0.1302(0.1522) Grad: 0.6267  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 7m 51s (remain 0m 52s) Loss: 0.1721(0.1521) Grad: 0.8522  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 8m 0s (remain 0m 43s) Loss: 0.2313(0.1523) Grad: 1.2260  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 8m 8s (remain 0m 34s) Loss: 0.1254(0.1524) Grad: 0.8270  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 8m 17s (remain 0m 25s) Loss: 0.0966(0.1524) Grad: 1.2509  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 8m 26s (remain 0m 16s) Loss: 0.1848(0.1523) Grad: 0.9756  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 8m 35s (remain 0m 7s) Loss: 0.1047(0.1523) Grad: 1.3624  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 8m 43s (remain 0m 0s) Loss: 0.1197(0.1522) Grad: 0.6613  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 49s) Loss: 0.0655(0.0655) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1708(0.1292) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.1448(0.1520) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.2020(0.1607) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.1102(0.1623) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 31s) Loss: 0.1605(0.1646) \n","EVAL: [600/737] Elapsed 1m 19s (remain 0m 17s) Loss: 0.1889(0.1637) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1207(0.1609) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0878(0.1591) \n","f1 score : 0.47289719626168225\n","recall score : 0.34891204413116766\n","precision score : 0.7335695876288659\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1522  avg_val_loss: 0.1591  time: 623s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1522  avg_val_loss: 0.1591  time: 623s\n","Epoch 3 - Score: 0.4729\n","INFO:__main__:Epoch 3 - Score: 0.4729\n","Epoch 3 - Save Best Score: 0.5413 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5413 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 39m 35s) Loss: 0.0914(0.0914) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 9s (remain 8m 58s) Loss: 0.0604(0.1482) Grad: 0.7479  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 18s (remain 8m 44s) Loss: 0.0938(0.1430) Grad: 0.5413  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 27s (remain 8m 34s) Loss: 0.1353(0.1420) Grad: 0.5954  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 0m 36s (remain 8m 20s) Loss: 0.1422(0.1426) Grad: 0.8412  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 0m 45s (remain 8m 9s) Loss: 0.2081(0.1419) Grad: 1.0069  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 0m 54s (remain 7m 58s) Loss: 0.1716(0.1422) Grad: 0.7565  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 3s (remain 7m 48s) Loss: 0.1427(0.1429) Grad: 1.2995  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 1m 12s (remain 7m 38s) Loss: 0.1512(0.1428) Grad: 0.7697  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 1m 21s (remain 7m 28s) Loss: 0.1116(0.1426) Grad: 0.5483  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 1m 29s (remain 7m 19s) Loss: 0.1783(0.1418) Grad: 0.7050  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 1m 38s (remain 7m 9s) Loss: 0.0666(0.1423) Grad: 0.6114  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 1m 47s (remain 7m 0s) Loss: 0.1381(0.1433) Grad: 1.0196  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 1m 56s (remain 6m 50s) Loss: 0.0801(0.1430) Grad: 0.8268  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 2m 5s (remain 6m 41s) Loss: 0.2290(0.1433) Grad: 0.9469  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 2m 14s (remain 6m 32s) Loss: 0.0917(0.1441) Grad: 1.4711  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 2m 23s (remain 6m 23s) Loss: 0.1316(0.1441) Grad: 1.0858  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 2m 31s (remain 6m 14s) Loss: 0.1281(0.1440) Grad: 0.6183  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 2m 40s (remain 6m 5s) Loss: 0.0316(0.1449) Grad: 0.5756  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 2m 49s (remain 5m 56s) Loss: 0.2644(0.1451) Grad: 1.8572  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 2m 58s (remain 5m 47s) Loss: 0.1521(0.1453) Grad: 0.7463  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 3m 7s (remain 5m 38s) Loss: 0.1046(0.1453) Grad: 1.0239  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 3m 16s (remain 5m 29s) Loss: 0.0751(0.1449) Grad: 0.8052  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 3m 25s (remain 5m 19s) Loss: 0.1331(0.1446) Grad: 1.0395  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 3m 33s (remain 5m 10s) Loss: 0.0740(0.1447) Grad: 0.8344  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 3m 42s (remain 5m 2s) Loss: 0.1545(0.1446) Grad: 0.6922  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 3m 51s (remain 4m 53s) Loss: 0.2368(0.1446) Grad: 1.0864  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 4m 0s (remain 4m 44s) Loss: 0.0643(0.1443) Grad: 1.0155  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 4m 9s (remain 4m 35s) Loss: 0.1021(0.1443) Grad: 0.5333  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 4m 18s (remain 4m 26s) Loss: 0.0406(0.1443) Grad: 0.8467  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 4m 27s (remain 4m 17s) Loss: 0.1055(0.1441) Grad: 1.0432  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 4m 36s (remain 4m 8s) Loss: 0.0907(0.1437) Grad: 0.9409  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 4m 44s (remain 3m 59s) Loss: 0.1539(0.1437) Grad: 1.0135  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 4m 53s (remain 3m 50s) Loss: 0.2053(0.1437) Grad: 0.9743  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 5m 2s (remain 3m 41s) Loss: 0.1191(0.1437) Grad: 0.9315  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 5m 11s (remain 3m 32s) Loss: 0.1750(0.1435) Grad: 1.2773  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 5m 20s (remain 3m 23s) Loss: 0.0891(0.1434) Grad: 0.6879  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 5m 29s (remain 3m 14s) Loss: 0.1108(0.1434) Grad: 0.7952  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 5m 38s (remain 3m 5s) Loss: 0.0837(0.1431) Grad: 1.3911  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 5m 46s (remain 2m 56s) Loss: 0.1038(0.1429) Grad: 0.8795  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 5m 55s (remain 2m 48s) Loss: 0.1692(0.1430) Grad: 0.6932  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 6m 4s (remain 2m 39s) Loss: 0.1737(0.1431) Grad: 0.9905  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 6m 13s (remain 2m 30s) Loss: 0.1780(0.1432) Grad: 1.5297  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 6m 22s (remain 2m 21s) Loss: 0.1721(0.1433) Grad: 1.3418  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 6m 31s (remain 2m 12s) Loss: 0.1044(0.1430) Grad: 0.6159  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 6m 40s (remain 2m 3s) Loss: 0.1272(0.1429) Grad: 0.6848  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 6m 49s (remain 1m 54s) Loss: 0.0615(0.1429) Grad: 0.6581  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 6m 58s (remain 1m 45s) Loss: 0.2307(0.1427) Grad: 1.0109  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 7m 7s (remain 1m 36s) Loss: 0.1754(0.1427) Grad: 0.8500  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 7m 15s (remain 1m 28s) Loss: 0.0981(0.1425) Grad: 0.6544  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 7m 24s (remain 1m 19s) Loss: 0.1182(0.1424) Grad: 1.0456  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 7m 33s (remain 1m 10s) Loss: 0.1393(0.1427) Grad: 0.8537  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 7m 42s (remain 1m 1s) Loss: 0.1938(0.1426) Grad: 1.1061  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 7m 51s (remain 0m 52s) Loss: 0.1528(0.1428) Grad: 0.8620  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 8m 0s (remain 0m 43s) Loss: 0.1311(0.1431) Grad: 1.1654  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 8m 8s (remain 0m 34s) Loss: 0.2035(0.1430) Grad: 0.9864  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 8m 17s (remain 0m 25s) Loss: 0.2480(0.1431) Grad: 1.4495  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 8m 26s (remain 0m 16s) Loss: 0.1555(0.1431) Grad: 0.7890  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 8m 36s (remain 0m 8s) Loss: 0.0885(0.1432) Grad: 0.9493  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 8m 44s (remain 0m 0s) Loss: 0.2739(0.1431) Grad: 1.8018  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 44s) Loss: 0.0630(0.0630) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 24s) Loss: 0.1771(0.1301) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 10s) Loss: 0.1428(0.1524) \n","EVAL: [300/737] Elapsed 0m 39s (remain 0m 57s) Loss: 0.2059(0.1609) \n","EVAL: [400/737] Elapsed 0m 52s (remain 0m 44s) Loss: 0.1107(0.1626) \n","EVAL: [500/737] Elapsed 1m 5s (remain 0m 31s) Loss: 0.1585(0.1647) \n","EVAL: [600/737] Elapsed 1m 18s (remain 0m 17s) Loss: 0.1954(0.1638) \n","EVAL: [700/737] Elapsed 1m 32s (remain 0m 4s) Loss: 0.1202(0.1611) \n","EVAL: [736/737] Elapsed 1m 36s (remain 0m 0s) Loss: 0.0805(0.1593) \n","f1 score : 0.49076569831286815\n","recall score : 0.37664725712534475\n","precision score : 0.7040962474935548\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1431  avg_val_loss: 0.1593  time: 623s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1431  avg_val_loss: 0.1593  time: 623s\n","Epoch 4 - Score: 0.4908\n","INFO:__main__:Epoch 4 - Score: 0.4908\n","========== fold: 4 result ==========\n","INFO:__main__:========== fold: 4 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.47289719626168225\n","recall score : 0.34891204413116766\n","precision score : 0.7335695876288659\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.4729\n","INFO:__main__:Score: 0.4729\n","F1 BEST Score: 0.5413\n","INFO:__main__:F1 BEST Score: 0.5413\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.4248724820610357\n","recall score : 0.3012166344886764\n","precision score : 0.7207596978807655\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.4249\n","INFO:__main__:Score: 0.4249\n","F1 BEST Score: 0.4886\n","INFO:__main__:F1 BEST Score: 0.4886\n"]}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"OotP5Fy0pmIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uj-f85L1tntx"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyMx6bxgRtp5FF06kRo0BPV9"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"9acb63c8c9a64667857802260d2114d2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b9e6dc791de8475fa36b1f95a57a26a2","IPY_MODEL_e3d9f19d00c0428d9d699006863d0eac","IPY_MODEL_ed025355237f4aebb1d74beb9778e57c"],"layout":"IPY_MODEL_e8eb34aaeaf34493a04b7f55d119f007"}},"b9e6dc791de8475fa36b1f95a57a26a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a02177be6b84f689b0dbca0ee32c626","placeholder":"​","style":"IPY_MODEL_9cf1552ed41f4ed98046cf78871c6e51","value":"Downloading (…)okenizer_config.json: 100%"}},"e3d9f19d00c0428d9d699006863d0eac":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d03d6c1eae944463b4563cae1a46af07","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cba7124a8bce45a48bada108b4eec8ca","value":52}},"ed025355237f4aebb1d74beb9778e57c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7afddeb8cc8c4cdba2f0ba1bd475a9d6","placeholder":"​","style":"IPY_MODEL_f8d484da0d4e4e2fbaa5a6256c0bee5c","value":" 52.0/52.0 [00:00&lt;00:00, 4.57kB/s]"}},"e8eb34aaeaf34493a04b7f55d119f007":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a02177be6b84f689b0dbca0ee32c626":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9cf1552ed41f4ed98046cf78871c6e51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d03d6c1eae944463b4563cae1a46af07":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cba7124a8bce45a48bada108b4eec8ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7afddeb8cc8c4cdba2f0ba1bd475a9d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f8d484da0d4e4e2fbaa5a6256c0bee5c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad877098f5614e58959a2c7160c39707":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_097fd25dd6fc45768cbf96f4c212bc2f","IPY_MODEL_4d30c56233504397b94fb548e9de58b6","IPY_MODEL_4c299d144a284b89b11feb9708df7b7f"],"layout":"IPY_MODEL_25a6dc0b9be342ebb3e9966352b248d6"}},"097fd25dd6fc45768cbf96f4c212bc2f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6aef6285f0ee40948757ebbe0bfe9ce2","placeholder":"​","style":"IPY_MODEL_e4fd48e1eb6c4ca8af77d2709b5e031d","value":"Downloading (…)lve/main/config.json: 100%"}},"4d30c56233504397b94fb548e9de58b6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e0a48121d36748f29409c4661c509e44","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a373b6f113284beba120dbdd5c82daf9","value":579}},"4c299d144a284b89b11feb9708df7b7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1476027af64543de9ede9c9274a140de","placeholder":"​","style":"IPY_MODEL_5e3c073892a345c9b5ed0bd8e23683b4","value":" 579/579 [00:00&lt;00:00, 51.7kB/s]"}},"25a6dc0b9be342ebb3e9966352b248d6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6aef6285f0ee40948757ebbe0bfe9ce2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e4fd48e1eb6c4ca8af77d2709b5e031d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e0a48121d36748f29409c4661c509e44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a373b6f113284beba120dbdd5c82daf9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1476027af64543de9ede9c9274a140de":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e3c073892a345c9b5ed0bd8e23683b4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6c335937fc249ad8c6765e1eba617bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e30befba94014e64826404db0b6fe29b","IPY_MODEL_3f419e4f950940d8b273406eb7ca6988","IPY_MODEL_7f7039a00c9e44d49d3aa4889b7fd5f9"],"layout":"IPY_MODEL_105b594db3b942238f41b909b66efee0"}},"e30befba94014e64826404db0b6fe29b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e93ceb0b0394420d848b4be3e4b6078d","placeholder":"​","style":"IPY_MODEL_38b3e82646914a58bfdd3c2079094a3b","value":"Downloading spm.model: 100%"}},"3f419e4f950940d8b273406eb7ca6988":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4e21345216342acaca1d2d6a9379386","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_55acf4daf0bc4eb299f8aa4765743f1e","value":2464616}},"7f7039a00c9e44d49d3aa4889b7fd5f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1aa4959267cc4f9c9af50b752002fdd3","placeholder":"​","style":"IPY_MODEL_3718227fe84a4987a924b0eb9c683b03","value":" 2.46M/2.46M [00:00&lt;00:00, 73.1MB/s]"}},"105b594db3b942238f41b909b66efee0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e93ceb0b0394420d848b4be3e4b6078d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38b3e82646914a58bfdd3c2079094a3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4e21345216342acaca1d2d6a9379386":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"55acf4daf0bc4eb299f8aa4765743f1e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1aa4959267cc4f9c9af50b752002fdd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3718227fe84a4987a924b0eb9c683b03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"48fd7fdcf7084bb3ab4336f4c78379ad":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7ad00761c8944735bfe8004b952454ed","IPY_MODEL_7af9b7340b59495aa231e3c16b856718","IPY_MODEL_34ef042217764fff9decdd7891f14b9c"],"layout":"IPY_MODEL_2322cc117b8f481f9f916041ff58169d"}},"7ad00761c8944735bfe8004b952454ed":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_38e12e0c881e4472b7302e7a25bf6eb0","placeholder":"​","style":"IPY_MODEL_50c1589c193c42b9915c132d08f46ea4","value":"Downloading pytorch_model.bin: 100%"}},"7af9b7340b59495aa231e3c16b856718":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_69fce6982c124bed86de400ad1cfc302","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3a505d8eb34f46acac5ab0f18a553b01","value":371146213}},"34ef042217764fff9decdd7891f14b9c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_39e0145a8e5745f296ff6d2edc4317bb","placeholder":"​","style":"IPY_MODEL_061f5e1c20cc4fe7bd08f331a87de7fd","value":" 371M/371M [00:00&lt;00:00, 498MB/s]"}},"2322cc117b8f481f9f916041ff58169d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"38e12e0c881e4472b7302e7a25bf6eb0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50c1589c193c42b9915c132d08f46ea4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"69fce6982c124bed86de400ad1cfc302":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3a505d8eb34f46acac5ab0f18a553b01":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"39e0145a8e5745f296ff6d2edc4317bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"061f5e1c20cc4fe7bd08f331a87de7fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}