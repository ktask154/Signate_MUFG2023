{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23154,"status":"ok","timestamp":1693040926903,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"MM4dTYOWdrrK","outputId":"7c04e33d-5b76-4fb5-a8e0-d7b94ed9e21f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"],"metadata":{"id":"CD_RBZ2zbgMk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693040955098,"user_tz":-540,"elapsed":28199,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"2851a9ce-66a0-4902-9c76-b905dcd9e3bb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.32.0-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m75.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0\n","Collecting datasets\n","  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.4 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"JK8PEmITblft","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693040955630,"user_tz":-540,"elapsed":536,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"43f6e0fa-db31-446b-bc30-bd10faa15b4f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sat Aug 26 09:09:15 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   33C    P0    25W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gqVuaXRJeCOe"},"outputs":[],"source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score, recall_score, accuracy_score, precision_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jm5aYY3Qd6kO"},"outputs":[],"source":["import os\n","\n","DIR = \"/content/drive/MyDrive/Competitions/Signate/MUFG2023\"\n","INPUT_DIR = os.path.join(DIR,\"input\")\n","OUTPUT_DIR = os.path.join(DIR,\"output\")\n","\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n","\n","\n","OUTPUT_EXP_DIR = DIR + '/output/EXP026/'\n","if not os.path.exists(OUTPUT_EXP_DIR):\n","    os.makedirs(OUTPUT_EXP_DIR)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cang6GVBAu94"},"outputs":[],"source":["\n","\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-base\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    # model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=64\n","    fc_dropout=0.2\n","    target=\"is_fraud?\"\n","    target_size=1\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = False\n","    freezing = False\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]"]},{"cell_type":"code","source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    f_score = f1_score(y_true, (y_pred>thresh).astype(int))\n","    r_score = recall_score(y_true, (y_pred>thresh).astype(int))\n","    p_score = precision_score(y_true, (y_pred>thresh).astype(int))\n","    print(f\"f1 score : {f_score}\")\n","    print(f\"recall score : {r_score}\")\n","    print(f\"precision score : {p_score}\")\n","    return f1_score(y_true, (y_pred>thresh).astype(int))\n","\n","def get_f1_score(labels, outputs):\n","    y_pred = outputs\n","    y_true = labels\n","    best_score = 0\n","    best_thresh = 0.5\n","    for thresh in np.arange(0.1, 0.80, 0.01):\n","        thresh = np.round(thresh, 2)\n","        score = f1_score(y_true, (y_pred>thresh).astype(int))\n","        #print(\"Accuracy score at threshold {0} is {1}\".format(thresh, score))\n","        if score > best_score:\n","          best_score = score\n","          best_thresh = thresh\n","    return f1_score(y_true, (y_pred>best_thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_EXP_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"lOI-vnq5cDJP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","\n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","\n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","\n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","\n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","\n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","\n","        if hasattr(embeddings_path, attr_name):\n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"3vZWA_5rcVEo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":846},"executionInfo":{"elapsed":6129,"status":"ok","timestamp":1693040978977,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"alfdMdcXeaGI","outputId":"168808be-f4ea-4f21-b406-97bf21acf253"},"outputs":[{"output_type":"stream","name":"stdout","text":["(471283, 12)\n"]},{"output_type":"display_data","data":{"text/plain":["   index  user_id  card_id  amount errors?  is_fraud?  merchant_id  \\\n","0      0     1721        0  $2.623      OK          0       209237   \n","1      1     1629        3    $6.4      OK          0         2568   \n","2      2      655        3  $123.5      OK          0       345310   \n","\n","  merchant_city merchant_state      zip   mcc           use_chip  \n","0        Joliet             IL  60436.0  5541  Swipe Transaction  \n","1      Edgerton             WI  53534.0  5814  Swipe Transaction  \n","2    Ridgefield             WA  98642.0  7538  Swipe Transaction  "],"text/html":["\n","  <div id=\"df-940f62b6-966b-491d-97c8-ecc10135563a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>user_id</th>\n","      <th>card_id</th>\n","      <th>amount</th>\n","      <th>errors?</th>\n","      <th>is_fraud?</th>\n","      <th>merchant_id</th>\n","      <th>merchant_city</th>\n","      <th>merchant_state</th>\n","      <th>zip</th>\n","      <th>mcc</th>\n","      <th>use_chip</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1721</td>\n","      <td>0</td>\n","      <td>$2.623</td>\n","      <td>OK</td>\n","      <td>0</td>\n","      <td>209237</td>\n","      <td>Joliet</td>\n","      <td>IL</td>\n","      <td>60436.0</td>\n","      <td>5541</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1629</td>\n","      <td>3</td>\n","      <td>$6.4</td>\n","      <td>OK</td>\n","      <td>0</td>\n","      <td>2568</td>\n","      <td>Edgerton</td>\n","      <td>WI</td>\n","      <td>53534.0</td>\n","      <td>5814</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>655</td>\n","      <td>3</td>\n","      <td>$123.5</td>\n","      <td>OK</td>\n","      <td>0</td>\n","      <td>345310</td>\n","      <td>Ridgefield</td>\n","      <td>WA</td>\n","      <td>98642.0</td>\n","      <td>7538</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-940f62b6-966b-491d-97c8-ecc10135563a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-940f62b6-966b-491d-97c8-ecc10135563a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-940f62b6-966b-491d-97c8-ecc10135563a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(457958, 11)\n"]},{"output_type":"display_data","data":{"text/plain":["    index  user_id  card_id    amount errors?  merchant_id      merchant_city  \\\n","0  471283      541        3  $113.278      OK       324189            Orlando   \n","1  471284      655        1  $293.944      OK        81219         Ridgefield   \n","2  471285      492        0     $47.4      OK       274755  Arlington Heights   \n","\n","  merchant_state      zip   mcc           use_chip  \n","0             FL  32821.0  4814  Swipe Transaction  \n","1             WA  98642.0  7538   Chip Transaction  \n","2             IL  60004.0  5719  Swipe Transaction  "],"text/html":["\n","  <div id=\"df-dd4a8d3b-831d-438d-b7b5-227f878df0a9\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>user_id</th>\n","      <th>card_id</th>\n","      <th>amount</th>\n","      <th>errors?</th>\n","      <th>merchant_id</th>\n","      <th>merchant_city</th>\n","      <th>merchant_state</th>\n","      <th>zip</th>\n","      <th>mcc</th>\n","      <th>use_chip</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>471283</td>\n","      <td>541</td>\n","      <td>3</td>\n","      <td>$113.278</td>\n","      <td>OK</td>\n","      <td>324189</td>\n","      <td>Orlando</td>\n","      <td>FL</td>\n","      <td>32821.0</td>\n","      <td>4814</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>471284</td>\n","      <td>655</td>\n","      <td>1</td>\n","      <td>$293.944</td>\n","      <td>OK</td>\n","      <td>81219</td>\n","      <td>Ridgefield</td>\n","      <td>WA</td>\n","      <td>98642.0</td>\n","      <td>7538</td>\n","      <td>Chip Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>471285</td>\n","      <td>492</td>\n","      <td>0</td>\n","      <td>$47.4</td>\n","      <td>OK</td>\n","      <td>274755</td>\n","      <td>Arlington Heights</td>\n","      <td>IL</td>\n","      <td>60004.0</td>\n","      <td>5719</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dd4a8d3b-831d-438d-b7b5-227f878df0a9')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-dd4a8d3b-831d-438d-b7b5-227f878df0a9 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-dd4a8d3b-831d-438d-b7b5-227f878df0a9');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(416, 10)\n"]},{"output_type":"display_data","data":{"text/plain":["   user_id  card_id card_brand card_type  expires has_chip  cards_issued  \\\n","0       39        0       Visa     Debit  09/2021      YES             1   \n","1       39        1       Amex    Credit  11/2024      YES             2   \n","2       41        0   Discover    Credit  03/2022      YES             2   \n","\n","  credit_limit acct_open_date  year_pin_last_changed  \n","0       $17117        05/2007                   2010  \n","1        $5400        10/2015                   2015  \n","2       $14800        12/2010                   2011  "],"text/html":["\n","  <div id=\"df-2806719f-57c1-48bf-8686-7419cedf951a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>card_id</th>\n","      <th>card_brand</th>\n","      <th>card_type</th>\n","      <th>expires</th>\n","      <th>has_chip</th>\n","      <th>cards_issued</th>\n","      <th>credit_limit</th>\n","      <th>acct_open_date</th>\n","      <th>year_pin_last_changed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>Visa</td>\n","      <td>Debit</td>\n","      <td>09/2021</td>\n","      <td>YES</td>\n","      <td>1</td>\n","      <td>$17117</td>\n","      <td>05/2007</td>\n","      <td>2010</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>Amex</td>\n","      <td>Credit</td>\n","      <td>11/2024</td>\n","      <td>YES</td>\n","      <td>2</td>\n","      <td>$5400</td>\n","      <td>10/2015</td>\n","      <td>2015</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>Discover</td>\n","      <td>Credit</td>\n","      <td>03/2022</td>\n","      <td>YES</td>\n","      <td>2</td>\n","      <td>$14800</td>\n","      <td>12/2010</td>\n","      <td>2011</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2806719f-57c1-48bf-8686-7419cedf951a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2806719f-57c1-48bf-8686-7419cedf951a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2806719f-57c1-48bf-8686-7419cedf951a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(97, 17)\n"]},{"output_type":"display_data","data":{"text/plain":["   user_id  current_age  retirement_age  birth_year  birth_month  gender  \\\n","0       39           57              64        1962           12  Female   \n","1       41           39              66        1980           10  Female   \n","2       47           40              67        1979            5  Female   \n","\n","               address       city state  zipcode  latitude  longitude  \\\n","0  442 Burns Boulevard  Mansfield    MA     2048     42.02     -71.21   \n","1    3863 River Avenue    Lincoln    CA    95648     38.93    -121.25   \n","2      8799 Elm Avenue   Mckinney    TX    75069     33.20     -96.65   \n","\n","  per_capita_income_zipcode yearly_income_person total_debt  fico_score  \\\n","0                    $37407               $76274    $102611         698   \n","1                    $21829               $44506     $57994         849   \n","2                    $24684               $50329     $76759         625   \n","\n","   num_credit_cards  \n","0                 2  \n","1                 3  \n","2                 4  "],"text/html":["\n","  <div id=\"df-b02b87a8-3436-46d2-baa5-365e231e6c1c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>current_age</th>\n","      <th>retirement_age</th>\n","      <th>birth_year</th>\n","      <th>birth_month</th>\n","      <th>gender</th>\n","      <th>address</th>\n","      <th>city</th>\n","      <th>state</th>\n","      <th>zipcode</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>per_capita_income_zipcode</th>\n","      <th>yearly_income_person</th>\n","      <th>total_debt</th>\n","      <th>fico_score</th>\n","      <th>num_credit_cards</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>57</td>\n","      <td>64</td>\n","      <td>1962</td>\n","      <td>12</td>\n","      <td>Female</td>\n","      <td>442 Burns Boulevard</td>\n","      <td>Mansfield</td>\n","      <td>MA</td>\n","      <td>2048</td>\n","      <td>42.02</td>\n","      <td>-71.21</td>\n","      <td>$37407</td>\n","      <td>$76274</td>\n","      <td>$102611</td>\n","      <td>698</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>41</td>\n","      <td>39</td>\n","      <td>66</td>\n","      <td>1980</td>\n","      <td>10</td>\n","      <td>Female</td>\n","      <td>3863 River Avenue</td>\n","      <td>Lincoln</td>\n","      <td>CA</td>\n","      <td>95648</td>\n","      <td>38.93</td>\n","      <td>-121.25</td>\n","      <td>$21829</td>\n","      <td>$44506</td>\n","      <td>$57994</td>\n","      <td>849</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>47</td>\n","      <td>40</td>\n","      <td>67</td>\n","      <td>1979</td>\n","      <td>5</td>\n","      <td>Female</td>\n","      <td>8799 Elm Avenue</td>\n","      <td>Mckinney</td>\n","      <td>TX</td>\n","      <td>75069</td>\n","      <td>33.20</td>\n","      <td>-96.65</td>\n","      <td>$24684</td>\n","      <td>$50329</td>\n","      <td>$76759</td>\n","      <td>625</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b02b87a8-3436-46d2-baa5-365e231e6c1c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b02b87a8-3436-46d2-baa5-365e231e6c1c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b02b87a8-3436-46d2-baa5-365e231e6c1c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(457958, 2)\n"]},{"output_type":"display_data","data":{"text/plain":["        0  1\n","0  471283  0\n","1  471284  1\n","2  471285  0"],"text/html":["\n","  <div id=\"df-45f9cfd0-ab43-45f6-b4c3-b352c22e83f4\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>471283</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>471284</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>471285</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45f9cfd0-ab43-45f6-b4c3-b352c22e83f4')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-45f9cfd0-ab43-45f6-b4c3-b352c22e83f4 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-45f9cfd0-ab43-45f6-b4c3-b352c22e83f4');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}}],"source":["import pandas as pd\n","import numpy as np\n","\n","\n","train = pd.read_csv(os.path.join(INPUT_DIR,\"train.csv\"))\n","test = pd.read_csv(os.path.join(INPUT_DIR,\"test.csv\"))\n","card = pd.read_csv(os.path.join(INPUT_DIR, \"card.csv\"))\n","user = pd.read_csv(os.path.join(INPUT_DIR, \"user.csv\"))\n","sub = pd.read_csv(os.path.join(INPUT_DIR, \"sample_submit.csv\"), header=None)\n","\n","print(train.shape)\n","display(train.head(3))\n","\n","print(test.shape)\n","display(test.head(3))\n","\n","print(card.shape)\n","display(card.head(3))\n","\n","print(user.shape)\n","display(user.head(3))\n","\n","print(sub.shape)\n","display(sub.head(3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i83_oAMoA1LW"},"outputs":[],"source":["train = train.merge(card, how=\"left\", on=[\"user_id\", \"card_id\"]).merge(user, how=\"left\", on=\"user_id\")"]},{"cell_type":"code","source":["month_dict = {\n","   \"01\": \"January\",\n","   \"02\": \"February\",\n","   \"03\": \"March\",\n","   \"04\": \"April\",\n","   \"05\": \"May\",\n","   \"06\": \"June\",\n","   \"07\": \"July\",\n","   \"08\": \"August\",\n","   \"09\": \"September\",\n","   \"10\": \"October\",\n","   \"11\": \"November\",\n","   \"12\": \"December\"\n","}\n","\n","def get_expires_values(df):\n","  _df = df[\"expires\"].str.split('/').apply(pd.Series)\n","  _df.columns = [\"month\",\"years\"]\n","  df[\"expires_month\"] = _df[\"month\"].astype(str)\n","  df[\"expires_years\"] = _df[\"years\"].astype(str)\n","  return df\n","\n","def get_acct_open_date_values(df):\n","  _df = df[\"acct_open_date\"].str.split('/').apply(pd.Series)\n","  _df.columns = [\"month\",\"years\"]\n","  df[\"acct_open_date_month\"] = _df[\"month\"].astype(str)\n","  df[\"acct_open_date_years\"] = _df[\"years\"].astype(str)\n","  return df\n","\n","train = get_expires_values(train)\n","train = get_acct_open_date_values(train)\n","train[\"expires_month\"] = train[\"expires_month\"].map(month_dict)\n","train[\"acct_open_date_month\"] = train[\"acct_open_date_month\"].map(month_dict)"],"metadata":{"id":"fA0Gj3oTfYow"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train.fillna('unknown', inplace = True)\n","\n","train[\"texts\"] = \"merchant\" + \"[SEP]\" + train[\"amount\"] + \"[SEP]\" + train[\"errors?\"] + \"[SEP]\" + train[\"merchant_city\"] + \"[SEP]\" + train[\"merchant_state\"] + \"[SEP]\" + train[\"use_chip\"] + \"[SEP]\" \\\n","+ \"card\" + \"[SEP]\" + train[\"card_brand\"] + \"[SEP]\" + train[\"card_type\"] + \"[SEP]\" + train[\"expires_month\"] + \" \" + train[\"expires_years\"] + \"[SEP]\" + train[\"has_chip\"] + \"[SEP]\" + train[\"acct_open_date_month\"] + \" \" + train[\"acct_open_date_years\"] + \"[SEP]\" + train[\"year_pin_last_changed\"].astype(str) + \"[SEP]\" \\\n","\"user\" + \"[SEP]\" + train[\"current_age\"].astype(str) + \" year old \" + train[\"gender\"] + \"[SEP]\" + \"retired at age \" + train[\"retirement_age\"].astype(str) + \"[SEP]\" + train[\"address\"] + \"[SEP]\" + train[\"city\"] + \"[SEP]\" + train[\"state\"] + \"[SEP]\" + train[\"per_capita_income_zipcode\"] + \"[SEP]\" + train[\"yearly_income_person\"] + \"[SEP]\" + train[\"total_debt\"]"],"metadata":{"id":"ZYevLBPI7-FT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train[CFG.target])):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","\n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=500, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"],"metadata":{"id":"ZSX1VrbRlwwt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_EXP_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["5c11f8f3dcad453a9967d77ad8372f5f","ad7bc6073e4b435e909f85d2b73436d3","360308e830904cdb86a2e4b4d8e1989b","bb9c43313b9747569bf2fa7646641fae","536ddfe6d93e4884a74308d7bc7e922a","6b7d3b0f7da845e081a1b1f5e7e61655","bde7137acbb44c6ca8ba732a4af0a8a8","d8fb2ce6535547b89dc12e2318099ca2","a58ec279b1e443c0bca85ec5eac0f2b7","58623b2481084e048abc0ba4b642367c","75a486cf3fca4495a5b6b537dd97b9c2","0232121ec17a4dde85beaf869b2db540","3224ff4f92e549c4b22fb62738b85a97","38e9b349c3ff49f99b14e9d66f618741","c2ec9845ba734b8c82df1d5d6516a8be","9c31fa911e3b434794a26568765dbb79","25d5efc7a33b42ddaa50e14be90654b4","09c32e5910704adaba90bac3db0c66b9","3b6d428fdbf04b52a39ae4a145f64375","34395be2fe494a95911b0d843a686c75","8a0bc629e19e4d5f964becabf9c953cf","a18475c7048141d886b45060227fde49","ad7060badd164f008a4caf4fd87cedde","56dccb33d4b94c33bc746571b87f1593","e8a61aa07ba54af1a0d569deed3da487","902c88b71fc1470cb1b28a2ca9c69271","4a5874d04ce1412a8c070da8e2ee4739","675b53d4c7ac49fda37b60a40be7dfc9","f6ebd36029574ad3a4652425b8401463","28f4880b692b4adc8032ca2a44b402cf","113e3fb6ca084cc68a88795172bc7d67","5792d4b3968d48599cf3e9d5707f6821","96374946536c473e85d00cea2fc14256"]},"id":"J8ohdOJCmB4m","executionInfo":{"status":"ok","timestamp":1693041143740,"user_tz":-540,"elapsed":2638,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"e4aedc80-7ca4-4435-fa3c-90541fededf7"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c11f8f3dcad453a9967d77ad8372f5f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0232121ec17a4dde85beaf869b2db540"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad7060badd164f008a4caf4fd87cedde"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['texts'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 23 # cls\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZyGX8bXmFgI","executionInfo":{"status":"ok","timestamp":1693041270139,"user_tz":-540,"elapsed":126405,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"14dddae4-58be-4ce8-fab7-976e99094179"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 471283/471283 [02:06<00:00, 3731.52it/s]\n","max_len: 97\n","INFO:__main__:max_len: 97\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df[CFG.target].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.half)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","class ValidDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df[CFG.target].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"HOhlEza3o2pR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        self.sig = nn.Sigmoid()\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        feature = self.layer_norm1(feature)\n","        output = self.fc(feature)\n","        #output = self.sig(output)\n","        return output"],"metadata":{"id":"bhk-PK8Mo-ia"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        #print(y_preds.sigmoid().squeeze().view(1, -1))\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        scaler.unscale_(optimizer)\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader),\n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds.view(-1, 1), labels.view(-1, 1))\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"vA_8DWfOpFRu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target].values\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = ValidDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_EXP_DIR+'config.pth')\n","    model.to(device)\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr,\n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = nn.BCEWithLogitsLoss()\n","\n","    best_score = -1.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","\n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","        f1_score = get_f1_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","\n","        if best_score < f1_score:\n","            best_score = f1_score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds"],"metadata":{"id":"Au28-HoKpISb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","\n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        f1_score = get_f1_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","        LOGGER.info(f'F1 BEST Score: {f1_score:<.4f}')\n","\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","            #break\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_EXP_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["4d64bf248f5d450382c526aca10dc959","c1c91464643a423197f686ec3224d102","b42bf0579b8d46ddbb76c254482c5bf4","85972f0ad47b450f99e90b6e544880c2","937ab54bdf4b417b88041c026b800b9f","79705da6978247f5a4070af6d0aa6464","cd69aa407e994503a9ec19df95d888e1","530d5a499da44537b047f360e6e7a331","4f7cdcf5886d475a93efe571ce881b9e","8c04ac063d14485f80722611c126d9f3","9f721ca58f484ea4bf723dd591173d0a"]},"id":"cDCGpigkpcaI","outputId":"2478e1c2-9ac4-411e-d57d-00e7b5d5609b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d64bf248f5d450382c526aca10dc959"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 3s (remain 386m 58s) Loss: 0.8779(0.8779) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 19s (remain 18m 35s) Loss: 0.2460(0.2716) Grad: 1.1382  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 35s (remain 16m 32s) Loss: 0.2573(0.2529) Grad: 1.3086  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 50s (remain 15m 33s) Loss: 0.2310(0.2429) Grad: 1.3982  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 1m 5s (remain 14m 59s) Loss: 0.1750(0.2385) Grad: 0.9111  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 1m 21s (remain 14m 35s) Loss: 0.2432(0.2340) Grad: 1.3765  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 1m 36s (remain 14m 11s) Loss: 0.1420(0.2312) Grad: 1.2037  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 52s (remain 13m 50s) Loss: 0.2595(0.2287) Grad: 1.1543  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 2m 7s (remain 13m 30s) Loss: 0.2981(0.2276) Grad: 0.8151  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 2m 25s (remain 13m 26s) Loss: 0.2428(0.2242) Grad: 1.0166  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 2m 41s (remain 13m 9s) Loss: 0.2708(0.2209) Grad: 1.4959  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 2m 56s (remain 12m 48s) Loss: 0.1799(0.2192) Grad: 0.5140  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 3m 11s (remain 12m 29s) Loss: 0.1523(0.2182) Grad: 0.5946  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 3m 27s (remain 12m 10s) Loss: 0.0617(0.2166) Grad: 0.8154  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 3m 42s (remain 11m 52s) Loss: 0.2341(0.2151) Grad: 0.5628  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 3m 57s (remain 11m 35s) Loss: 0.2299(0.2145) Grad: 0.8670  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 4m 13s (remain 11m 18s) Loss: 0.4902(0.2131) Grad: 2.2928  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 4m 28s (remain 11m 1s) Loss: 0.1969(0.2115) Grad: 0.5311  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 4m 43s (remain 10m 44s) Loss: 0.1379(0.2110) Grad: 1.3076  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 5m 2s (remain 10m 34s) Loss: 0.1587(0.2102) Grad: 0.5950  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 5m 17s (remain 10m 17s) Loss: 0.0848(0.2095) Grad: 0.6034  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 5m 33s (remain 10m 1s) Loss: 0.1392(0.2089) Grad: 0.7386  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 5m 48s (remain 9m 44s) Loss: 0.1532(0.2079) Grad: 0.4679  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 6m 4s (remain 9m 28s) Loss: 0.2615(0.2073) Grad: 1.1831  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 6m 19s (remain 9m 11s) Loss: 0.1085(0.2059) Grad: 0.3861  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 6m 34s (remain 8m 55s) Loss: 0.3469(0.2055) Grad: 1.8003  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 6m 49s (remain 8m 38s) Loss: 0.2551(0.2050) Grad: 1.1574  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 7m 4s (remain 8m 21s) Loss: 0.2271(0.2040) Grad: 1.5859  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 7m 20s (remain 8m 5s) Loss: 0.1816(0.2032) Grad: 0.7336  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 7m 38s (remain 7m 52s) Loss: 0.1050(0.2026) Grad: 1.1529  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 7m 54s (remain 7m 36s) Loss: 0.1157(0.2018) Grad: 1.4973  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 8m 9s (remain 7m 20s) Loss: 0.0765(0.2013) Grad: 0.6110  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 8m 24s (remain 7m 3s) Loss: 0.0882(0.2011) Grad: 1.1883  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 8m 39s (remain 6m 47s) Loss: 0.0731(0.2006) Grad: 0.4308  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 8m 55s (remain 6m 31s) Loss: 0.1366(0.1999) Grad: 0.9066  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 9m 10s (remain 6m 15s) Loss: 0.1892(0.1993) Grad: 0.6619  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 9m 25s (remain 5m 59s) Loss: 0.1975(0.1988) Grad: 0.4928  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 9m 41s (remain 5m 44s) Loss: 0.3289(0.1984) Grad: 2.1387  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 9m 57s (remain 5m 28s) Loss: 0.1812(0.1981) Grad: 0.6545  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 10m 15s (remain 5m 13s) Loss: 0.1364(0.1973) Grad: 0.5831  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 10m 30s (remain 4m 57s) Loss: 0.1671(0.1969) Grad: 0.7090  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 10m 46s (remain 4m 41s) Loss: 0.3040(0.1966) Grad: 1.3940  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 11m 1s (remain 4m 26s) Loss: 0.1173(0.1960) Grad: 0.6555  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 11m 16s (remain 4m 10s) Loss: 0.1589(0.1956) Grad: 0.8766  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 11m 32s (remain 3m 54s) Loss: 0.1677(0.1952) Grad: 0.9580  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 11m 47s (remain 3m 38s) Loss: 0.2446(0.1949) Grad: 0.7855  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 12m 2s (remain 3m 22s) Loss: 0.1862(0.1945) Grad: 1.0803  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 12m 17s (remain 3m 6s) Loss: 0.1037(0.1939) Grad: 0.7908  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 12m 34s (remain 2m 51s) Loss: 0.1647(0.1936) Grad: 0.9336  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 12m 49s (remain 2m 35s) Loss: 0.1385(0.1931) Grad: 0.3556  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 13m 4s (remain 2m 19s) Loss: 0.2791(0.1928) Grad: 1.4889  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 13m 20s (remain 2m 3s) Loss: 0.2783(0.1926) Grad: 0.9004  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 13m 35s (remain 1m 48s) Loss: 0.1111(0.1925) Grad: 0.7054  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 13m 50s (remain 1m 32s) Loss: 0.1033(0.1920) Grad: 0.8218  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 14m 6s (remain 1m 16s) Loss: 0.3787(0.1920) Grad: 1.6623  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 14m 21s (remain 1m 1s) Loss: 0.1536(0.1916) Grad: 2.9233  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 14m 36s (remain 0m 45s) Loss: 0.0767(0.1916) Grad: 0.6704  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 14m 51s (remain 0m 29s) Loss: 0.1914(0.1914) Grad: 0.3747  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 15m 7s (remain 0m 14s) Loss: 0.1385(0.1912) Grad: 0.7721  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 15m 22s (remain 0m 0s) Loss: 0.2368(0.1907) Grad: 1.6606  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 7m 2s) Loss: 0.1673(0.1673) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 0s) Loss: 0.2410(0.1377) \n","EVAL: [200/737] Elapsed 0m 37s (remain 1m 40s) Loss: 0.2349(0.1601) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 21s) Loss: 0.1809(0.1721) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.2401(0.1764) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.2060(0.1799) \n","EVAL: [600/737] Elapsed 1m 52s (remain 0m 25s) Loss: 0.1823(0.1794) \n","EVAL: [700/737] Elapsed 2m 11s (remain 0m 6s) Loss: 0.1095(0.1755) \n","EVAL: [736/737] Elapsed 2m 18s (remain 0m 0s) Loss: 0.0208(0.1737) \n","f1 score : 0.40842572062084265\n","recall score : 0.28225559301256514\n","precision score : 0.7385725741780272\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.1907  avg_val_loss: 0.1737  time: 1065s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.1907  avg_val_loss: 0.1737  time: 1065s\n","Epoch 1 - Score: 0.4084\n","INFO:__main__:Epoch 1 - Score: 0.4084\n","Epoch 1 - Save Best Score: 0.5016 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5016 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 73m 56s) Loss: 0.2505(0.2505) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 18s (remain 17m 34s) Loss: 0.0740(0.1596) Grad: 1.4657  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 34s (remain 16m 12s) Loss: 0.1292(0.1704) Grad: 0.9309  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 49s (remain 15m 27s) Loss: 0.2126(0.1691) Grad: 1.0573  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 1m 5s (remain 14m 54s) Loss: 0.0588(0.1682) Grad: 1.0193  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 1m 20s (remain 14m 27s) Loss: 0.1392(0.1702) Grad: 0.3424  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 1m 36s (remain 14m 6s) Loss: 0.2793(0.1680) Grad: 1.2662  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 51s (remain 13m 45s) Loss: 0.1515(0.1686) Grad: 0.5364  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 2m 6s (remain 13m 25s) Loss: 0.2137(0.1677) Grad: 1.1241  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 2m 22s (remain 13m 9s) Loss: 0.2289(0.1678) Grad: 1.3040  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 2m 41s (remain 13m 7s) Loss: 0.1744(0.1681) Grad: 0.8553  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 2m 57s (remain 12m 51s) Loss: 0.2001(0.1666) Grad: 0.8981  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 3m 12s (remain 12m 33s) Loss: 0.1760(0.1676) Grad: 0.9083  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 3m 28s (remain 12m 16s) Loss: 0.2422(0.1674) Grad: 0.8691  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 3m 44s (remain 11m 58s) Loss: 0.0947(0.1672) Grad: 1.4091  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 3m 59s (remain 11m 41s) Loss: 0.0674(0.1673) Grad: 1.6280  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 4m 15s (remain 11m 24s) Loss: 0.2147(0.1676) Grad: 0.8831  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 4m 31s (remain 11m 8s) Loss: 0.0455(0.1676) Grad: 0.5455  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 4m 47s (remain 10m 52s) Loss: 0.2791(0.1680) Grad: 0.9659  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 5m 6s (remain 10m 42s) Loss: 0.0846(0.1674) Grad: 0.4713  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 5m 22s (remain 10m 26s) Loss: 0.0779(0.1672) Grad: 0.8975  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 5m 37s (remain 10m 9s) Loss: 0.1931(0.1676) Grad: 1.3335  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 5m 53s (remain 9m 52s) Loss: 0.2905(0.1678) Grad: 0.7581  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 6m 9s (remain 9m 36s) Loss: 0.2159(0.1681) Grad: 1.4109  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 6m 25s (remain 9m 19s) Loss: 0.2485(0.1681) Grad: 0.9189  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 6m 41s (remain 9m 3s) Loss: 0.0847(0.1680) Grad: 0.8577  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 6m 56s (remain 8m 47s) Loss: 0.1232(0.1674) Grad: 0.5769  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 7m 12s (remain 8m 30s) Loss: 0.1462(0.1677) Grad: 0.5681  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 7m 29s (remain 8m 15s) Loss: 0.1682(0.1678) Grad: 0.5111  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 7m 46s (remain 8m 1s) Loss: 0.1329(0.1677) Grad: 0.6119  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 8m 2s (remain 7m 44s) Loss: 0.1448(0.1675) Grad: 0.5481  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 8m 18s (remain 7m 28s) Loss: 0.1539(0.1673) Grad: 0.8803  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 8m 34s (remain 7m 12s) Loss: 0.3518(0.1674) Grad: 1.5109  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 8m 49s (remain 6m 55s) Loss: 0.1484(0.1671) Grad: 0.8183  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 9m 5s (remain 6m 39s) Loss: 0.1235(0.1670) Grad: 0.9043  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 9m 21s (remain 6m 23s) Loss: 0.2175(0.1669) Grad: 1.0145  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 9m 37s (remain 6m 7s) Loss: 0.1730(0.1668) Grad: 0.9218  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 9m 53s (remain 5m 50s) Loss: 0.1558(0.1669) Grad: 1.8004  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 10m 12s (remain 5m 36s) Loss: 0.1499(0.1666) Grad: 0.6444  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 10m 28s (remain 5m 20s) Loss: 0.2632(0.1666) Grad: 1.4956  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 10m 43s (remain 5m 4s) Loss: 0.0635(0.1661) Grad: 0.6075  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 10m 59s (remain 4m 47s) Loss: 0.1753(0.1658) Grad: 0.7682  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 11m 14s (remain 4m 31s) Loss: 0.2394(0.1657) Grad: 1.4538  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 11m 30s (remain 4m 15s) Loss: 0.1555(0.1656) Grad: 0.6898  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 11m 45s (remain 3m 58s) Loss: 0.1437(0.1654) Grad: 0.5456  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 12m 0s (remain 3m 42s) Loss: 0.1328(0.1652) Grad: 0.8232  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 12m 16s (remain 3m 26s) Loss: 0.1216(0.1653) Grad: 0.7341  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 12m 32s (remain 3m 10s) Loss: 0.1304(0.1651) Grad: 0.6215  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 12m 51s (remain 2m 55s) Loss: 0.1053(0.1648) Grad: 0.5827  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 13m 7s (remain 2m 38s) Loss: 0.1069(0.1647) Grad: 0.5631  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 13m 22s (remain 2m 22s) Loss: 0.1769(0.1647) Grad: 0.8538  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 13m 38s (remain 2m 6s) Loss: 0.2534(0.1646) Grad: 1.0640  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 13m 54s (remain 1m 50s) Loss: 0.2466(0.1645) Grad: 1.3483  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 14m 9s (remain 1m 34s) Loss: 0.0939(0.1643) Grad: 0.7882  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 14m 25s (remain 1m 18s) Loss: 0.2292(0.1643) Grad: 1.4865  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 14m 40s (remain 1m 2s) Loss: 0.0946(0.1642) Grad: 0.3693  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 14m 56s (remain 0m 46s) Loss: 0.1263(0.1642) Grad: 0.6281  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 15m 14s (remain 0m 30s) Loss: 0.1132(0.1642) Grad: 0.5271  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 15m 31s (remain 0m 14s) Loss: 0.1406(0.1640) Grad: 0.8708  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 15m 45s (remain 0m 0s) Loss: 0.2659(0.1640) Grad: 1.1601  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 11m 44s) Loss: 0.1615(0.1615) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 3s) Loss: 0.2164(0.1302) \n","EVAL: [200/737] Elapsed 0m 38s (remain 1m 42s) Loss: 0.1941(0.1478) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 22s) Loss: 0.1662(0.1572) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.2211(0.1618) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.1736(0.1646) \n","EVAL: [600/737] Elapsed 1m 53s (remain 0m 25s) Loss: 0.1631(0.1642) \n","EVAL: [700/737] Elapsed 2m 12s (remain 0m 6s) Loss: 0.0951(0.1603) \n","EVAL: [736/737] Elapsed 2m 19s (remain 0m 0s) Loss: 0.0304(0.1587) \n","f1 score : 0.4729362591431556\n","recall score : 0.34676677903769537\n","precision score : 0.7434296977660972\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.1640  avg_val_loss: 0.1587  time: 1088s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1640  avg_val_loss: 0.1587  time: 1088s\n","Epoch 2 - Score: 0.4729\n","INFO:__main__:Epoch 2 - Score: 0.4729\n","Epoch 2 - Save Best Score: 0.5337 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5337 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 59m 34s) Loss: 0.2137(0.2137) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 17s (remain 16m 34s) Loss: 0.1592(0.1453) Grad: 0.9910  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 33s (remain 15m 55s) Loss: 0.1791(0.1481) Grad: 1.0324  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 49s (remain 15m 16s) Loss: 0.2395(0.1503) Grad: 1.5315  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 1m 4s (remain 14m 48s) Loss: 0.1305(0.1543) Grad: 0.8272  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 1m 20s (remain 14m 27s) Loss: 0.0743(0.1541) Grad: 0.9021  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 1m 36s (remain 14m 6s) Loss: 0.1967(0.1531) Grad: 0.8713  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 51s (remain 13m 45s) Loss: 0.2288(0.1539) Grad: 0.8015  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 2m 9s (remain 13m 43s) Loss: 0.1584(0.1537) Grad: 0.6136  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 2m 25s (remain 13m 25s) Loss: 0.2261(0.1534) Grad: 0.9286  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 2m 40s (remain 13m 4s) Loss: 0.1575(0.1541) Grad: 0.4604  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 2m 55s (remain 12m 44s) Loss: 0.1053(0.1537) Grad: 0.5762  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 3m 10s (remain 12m 25s) Loss: 0.1100(0.1535) Grad: 0.8933  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 3m 26s (remain 12m 7s) Loss: 0.1009(0.1536) Grad: 0.9482  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 3m 41s (remain 11m 49s) Loss: 0.1063(0.1532) Grad: 0.6895  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 3m 56s (remain 11m 32s) Loss: 0.1040(0.1532) Grad: 1.1780  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 4m 12s (remain 11m 15s) Loss: 0.1189(0.1537) Grad: 0.5516  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 4m 27s (remain 10m 59s) Loss: 0.1812(0.1535) Grad: 0.9481  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 4m 46s (remain 10m 49s) Loss: 0.0613(0.1542) Grad: 0.8678  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 5m 1s (remain 10m 33s) Loss: 0.0809(0.1540) Grad: 0.7779  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 5m 17s (remain 10m 16s) Loss: 0.1790(0.1545) Grad: 0.7600  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 5m 32s (remain 9m 59s) Loss: 0.1682(0.1548) Grad: 0.5410  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 5m 47s (remain 9m 43s) Loss: 0.0819(0.1544) Grad: 1.1123  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 6m 3s (remain 9m 26s) Loss: 0.2137(0.1547) Grad: 0.8275  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 6m 18s (remain 9m 10s) Loss: 0.0943(0.1545) Grad: 0.6167  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 6m 33s (remain 8m 53s) Loss: 0.0471(0.1539) Grad: 0.5858  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 6m 49s (remain 8m 37s) Loss: 0.1376(0.1537) Grad: 0.9881  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 7m 4s (remain 8m 21s) Loss: 0.0485(0.1536) Grad: 0.6588  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 7m 22s (remain 8m 8s) Loss: 0.1033(0.1534) Grad: 1.0247  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 7m 38s (remain 7m 52s) Loss: 0.1947(0.1533) Grad: 1.3760  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 7m 53s (remain 7m 36s) Loss: 0.2546(0.1534) Grad: 1.1408  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 8m 9s (remain 7m 20s) Loss: 0.0616(0.1535) Grad: 1.0322  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 8m 24s (remain 7m 4s) Loss: 0.1198(0.1534) Grad: 1.5334  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 8m 39s (remain 6m 47s) Loss: 0.1141(0.1534) Grad: 0.5125  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 8m 55s (remain 6m 31s) Loss: 0.1499(0.1536) Grad: 0.9572  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 9m 10s (remain 6m 15s) Loss: 0.0566(0.1538) Grad: 0.9161  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 9m 25s (remain 5m 59s) Loss: 0.0977(0.1534) Grad: 0.8075  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 9m 41s (remain 5m 43s) Loss: 0.3579(0.1532) Grad: 1.8214  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 9m 59s (remain 5m 29s) Loss: 0.1284(0.1533) Grad: 1.0711  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 10m 15s (remain 5m 13s) Loss: 0.1221(0.1532) Grad: 0.5534  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 10m 30s (remain 4m 57s) Loss: 0.1453(0.1530) Grad: 0.8728  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 10m 46s (remain 4m 41s) Loss: 0.0834(0.1528) Grad: 1.1647  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 11m 1s (remain 4m 26s) Loss: 0.1638(0.1527) Grad: 0.7109  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 11m 17s (remain 4m 10s) Loss: 0.0768(0.1527) Grad: 0.6469  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 11m 32s (remain 3m 54s) Loss: 0.2554(0.1526) Grad: 1.6257  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 11m 48s (remain 3m 38s) Loss: 0.0715(0.1526) Grad: 0.7169  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 12m 3s (remain 3m 22s) Loss: 0.1031(0.1525) Grad: 0.7137  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 12m 19s (remain 3m 7s) Loss: 0.1809(0.1525) Grad: 0.5379  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 12m 37s (remain 2m 52s) Loss: 0.1223(0.1526) Grad: 1.0069  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 12m 53s (remain 2m 36s) Loss: 0.1086(0.1525) Grad: 0.6744  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 13m 8s (remain 2m 20s) Loss: 0.0509(0.1524) Grad: 1.1788  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 13m 24s (remain 2m 4s) Loss: 0.2036(0.1527) Grad: 0.8023  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 13m 39s (remain 1m 48s) Loss: 0.1826(0.1528) Grad: 0.8083  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 13m 54s (remain 1m 32s) Loss: 0.0641(0.1527) Grad: 0.5697  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 14m 9s (remain 1m 17s) Loss: 0.2162(0.1527) Grad: 0.9353  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 14m 25s (remain 1m 1s) Loss: 0.1876(0.1525) Grad: 0.9174  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 14m 40s (remain 0m 45s) Loss: 0.1278(0.1524) Grad: 1.0618  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 14m 56s (remain 0m 29s) Loss: 0.1274(0.1522) Grad: 0.7136  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 15m 15s (remain 0m 14s) Loss: 0.2185(0.1522) Grad: 1.0448  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 15m 29s (remain 0m 0s) Loss: 0.2118(0.1523) Grad: 1.0433  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 6m 13s) Loss: 0.1696(0.1696) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 0s) Loss: 0.2190(0.1285) \n","EVAL: [200/737] Elapsed 0m 37s (remain 1m 40s) Loss: 0.1942(0.1461) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 21s) Loss: 0.1607(0.1552) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.2269(0.1597) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.1844(0.1623) \n","EVAL: [600/737] Elapsed 1m 53s (remain 0m 25s) Loss: 0.1702(0.1616) \n","EVAL: [700/737] Elapsed 2m 12s (remain 0m 6s) Loss: 0.0980(0.1579) \n","EVAL: [736/737] Elapsed 2m 19s (remain 0m 0s) Loss: 0.0237(0.1563) \n","f1 score : 0.48932676518883417\n","recall score : 0.3653079987741342\n","precision score : 0.7408328154133001\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1523  avg_val_loss: 0.1563  time: 1073s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1523  avg_val_loss: 0.1563  time: 1073s\n","Epoch 3 - Score: 0.4893\n","INFO:__main__:Epoch 3 - Score: 0.4893\n","Epoch 3 - Save Best Score: 0.5496 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5496 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 56m 35s) Loss: 0.0557(0.0557) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 17s (remain 16m 32s) Loss: 0.1824(0.1510) Grad: 0.9307  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 33s (remain 15m 41s) Loss: 0.1097(0.1440) Grad: 0.5207  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 48s (remain 15m 1s) Loss: 0.1058(0.1465) Grad: 0.7026  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 1m 3s (remain 14m 35s) Loss: 0.2727(0.1425) Grad: 1.2320  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 1m 19s (remain 14m 15s) Loss: 0.2173(0.1441) Grad: 0.7424  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 1m 34s (remain 13m 55s) Loss: 0.0859(0.1444) Grad: 1.1496  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 50s (remain 13m 36s) Loss: 0.1646(0.1447) Grad: 0.9040  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 2m 5s (remain 13m 18s) Loss: 0.1671(0.1450) Grad: 0.9063  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 2m 21s (remain 13m 3s) Loss: 0.0347(0.1449) Grad: 0.7459  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 2m 40s (remain 13m 1s) Loss: 0.0979(0.1445) Grad: 1.2299  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 2m 55s (remain 12m 42s) Loss: 0.0559(0.1441) Grad: 1.3144  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 3m 10s (remain 12m 24s) Loss: 0.1104(0.1439) Grad: 0.7710  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 3m 25s (remain 12m 5s) Loss: 0.1768(0.1437) Grad: 0.6573  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 3m 40s (remain 11m 47s) Loss: 0.0935(0.1433) Grad: 1.2052  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 3m 56s (remain 11m 30s) Loss: 0.1531(0.1433) Grad: 0.8250  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 4m 11s (remain 11m 13s) Loss: 0.0946(0.1442) Grad: 0.6987  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 4m 26s (remain 10m 57s) Loss: 0.0972(0.1434) Grad: 0.6387  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 4m 42s (remain 10m 41s) Loss: 0.2983(0.1433) Grad: 1.3873  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 4m 57s (remain 10m 24s) Loss: 0.1718(0.1434) Grad: 0.5904  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 5m 16s (remain 10m 15s) Loss: 0.0371(0.1427) Grad: 0.9693  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 5m 32s (remain 9m 59s) Loss: 0.1652(0.1427) Grad: 0.6733  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 5m 47s (remain 9m 42s) Loss: 0.2089(0.1430) Grad: 0.7625  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 6m 2s (remain 9m 26s) Loss: 0.1841(0.1430) Grad: 1.0570  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 6m 18s (remain 9m 10s) Loss: 0.1426(0.1429) Grad: 1.2469  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 6m 33s (remain 8m 53s) Loss: 0.3213(0.1429) Grad: 1.6394  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 6m 49s (remain 8m 37s) Loss: 0.1465(0.1428) Grad: 1.0109  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 7m 4s (remain 8m 21s) Loss: 0.1372(0.1428) Grad: 1.1492  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 7m 19s (remain 8m 5s) Loss: 0.1960(0.1424) Grad: 1.0923  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 7m 35s (remain 7m 49s) Loss: 0.0490(0.1429) Grad: 0.7563  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 7m 53s (remain 7m 36s) Loss: 0.1138(0.1431) Grad: 1.1978  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 8m 8s (remain 7m 19s) Loss: 0.1349(0.1429) Grad: 0.9143  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 8m 24s (remain 7m 3s) Loss: 0.0733(0.1429) Grad: 1.2851  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 8m 39s (remain 6m 47s) Loss: 0.1582(0.1429) Grad: 0.9714  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 8m 55s (remain 6m 31s) Loss: 0.1914(0.1429) Grad: 0.8504  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 9m 10s (remain 6m 15s) Loss: 0.2484(0.1430) Grad: 1.3592  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 9m 26s (remain 6m 0s) Loss: 0.1198(0.1430) Grad: 0.8459  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 9m 41s (remain 5m 44s) Loss: 0.1622(0.1430) Grad: 1.0661  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 9m 56s (remain 5m 28s) Loss: 0.1272(0.1431) Grad: 0.5833  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 10m 12s (remain 5m 12s) Loss: 0.2651(0.1430) Grad: 1.7570  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 10m 30s (remain 4m 57s) Loss: 0.1686(0.1431) Grad: 1.1006  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 10m 45s (remain 4m 41s) Loss: 0.0891(0.1432) Grad: 0.6338  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 11m 1s (remain 4m 25s) Loss: 0.2325(0.1431) Grad: 1.1899  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 11m 16s (remain 4m 10s) Loss: 0.1102(0.1433) Grad: 0.7549  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 11m 31s (remain 3m 54s) Loss: 0.1143(0.1435) Grad: 0.7130  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 11m 46s (remain 3m 38s) Loss: 0.1582(0.1436) Grad: 0.9462  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 12m 2s (remain 3m 22s) Loss: 0.2031(0.1438) Grad: 1.1591  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 12m 17s (remain 3m 6s) Loss: 0.1603(0.1436) Grad: 0.7047  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 12m 33s (remain 2m 50s) Loss: 0.2532(0.1439) Grad: 1.2899  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 12m 48s (remain 2m 35s) Loss: 0.1422(0.1439) Grad: 0.6707  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 13m 7s (remain 2m 20s) Loss: 0.1366(0.1437) Grad: 1.4074  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 13m 22s (remain 2m 4s) Loss: 0.2184(0.1437) Grad: 1.2530  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 13m 38s (remain 1m 48s) Loss: 0.1296(0.1437) Grad: 0.8626  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 13m 53s (remain 1m 32s) Loss: 0.1749(0.1435) Grad: 1.1289  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 14m 8s (remain 1m 17s) Loss: 0.1005(0.1434) Grad: 0.7712  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 14m 24s (remain 1m 1s) Loss: 0.1449(0.1433) Grad: 1.1813  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 14m 39s (remain 0m 45s) Loss: 0.1332(0.1433) Grad: 1.0954  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 14m 55s (remain 0m 29s) Loss: 0.1074(0.1434) Grad: 0.8989  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 15m 10s (remain 0m 14s) Loss: 0.1995(0.1433) Grad: 1.2233  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 15m 23s (remain 0m 0s) Loss: 0.1262(0.1431) Grad: 0.7986  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 1s (remain 14m 5s) Loss: 0.1716(0.1716) \n","EVAL: [100/737] Elapsed 0m 20s (remain 2m 6s) Loss: 0.2095(0.1297) \n","EVAL: [200/737] Elapsed 0m 38s (remain 1m 43s) Loss: 0.1955(0.1461) \n","EVAL: [300/737] Elapsed 0m 57s (remain 1m 23s) Loss: 0.1619(0.1546) \n","EVAL: [400/737] Elapsed 1m 16s (remain 1m 4s) Loss: 0.2299(0.1591) \n","EVAL: [500/737] Elapsed 1m 35s (remain 0m 44s) Loss: 0.1748(0.1617) \n","EVAL: [600/737] Elapsed 1m 54s (remain 0m 25s) Loss: 0.1680(0.1610) \n","EVAL: [700/737] Elapsed 2m 12s (remain 0m 6s) Loss: 0.1004(0.1574) \n","EVAL: [736/737] Elapsed 2m 19s (remain 0m 0s) Loss: 0.0224(0.1558) \n","f1 score : 0.5036948272418613\n","recall score : 0.38645418326693226\n","precision score : 0.7230504587155964\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1431  avg_val_loss: 0.1558  time: 1068s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1431  avg_val_loss: 0.1558  time: 1068s\n","Epoch 4 - Score: 0.5037\n","INFO:__main__:Epoch 4 - Score: 0.5037\n","Epoch 4 - Save Best Score: 0.5550 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.5550 Model\n","========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.5036948272418613\n","recall score : 0.38645418326693226\n","precision score : 0.7230504587155964\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.5037\n","INFO:__main__:Score: 0.5037\n","F1 BEST Score: 0.5550\n","INFO:__main__:F1 BEST Score: 0.5550\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 1s (remain 143m 11s) Loss: 0.6782(0.6782) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 19s (remain 18m 34s) Loss: 0.2499(0.2752) Grad: 0.9331  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 34s (remain 16m 19s) Loss: 0.1604(0.2529) Grad: 0.7039  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 50s (remain 15m 29s) Loss: 0.1444(0.2407) Grad: 0.6625  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 1m 5s (remain 14m 57s) Loss: 0.2632(0.2329) Grad: 1.1136  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 1m 20s (remain 14m 31s) Loss: 0.2837(0.2293) Grad: 0.7751  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 1m 36s (remain 14m 8s) Loss: 0.1332(0.2222) Grad: 0.4975  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 51s (remain 13m 48s) Loss: 0.3552(0.2198) Grad: 1.0047  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 2m 7s (remain 13m 29s) Loss: 0.1577(0.2173) Grad: 1.0632  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 2m 23s (remain 13m 15s) Loss: 0.1771(0.2144) Grad: 0.5723  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 2m 41s (remain 13m 7s) Loss: 0.1948(0.2135) Grad: 0.4844  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 2m 56s (remain 12m 48s) Loss: 0.1359(0.2113) Grad: 1.3055  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 3m 12s (remain 12m 30s) Loss: 0.3059(0.2107) Grad: 0.8301  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 3m 27s (remain 12m 11s) Loss: 0.3352(0.2106) Grad: 1.2420  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 3m 42s (remain 11m 52s) Loss: 0.1523(0.2097) Grad: 1.4606  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 3m 57s (remain 11m 34s) Loss: 0.2164(0.2081) Grad: 0.8900  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 4m 12s (remain 11m 17s) Loss: 0.1656(0.2076) Grad: 0.8614  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 4m 27s (remain 10m 59s) Loss: 0.1539(0.2072) Grad: 0.6353  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 4m 42s (remain 10m 42s) Loss: 0.1598(0.2065) Grad: 0.8203  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 4m 59s (remain 10m 29s) Loss: 0.1691(0.2055) Grad: 0.6163  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 5m 16s (remain 10m 15s) Loss: 0.1530(0.2046) Grad: 1.4280  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 5m 32s (remain 9m 59s) Loss: 0.1635(0.2042) Grad: 1.0875  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 5m 47s (remain 9m 42s) Loss: 0.1849(0.2038) Grad: 0.6316  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 6m 3s (remain 9m 26s) Loss: 0.1223(0.2032) Grad: 1.1625  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 6m 18s (remain 9m 10s) Loss: 0.1802(0.2026) Grad: 0.6853  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 6m 34s (remain 8m 54s) Loss: 0.2010(0.2022) Grad: 1.0679  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 6m 49s (remain 8m 37s) Loss: 0.3059(0.2019) Grad: 1.0367  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 7m 4s (remain 8m 21s) Loss: 0.2766(0.2011) Grad: 1.6717  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 7m 19s (remain 8m 5s) Loss: 0.2051(0.2002) Grad: 0.4825  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 7m 38s (remain 7m 52s) Loss: 0.1768(0.1998) Grad: 0.6856  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 7m 53s (remain 7m 35s) Loss: 0.0929(0.1989) Grad: 0.9265  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 8m 8s (remain 7m 19s) Loss: 0.1226(0.1983) Grad: 1.3337  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 8m 23s (remain 7m 3s) Loss: 0.2710(0.1977) Grad: 1.3238  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 8m 38s (remain 6m 47s) Loss: 0.1693(0.1971) Grad: 0.7251  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 8m 53s (remain 6m 30s) Loss: 0.1079(0.1966) Grad: 0.4846  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 9m 9s (remain 6m 14s) Loss: 0.2029(0.1959) Grad: 0.7283  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 9m 24s (remain 5m 58s) Loss: 0.3057(0.1955) Grad: 1.4478  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 9m 39s (remain 5m 42s) Loss: 0.0848(0.1948) Grad: 0.9548  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 9m 55s (remain 5m 27s) Loss: 0.1559(0.1943) Grad: 0.9582  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 10m 12s (remain 5m 12s) Loss: 0.1323(0.1939) Grad: 1.3390  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 10m 28s (remain 4m 56s) Loss: 0.1510(0.1933) Grad: 0.7087  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 10m 43s (remain 4m 40s) Loss: 0.1857(0.1928) Grad: 1.1800  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 10m 58s (remain 4m 24s) Loss: 0.1750(0.1922) Grad: 0.5904  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 11m 13s (remain 4m 9s) Loss: 0.2445(0.1919) Grad: 1.3007  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 11m 29s (remain 3m 53s) Loss: 0.1649(0.1915) Grad: 0.8798  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 11m 44s (remain 3m 37s) Loss: 0.0642(0.1913) Grad: 1.0746  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 12m 0s (remain 3m 21s) Loss: 0.2338(0.1910) Grad: 0.7484  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 12m 15s (remain 3m 6s) Loss: 0.2296(0.1906) Grad: 1.3999  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 12m 33s (remain 2m 50s) Loss: 0.1242(0.1904) Grad: 1.8957  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 12m 49s (remain 2m 35s) Loss: 0.1654(0.1902) Grad: 0.9632  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 13m 4s (remain 2m 19s) Loss: 0.2510(0.1901) Grad: 0.8900  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 13m 19s (remain 2m 3s) Loss: 0.0991(0.1898) Grad: 0.4523  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 13m 34s (remain 1m 48s) Loss: 0.3872(0.1894) Grad: 2.2318  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 13m 50s (remain 1m 32s) Loss: 0.1820(0.1888) Grad: 0.7257  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 14m 5s (remain 1m 16s) Loss: 0.2393(0.1884) Grad: 1.2698  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 14m 21s (remain 1m 1s) Loss: 0.4172(0.1882) Grad: 2.1650  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 14m 36s (remain 0m 45s) Loss: 0.1467(0.1880) Grad: 0.6110  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 14m 53s (remain 0m 29s) Loss: 0.1300(0.1875) Grad: 0.7620  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 15m 9s (remain 0m 14s) Loss: 0.1065(0.1874) Grad: 0.9928  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 15m 23s (remain 0m 0s) Loss: 0.2915(0.1870) Grad: 0.8272  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 10m 37s) Loss: 0.1749(0.1749) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 2s) Loss: 0.1076(0.1365) \n","EVAL: [200/737] Elapsed 0m 38s (remain 1m 41s) Loss: 0.2622(0.1546) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 22s) Loss: 0.0992(0.1638) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.1959(0.1699) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.1568(0.1715) \n","EVAL: [600/737] Elapsed 1m 53s (remain 0m 25s) Loss: 0.1609(0.1714) \n","EVAL: [700/737] Elapsed 2m 12s (remain 0m 6s) Loss: 0.1303(0.1682) \n","EVAL: [736/737] Elapsed 2m 19s (remain 0m 0s) Loss: 0.0941(0.1665) \n","f1 score : 0.4177298724153101\n","recall score : 0.2909898866074165\n","precision score : 0.740062353858145\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.1870  avg_val_loss: 0.1665  time: 1065s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.1870  avg_val_loss: 0.1665  time: 1065s\n","Epoch 1 - Score: 0.4177\n","INFO:__main__:Epoch 1 - Score: 0.4177\n","Epoch 1 - Save Best Score: 0.5149 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5149 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 61m 42s) Loss: 0.1142(0.1142) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 17s (remain 16m 26s) Loss: 0.1337(0.1582) Grad: 1.5159  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 32s (remain 15m 32s) Loss: 0.1069(0.1619) Grad: 0.5461  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 48s (remain 14m 54s) Loss: 0.0955(0.1626) Grad: 0.6463  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 1m 3s (remain 14m 27s) Loss: 0.2423(0.1607) Grad: 0.6304  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 1m 18s (remain 14m 4s) Loss: 0.1184(0.1613) Grad: 0.3937  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 1m 33s (remain 13m 44s) Loss: 0.0673(0.1632) Grad: 0.5698  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 48s (remain 13m 24s) Loss: 0.1065(0.1628) Grad: 0.5968  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 2m 5s (remain 13m 15s) Loss: 0.2849(0.1637) Grad: 1.2411  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 2m 21s (remain 13m 4s) Loss: 0.0777(0.1632) Grad: 0.6590  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 2m 36s (remain 12m 46s) Loss: 0.1846(0.1640) Grad: 0.7430  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 2m 51s (remain 12m 26s) Loss: 0.0684(0.1639) Grad: 0.8215  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 3m 6s (remain 12m 8s) Loss: 0.1282(0.1637) Grad: 0.5240  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 3m 21s (remain 11m 52s) Loss: 0.1255(0.1636) Grad: 0.5678  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 3m 37s (remain 11m 35s) Loss: 0.1061(0.1644) Grad: 0.8302  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 3m 52s (remain 11m 19s) Loss: 0.1508(0.1650) Grad: 0.7908  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 4m 6s (remain 11m 1s) Loss: 0.1472(0.1646) Grad: 0.9217  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 4m 22s (remain 10m 45s) Loss: 0.1741(0.1646) Grad: 0.5962  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 4m 40s (remain 10m 36s) Loss: 0.0544(0.1640) Grad: 1.1449  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 4m 55s (remain 10m 20s) Loss: 0.2390(0.1636) Grad: 1.1265  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 5m 10s (remain 10m 4s) Loss: 0.2014(0.1640) Grad: 1.1327  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 5m 25s (remain 9m 47s) Loss: 0.1841(0.1638) Grad: 0.7375  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 5m 40s (remain 9m 31s) Loss: 0.1475(0.1642) Grad: 1.1912  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 5m 55s (remain 9m 14s) Loss: 0.1191(0.1636) Grad: 0.9250  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 6m 10s (remain 8m 58s) Loss: 0.0565(0.1637) Grad: 0.8412  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 6m 25s (remain 8m 42s) Loss: 0.0955(0.1634) Grad: 0.7001  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 6m 40s (remain 8m 26s) Loss: 0.1647(0.1639) Grad: 1.0958  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 6m 55s (remain 8m 11s) Loss: 0.2179(0.1637) Grad: 0.9090  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 7m 14s (remain 7m 59s) Loss: 0.2073(0.1635) Grad: 0.7917  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 7m 29s (remain 7m 43s) Loss: 0.1233(0.1637) Grad: 0.7786  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 7m 45s (remain 7m 27s) Loss: 0.1885(0.1637) Grad: 0.8156  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 8m 0s (remain 7m 12s) Loss: 0.1378(0.1633) Grad: 0.9566  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 8m 15s (remain 6m 56s) Loss: 0.1896(0.1633) Grad: 1.1262  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 8m 31s (remain 6m 41s) Loss: 0.1104(0.1631) Grad: 0.5669  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 8m 46s (remain 6m 25s) Loss: 0.2465(0.1632) Grad: 1.0379  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 9m 1s (remain 6m 9s) Loss: 0.3020(0.1633) Grad: 0.9673  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 9m 16s (remain 5m 53s) Loss: 0.1633(0.1631) Grad: 0.7261  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 9m 32s (remain 5m 38s) Loss: 0.1489(0.1633) Grad: 0.7011  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 9m 50s (remain 5m 24s) Loss: 0.0484(0.1632) Grad: 0.6976  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 10m 5s (remain 5m 8s) Loss: 0.2229(0.1633) Grad: 1.4924  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 10m 20s (remain 4m 53s) Loss: 0.2196(0.1634) Grad: 0.9678  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 10m 35s (remain 4m 37s) Loss: 0.2448(0.1632) Grad: 0.9145  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 10m 51s (remain 4m 21s) Loss: 0.1383(0.1631) Grad: 1.1141  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 11m 6s (remain 4m 6s) Loss: 0.0964(0.1630) Grad: 1.0512  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 11m 21s (remain 3m 50s) Loss: 0.2068(0.1631) Grad: 0.8503  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 11m 37s (remain 3m 35s) Loss: 0.2083(0.1628) Grad: 0.9702  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 11m 52s (remain 3m 19s) Loss: 0.1317(0.1627) Grad: 0.6722  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 12m 7s (remain 3m 4s) Loss: 0.1947(0.1624) Grad: 1.1076  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 12m 25s (remain 2m 49s) Loss: 0.0461(0.1622) Grad: 0.7888  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 12m 40s (remain 2m 33s) Loss: 0.1337(0.1620) Grad: 0.5477  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 12m 55s (remain 2m 18s) Loss: 0.2673(0.1622) Grad: 1.5936  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 13m 10s (remain 2m 2s) Loss: 0.2229(0.1620) Grad: 1.1042  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 13m 26s (remain 1m 46s) Loss: 0.0690(0.1620) Grad: 0.8246  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 13m 41s (remain 1m 31s) Loss: 0.2140(0.1621) Grad: 0.6409  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 13m 57s (remain 1m 15s) Loss: 0.0920(0.1621) Grad: 0.6608  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 14m 12s (remain 1m 0s) Loss: 0.1181(0.1621) Grad: 1.2623  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 14m 27s (remain 0m 44s) Loss: 0.1027(0.1619) Grad: 0.5199  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 14m 43s (remain 0m 29s) Loss: 0.2240(0.1619) Grad: 0.9792  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 15m 0s (remain 0m 13s) Loss: 0.0527(0.1617) Grad: 1.2427  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 15m 13s (remain 0m 0s) Loss: 0.2529(0.1617) Grad: 0.8020  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 7m 16s) Loss: 0.1802(0.1802) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 0s) Loss: 0.1162(0.1294) \n","EVAL: [200/737] Elapsed 0m 37s (remain 1m 40s) Loss: 0.2344(0.1475) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 21s) Loss: 0.1115(0.1572) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 2s) Loss: 0.1795(0.1624) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.1591(0.1641) \n","EVAL: [600/737] Elapsed 1m 52s (remain 0m 25s) Loss: 0.1513(0.1634) \n","EVAL: [700/737] Elapsed 2m 12s (remain 0m 6s) Loss: 0.1002(0.1602) \n","EVAL: [736/737] Elapsed 2m 18s (remain 0m 0s) Loss: 0.1089(0.1588) \n","f1 score : 0.4665327270804696\n","recall score : 0.33803248544284403\n","precision score : 0.7526441487546912\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.1617  avg_val_loss: 0.1588  time: 1055s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1617  avg_val_loss: 0.1588  time: 1055s\n","Epoch 2 - Score: 0.4665\n","INFO:__main__:Epoch 2 - Score: 0.4665\n","Epoch 2 - Save Best Score: 0.5466 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5466 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 1s (remain 98m 18s) Loss: 0.1791(0.1791) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 17s (remain 16m 18s) Loss: 0.0688(0.1573) Grad: 1.0158  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 33s (remain 15m 41s) Loss: 0.1897(0.1522) Grad: 0.9492  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 48s (remain 15m 2s) Loss: 0.2120(0.1535) Grad: 0.8954  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 1m 3s (remain 14m 33s) Loss: 0.1261(0.1524) Grad: 0.7488  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 1m 18s (remain 14m 9s) Loss: 0.1099(0.1506) Grad: 0.5360  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 1m 34s (remain 13m 49s) Loss: 0.2715(0.1519) Grad: 1.3450  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 49s (remain 13m 30s) Loss: 0.2329(0.1510) Grad: 1.6990  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 2m 4s (remain 13m 13s) Loss: 0.1120(0.1497) Grad: 0.5127  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 2m 23s (remain 13m 15s) Loss: 0.0649(0.1504) Grad: 1.3515  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 2m 39s (remain 12m 57s) Loss: 0.1814(0.1506) Grad: 0.8552  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 2m 54s (remain 12m 40s) Loss: 0.1548(0.1509) Grad: 0.6864  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 3m 10s (remain 12m 22s) Loss: 0.1666(0.1507) Grad: 0.6557  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 3m 25s (remain 12m 4s) Loss: 0.1388(0.1516) Grad: 1.4017  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 3m 40s (remain 11m 47s) Loss: 0.2410(0.1525) Grad: 0.9389  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 3m 55s (remain 11m 30s) Loss: 0.1725(0.1522) Grad: 0.6499  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 4m 11s (remain 11m 13s) Loss: 0.0876(0.1522) Grad: 0.7847  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 4m 26s (remain 10m 56s) Loss: 0.2347(0.1515) Grad: 1.2102  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 4m 41s (remain 10m 39s) Loss: 0.0837(0.1514) Grad: 0.6155  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 4m 59s (remain 10m 29s) Loss: 0.1755(0.1507) Grad: 1.1402  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 5m 14s (remain 10m 12s) Loss: 0.2455(0.1505) Grad: 0.9691  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 5m 30s (remain 9m 55s) Loss: 0.1478(0.1508) Grad: 0.8209  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 5m 45s (remain 9m 38s) Loss: 0.2100(0.1511) Grad: 2.2351  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 6m 0s (remain 9m 23s) Loss: 0.1014(0.1511) Grad: 1.1493  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 6m 16s (remain 9m 6s) Loss: 0.1775(0.1509) Grad: 0.6928  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 6m 31s (remain 8m 51s) Loss: 0.2004(0.1511) Grad: 0.9230  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 6m 47s (remain 8m 35s) Loss: 0.2998(0.1510) Grad: 1.2131  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 7m 2s (remain 8m 19s) Loss: 0.1162(0.1512) Grad: 0.5437  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 7m 19s (remain 8m 4s) Loss: 0.3350(0.1515) Grad: 1.9777  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 7m 36s (remain 7m 50s) Loss: 0.2150(0.1520) Grad: 0.8818  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 7m 52s (remain 7m 34s) Loss: 0.1339(0.1519) Grad: 0.6510  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 8m 7s (remain 7m 18s) Loss: 0.2250(0.1518) Grad: 0.7973  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 8m 22s (remain 7m 2s) Loss: 0.0715(0.1518) Grad: 1.5340  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 8m 38s (remain 6m 46s) Loss: 0.1410(0.1520) Grad: 1.0885  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 8m 53s (remain 6m 30s) Loss: 0.1509(0.1521) Grad: 0.7082  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 9m 9s (remain 6m 15s) Loss: 0.1731(0.1519) Grad: 0.8117  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 9m 24s (remain 5m 59s) Loss: 0.0932(0.1518) Grad: 1.2970  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 9m 40s (remain 5m 43s) Loss: 0.0981(0.1519) Grad: 0.9133  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 9m 58s (remain 5m 29s) Loss: 0.2390(0.1517) Grad: 0.7012  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 10m 14s (remain 5m 13s) Loss: 0.1749(0.1516) Grad: 0.7903  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 10m 30s (remain 4m 57s) Loss: 0.2048(0.1515) Grad: 1.1344  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 10m 46s (remain 4m 42s) Loss: 0.2063(0.1515) Grad: 1.0879  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 11m 1s (remain 4m 26s) Loss: 0.0714(0.1514) Grad: 0.7404  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 11m 16s (remain 4m 10s) Loss: 0.0778(0.1515) Grad: 0.7308  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 11m 31s (remain 3m 54s) Loss: 0.1093(0.1517) Grad: 0.9339  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 11m 47s (remain 3m 38s) Loss: 0.0757(0.1513) Grad: 0.5380  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 12m 2s (remain 3m 22s) Loss: 0.2042(0.1512) Grad: 0.7256  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 12m 17s (remain 3m 6s) Loss: 0.1488(0.1513) Grad: 0.7999  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 12m 36s (remain 2m 51s) Loss: 0.0310(0.1513) Grad: 0.7837  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 12m 52s (remain 2m 35s) Loss: 0.0374(0.1511) Grad: 0.6759  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 13m 7s (remain 2m 20s) Loss: 0.1238(0.1513) Grad: 0.8882  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 13m 22s (remain 2m 4s) Loss: 0.0930(0.1511) Grad: 0.9279  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 13m 38s (remain 1m 48s) Loss: 0.1616(0.1512) Grad: 0.8177  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 13m 53s (remain 1m 32s) Loss: 0.0818(0.1513) Grad: 0.6046  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 14m 9s (remain 1m 17s) Loss: 0.0475(0.1511) Grad: 0.5992  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 14m 24s (remain 1m 1s) Loss: 0.2827(0.1507) Grad: 1.2858  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 14m 40s (remain 0m 45s) Loss: 0.0728(0.1506) Grad: 1.5605  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 14m 56s (remain 0m 29s) Loss: 0.1781(0.1507) Grad: 0.9041  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 15m 14s (remain 0m 14s) Loss: 0.1349(0.1507) Grad: 0.7461  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 15m 28s (remain 0m 0s) Loss: 0.2593(0.1507) Grad: 0.8551  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 10m 39s) Loss: 0.1549(0.1549) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 2s) Loss: 0.1134(0.1252) \n","EVAL: [200/737] Elapsed 0m 38s (remain 1m 41s) Loss: 0.2042(0.1438) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 22s) Loss: 0.1097(0.1534) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.1859(0.1581) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.1535(0.1597) \n","EVAL: [600/737] Elapsed 1m 53s (remain 0m 25s) Loss: 0.1588(0.1592) \n","EVAL: [700/737] Elapsed 2m 12s (remain 0m 6s) Loss: 0.0941(0.1565) \n","EVAL: [736/737] Elapsed 2m 19s (remain 0m 0s) Loss: 0.1048(0.1550) \n","f1 score : 0.5025692695214106\n","recall score : 0.38216365307998773\n","precision score : 0.7337452191821124\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1507  avg_val_loss: 0.1550  time: 1072s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1507  avg_val_loss: 0.1550  time: 1072s\n","Epoch 3 - Score: 0.5026\n","INFO:__main__:Epoch 3 - Score: 0.5026\n","Epoch 3 - Save Best Score: 0.5531 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5531 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 60m 8s) Loss: 0.0714(0.0714) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 17s (remain 17m 4s) Loss: 0.1526(0.1428) Grad: 1.2623  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 33s (remain 15m 55s) Loss: 0.0710(0.1396) Grad: 0.5867  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 49s (remain 15m 14s) Loss: 0.1229(0.1413) Grad: 0.6500  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 1m 4s (remain 14m 47s) Loss: 0.1248(0.1426) Grad: 0.8720  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 1m 20s (remain 14m 24s) Loss: 0.2117(0.1435) Grad: 1.0172  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 1m 35s (remain 14m 2s) Loss: 0.2375(0.1452) Grad: 1.6620  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 51s (remain 13m 44s) Loss: 0.0970(0.1445) Grad: 0.7865  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 2m 6s (remain 13m 25s) Loss: 0.1014(0.1444) Grad: 0.5606  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 2m 25s (remain 13m 23s) Loss: 0.1884(0.1439) Grad: 0.8174  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 2m 40s (remain 13m 3s) Loss: 0.1098(0.1433) Grad: 0.9515  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 2m 55s (remain 12m 44s) Loss: 0.0550(0.1435) Grad: 0.7372  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 3m 11s (remain 12m 26s) Loss: 0.0928(0.1431) Grad: 0.7369  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 3m 26s (remain 12m 7s) Loss: 0.2029(0.1433) Grad: 1.2367  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 3m 41s (remain 11m 50s) Loss: 0.1175(0.1433) Grad: 1.1546  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 3m 57s (remain 11m 33s) Loss: 0.0883(0.1435) Grad: 0.6697  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 4m 12s (remain 11m 16s) Loss: 0.3242(0.1435) Grad: 2.0769  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 4m 27s (remain 10m 59s) Loss: 0.0537(0.1435) Grad: 0.8109  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 4m 43s (remain 10m 43s) Loss: 0.1274(0.1437) Grad: 0.8291  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 5m 2s (remain 10m 35s) Loss: 0.1564(0.1439) Grad: 0.6704  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 5m 18s (remain 10m 18s) Loss: 0.1205(0.1438) Grad: 0.8949  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 5m 33s (remain 10m 1s) Loss: 0.1375(0.1441) Grad: 0.6813  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 5m 49s (remain 9m 45s) Loss: 0.1873(0.1439) Grad: 1.0529  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 6m 4s (remain 9m 28s) Loss: 0.0790(0.1439) Grad: 0.5576  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 6m 20s (remain 9m 12s) Loss: 0.2076(0.1434) Grad: 0.9944  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 6m 35s (remain 8m 56s) Loss: 0.1852(0.1435) Grad: 1.1311  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 6m 51s (remain 8m 40s) Loss: 0.1844(0.1436) Grad: 0.9432  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 7m 6s (remain 8m 23s) Loss: 0.1897(0.1430) Grad: 1.2700  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 7m 22s (remain 8m 7s) Loss: 0.0872(0.1432) Grad: 0.6808  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 7m 40s (remain 7m 54s) Loss: 0.1965(0.1430) Grad: 0.7210  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 7m 55s (remain 7m 38s) Loss: 0.1405(0.1429) Grad: 0.7532  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 8m 11s (remain 7m 22s) Loss: 0.1359(0.1429) Grad: 1.0212  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 8m 26s (remain 7m 5s) Loss: 0.0254(0.1426) Grad: 0.6206  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 8m 41s (remain 6m 49s) Loss: 0.1833(0.1425) Grad: 1.0549  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 8m 57s (remain 6m 33s) Loss: 0.1138(0.1426) Grad: 1.8739  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 9m 13s (remain 6m 17s) Loss: 0.1837(0.1425) Grad: 0.9389  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 9m 29s (remain 6m 1s) Loss: 0.1599(0.1420) Grad: 1.7992  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 9m 44s (remain 5m 46s) Loss: 0.1442(0.1421) Grad: 0.6980  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 10m 2s (remain 5m 31s) Loss: 0.0516(0.1422) Grad: 0.6745  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 10m 19s (remain 5m 15s) Loss: 0.2725(0.1420) Grad: 1.1146  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 10m 34s (remain 4m 59s) Loss: 0.0758(0.1417) Grad: 0.7733  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 10m 50s (remain 4m 44s) Loss: 0.4358(0.1419) Grad: 2.7514  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 11m 6s (remain 4m 28s) Loss: 0.1646(0.1418) Grad: 1.3325  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 11m 21s (remain 4m 12s) Loss: 0.1288(0.1420) Grad: 0.7086  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 11m 37s (remain 3m 56s) Loss: 0.2703(0.1420) Grad: 1.3907  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 11m 53s (remain 3m 40s) Loss: 0.2551(0.1419) Grad: 1.6019  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 12m 8s (remain 3m 24s) Loss: 0.0865(0.1419) Grad: 0.7459  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 12m 24s (remain 3m 8s) Loss: 0.3113(0.1418) Grad: 2.1116  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 12m 42s (remain 2m 53s) Loss: 0.0745(0.1418) Grad: 0.8204  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 12m 57s (remain 2m 37s) Loss: 0.1871(0.1416) Grad: 1.0986  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 13m 13s (remain 2m 21s) Loss: 0.0648(0.1415) Grad: 0.6199  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 13m 29s (remain 2m 5s) Loss: 0.0683(0.1414) Grad: 0.9392  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 13m 44s (remain 1m 49s) Loss: 0.3142(0.1415) Grad: 1.5715  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 13m 59s (remain 1m 33s) Loss: 0.1042(0.1416) Grad: 0.7562  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 14m 15s (remain 1m 17s) Loss: 0.1571(0.1416) Grad: 1.1579  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 14m 30s (remain 1m 1s) Loss: 0.0714(0.1416) Grad: 0.5432  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 14m 46s (remain 0m 45s) Loss: 0.0759(0.1417) Grad: 0.6175  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 15m 2s (remain 0m 30s) Loss: 0.1495(0.1416) Grad: 1.0221  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 15m 21s (remain 0m 14s) Loss: 0.0519(0.1417) Grad: 0.5835  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 15m 35s (remain 0m 0s) Loss: 0.1333(0.1415) Grad: 0.9955  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 8m 36s) Loss: 0.1519(0.1519) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 1s) Loss: 0.1134(0.1266) \n","EVAL: [200/737] Elapsed 0m 37s (remain 1m 41s) Loss: 0.1980(0.1447) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 22s) Loss: 0.1103(0.1543) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.1978(0.1588) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.1594(0.1605) \n","EVAL: [600/737] Elapsed 1m 53s (remain 0m 25s) Loss: 0.1666(0.1601) \n","EVAL: [700/737] Elapsed 2m 12s (remain 0m 6s) Loss: 0.0829(0.1575) \n","EVAL: [736/737] Elapsed 2m 19s (remain 0m 0s) Loss: 0.1038(0.1561) \n","f1 score : 0.5130869522595823\n","recall score : 0.4010113392583512\n","precision score : 0.712108843537415\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1415  avg_val_loss: 0.1561  time: 1079s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1415  avg_val_loss: 0.1561  time: 1079s\n","Epoch 4 - Score: 0.5131\n","INFO:__main__:Epoch 4 - Score: 0.5131\n","Epoch 4 - Save Best Score: 0.5531 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.5531 Model\n","========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.5130869522595823\n","recall score : 0.4010113392583512\n","precision score : 0.712108843537415\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.5131\n","INFO:__main__:Score: 0.5131\n","F1 BEST Score: 0.5531\n","INFO:__main__:F1 BEST Score: 0.5531\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 0s (remain 63m 20s) Loss: 0.4268(0.4268) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 18s (remain 17m 50s) Loss: 0.2034(0.2501) Grad: 0.5860  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 34s (remain 16m 7s) Loss: 0.1707(0.2400) Grad: 1.8798  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 49s (remain 15m 23s) Loss: 0.3359(0.2288) Grad: 1.6633  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 1m 5s (remain 14m 50s) Loss: 0.2065(0.2253) Grad: 0.1656  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 1m 20s (remain 14m 28s) Loss: 0.0904(0.2202) Grad: 1.4075  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 1m 36s (remain 14m 5s) Loss: 0.1575(0.2211) Grad: 1.2565  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 51s (remain 13m 45s) Loss: 0.0775(0.2197) Grad: 0.9676  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 2m 7s (remain 13m 30s) Loss: 0.2375(0.2167) Grad: 1.5751  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 2m 25s (remain 13m 26s) Loss: 0.2739(0.2151) Grad: 1.5855  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 2m 41s (remain 13m 7s) Loss: 0.1368(0.2137) Grad: 0.5207  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 2m 56s (remain 12m 48s) Loss: 0.2634(0.2122) Grad: 1.2358  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 3m 12s (remain 12m 30s) Loss: 0.1252(0.2113) Grad: 1.5431  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 3m 27s (remain 12m 11s) Loss: 0.1550(0.2107) Grad: 0.7577  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 3m 42s (remain 11m 54s) Loss: 0.0909(0.2101) Grad: 2.1197  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 3m 58s (remain 11m 36s) Loss: 0.1598(0.2100) Grad: 0.6751  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 4m 13s (remain 11m 19s) Loss: 0.3191(0.2089) Grad: 1.6092  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 4m 29s (remain 11m 2s) Loss: 0.2109(0.2088) Grad: 0.7728  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 4m 45s (remain 10m 48s) Loss: 0.1836(0.2081) Grad: 0.3084  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 5m 4s (remain 10m 38s) Loss: 0.3325(0.2073) Grad: 1.5779  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 5m 20s (remain 10m 22s) Loss: 0.3132(0.2071) Grad: 0.9097  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 5m 36s (remain 10m 6s) Loss: 0.1293(0.2068) Grad: 1.1739  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 5m 52s (remain 9m 50s) Loss: 0.1425(0.2061) Grad: 1.5341  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 6m 7s (remain 9m 33s) Loss: 0.1362(0.2055) Grad: 0.8075  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 6m 23s (remain 9m 16s) Loss: 0.2030(0.2051) Grad: 1.5598  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 6m 38s (remain 9m 0s) Loss: 0.1810(0.2040) Grad: 0.6288  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 6m 53s (remain 8m 43s) Loss: 0.0349(0.2037) Grad: 0.9160  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 7m 9s (remain 8m 27s) Loss: 0.1610(0.2029) Grad: 0.5151  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 7m 25s (remain 8m 11s) Loss: 0.1824(0.2025) Grad: 1.0451  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 7m 43s (remain 7m 57s) Loss: 0.2625(0.2022) Grad: 0.8119  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 7m 59s (remain 7m 41s) Loss: 0.2258(0.2011) Grad: 0.6331  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 8m 14s (remain 7m 25s) Loss: 0.0880(0.2006) Grad: 0.9382  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 8m 30s (remain 7m 8s) Loss: 0.2512(0.2001) Grad: 0.8617  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 8m 45s (remain 6m 52s) Loss: 0.1949(0.1996) Grad: 0.4869  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 9m 0s (remain 6m 35s) Loss: 0.1067(0.1989) Grad: 0.9768  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 9m 15s (remain 6m 19s) Loss: 0.1710(0.1984) Grad: 0.4781  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 9m 30s (remain 6m 3s) Loss: 0.3147(0.1980) Grad: 0.9063  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 9m 46s (remain 5m 46s) Loss: 0.1151(0.1974) Grad: 0.6515  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 10m 2s (remain 5m 31s) Loss: 0.1165(0.1970) Grad: 0.7942  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 10m 20s (remain 5m 16s) Loss: 0.1790(0.1965) Grad: 0.4827  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 10m 35s (remain 5m 0s) Loss: 0.1927(0.1959) Grad: 0.8558  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 10m 51s (remain 4m 44s) Loss: 0.2303(0.1956) Grad: 0.7283  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 11m 7s (remain 4m 28s) Loss: 0.0872(0.1952) Grad: 1.8594  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 11m 22s (remain 4m 12s) Loss: 0.3870(0.1959) Grad: 1.2061  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 11m 37s (remain 3m 56s) Loss: 0.3135(0.1973) Grad: 0.4888  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 11m 53s (remain 3m 40s) Loss: 0.1917(0.1983) Grad: 0.4969  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 12m 8s (remain 3m 24s) Loss: 0.3152(0.1994) Grad: 0.6958  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 12m 23s (remain 3m 8s) Loss: 0.2759(0.2002) Grad: 0.4069  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 12m 41s (remain 2m 52s) Loss: 0.2751(0.2010) Grad: 0.2843  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 12m 57s (remain 2m 37s) Loss: 0.2435(0.2020) Grad: 0.5169  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 13m 12s (remain 2m 21s) Loss: 0.2313(0.2025) Grad: 0.7512  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 13m 27s (remain 2m 5s) Loss: 0.3306(0.2023) Grad: 1.4534  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 13m 42s (remain 1m 49s) Loss: 0.0777(0.2019) Grad: 0.6411  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 13m 57s (remain 1m 33s) Loss: 0.2456(0.2016) Grad: 0.5487  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 14m 12s (remain 1m 17s) Loss: 0.1458(0.2014) Grad: 0.6544  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 14m 27s (remain 1m 1s) Loss: 0.1436(0.2013) Grad: 1.0354  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 14m 43s (remain 0m 45s) Loss: 0.1185(0.2009) Grad: 1.0092  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 14m 58s (remain 0m 29s) Loss: 0.2058(0.2005) Grad: 0.4769  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 15m 16s (remain 0m 14s) Loss: 0.2952(0.2002) Grad: 1.4293  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 15m 30s (remain 0m 0s) Loss: 0.1102(0.1999) Grad: 0.9536  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 6m 52s) Loss: 0.1277(0.1277) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 0s) Loss: 0.1664(0.1415) \n","EVAL: [200/737] Elapsed 0m 37s (remain 1m 40s) Loss: 0.1930(0.1641) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 21s) Loss: 0.2709(0.1706) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 2s) Loss: 0.1871(0.1744) \n","EVAL: [500/737] Elapsed 1m 33s (remain 0m 44s) Loss: 0.1716(0.1773) \n","EVAL: [600/737] Elapsed 1m 52s (remain 0m 25s) Loss: 0.1536(0.1792) \n","EVAL: [700/737] Elapsed 2m 11s (remain 0m 6s) Loss: 0.1694(0.1765) \n","EVAL: [736/737] Elapsed 2m 18s (remain 0m 0s) Loss: 0.1601(0.1752) \n","f1 score : 0.375812892184826\n","recall score : 0.2523364485981308\n","precision score : 0.7359249329758714\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.1999  avg_val_loss: 0.1752  time: 1073s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.1999  avg_val_loss: 0.1752  time: 1073s\n","Epoch 1 - Score: 0.3758\n","INFO:__main__:Epoch 1 - Score: 0.3758\n","Epoch 1 - Save Best Score: 0.4933 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4933 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 62m 54s) Loss: 0.1052(0.1052) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 16s (remain 16m 10s) Loss: 0.1895(0.1782) Grad: 0.5710  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 32s (remain 15m 29s) Loss: 0.1163(0.1743) Grad: 0.5199  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 48s (remain 14m 53s) Loss: 0.0478(0.1716) Grad: 0.7507  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 1m 3s (remain 14m 29s) Loss: 0.1160(0.1694) Grad: 0.6112  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 1m 19s (remain 14m 10s) Loss: 0.1517(0.1703) Grad: 0.8029  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 1m 34s (remain 13m 53s) Loss: 0.1674(0.1705) Grad: 1.0094  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 50s (remain 13m 37s) Loss: 0.2148(0.1701) Grad: 1.1134  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 2m 5s (remain 13m 18s) Loss: 0.0728(0.1697) Grad: 0.8866  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 2m 23s (remain 13m 15s) Loss: 0.2795(0.1706) Grad: 1.1421  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 2m 39s (remain 12m 59s) Loss: 0.1615(0.1709) Grad: 0.5029  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 2m 54s (remain 12m 41s) Loss: 0.0718(0.1702) Grad: 0.8088  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 3m 10s (remain 12m 22s) Loss: 0.1832(0.1709) Grad: 1.0605  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 3m 25s (remain 12m 3s) Loss: 0.0823(0.1711) Grad: 0.8570  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 3m 40s (remain 11m 45s) Loss: 0.1506(0.1718) Grad: 0.5859  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 3m 55s (remain 11m 27s) Loss: 0.0596(0.1711) Grad: 0.5597  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 4m 10s (remain 11m 10s) Loss: 0.0599(0.1704) Grad: 1.0886  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 4m 25s (remain 10m 53s) Loss: 0.2583(0.1703) Grad: 1.1562  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 4m 41s (remain 10m 38s) Loss: 0.0831(0.1704) Grad: 0.9679  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 4m 59s (remain 10m 27s) Loss: 0.1716(0.1701) Grad: 0.5204  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 5m 14s (remain 10m 10s) Loss: 0.1121(0.1700) Grad: 0.5030  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 5m 29s (remain 9m 54s) Loss: 0.1608(0.1701) Grad: 0.5606  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 5m 44s (remain 9m 37s) Loss: 0.2242(0.1702) Grad: 0.9414  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 6m 0s (remain 9m 22s) Loss: 0.2373(0.1702) Grad: 1.0958  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 6m 15s (remain 9m 6s) Loss: 0.0946(0.1702) Grad: 0.5811  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 6m 31s (remain 8m 50s) Loss: 0.0681(0.1700) Grad: 0.8012  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 6m 46s (remain 8m 34s) Loss: 0.2585(0.1699) Grad: 1.5007  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 7m 1s (remain 8m 17s) Loss: 0.0992(0.1695) Grad: 0.7460  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 7m 17s (remain 8m 2s) Loss: 0.2283(0.1697) Grad: 0.8911  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 7m 34s (remain 7m 48s) Loss: 0.0905(0.1700) Grad: 0.7692  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 7m 49s (remain 7m 31s) Loss: 0.1665(0.1698) Grad: 0.6484  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 8m 3s (remain 7m 15s) Loss: 0.1271(0.1697) Grad: 0.4698  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 8m 19s (remain 6m 59s) Loss: 0.1659(0.1693) Grad: 0.6907  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 8m 34s (remain 6m 43s) Loss: 0.2480(0.1696) Grad: 1.6175  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 8m 50s (remain 6m 28s) Loss: 0.0867(0.1693) Grad: 0.7765  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 9m 5s (remain 6m 12s) Loss: 0.1500(0.1691) Grad: 0.7386  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 9m 21s (remain 5m 57s) Loss: 0.1539(0.1687) Grad: 0.5406  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 9m 36s (remain 5m 41s) Loss: 0.1249(0.1687) Grad: 0.7579  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 9m 55s (remain 5m 27s) Loss: 0.0477(0.1685) Grad: 0.5046  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 10m 11s (remain 5m 11s) Loss: 0.0582(0.1683) Grad: 1.1375  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 10m 27s (remain 4m 56s) Loss: 0.1971(0.1682) Grad: 1.2998  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 10m 42s (remain 4m 40s) Loss: 0.2251(0.1680) Grad: 1.3418  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 10m 58s (remain 4m 24s) Loss: 0.1434(0.1679) Grad: 0.7342  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 11m 13s (remain 4m 9s) Loss: 0.0715(0.1677) Grad: 1.2605  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 11m 29s (remain 3m 53s) Loss: 0.1741(0.1676) Grad: 1.0063  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 11m 45s (remain 3m 37s) Loss: 0.1186(0.1673) Grad: 1.0201  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 12m 0s (remain 3m 21s) Loss: 0.2159(0.1670) Grad: 1.3209  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 12m 15s (remain 3m 6s) Loss: 0.1028(0.1671) Grad: 0.4882  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 12m 33s (remain 2m 51s) Loss: 0.1671(0.1669) Grad: 0.9994  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 12m 49s (remain 2m 35s) Loss: 0.0426(0.1665) Grad: 0.7753  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 13m 4s (remain 2m 19s) Loss: 0.2010(0.1665) Grad: 0.8689  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 13m 19s (remain 2m 3s) Loss: 0.1411(0.1662) Grad: 0.6035  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 13m 35s (remain 1m 48s) Loss: 0.1090(0.1662) Grad: 0.3890  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 13m 50s (remain 1m 32s) Loss: 0.2289(0.1661) Grad: 0.7484  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 14m 5s (remain 1m 16s) Loss: 0.1919(0.1661) Grad: 1.1094  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 14m 20s (remain 1m 1s) Loss: 0.1650(0.1661) Grad: 0.5710  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 14m 36s (remain 0m 45s) Loss: 0.1550(0.1660) Grad: 1.1843  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 14m 51s (remain 0m 29s) Loss: 0.1854(0.1657) Grad: 0.6933  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 15m 9s (remain 0m 14s) Loss: 0.0870(0.1655) Grad: 0.7067  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 15m 22s (remain 0m 0s) Loss: 0.1081(0.1652) Grad: 1.2177  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 11m 54s) Loss: 0.1124(0.1124) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 2s) Loss: 0.1564(0.1300) \n","EVAL: [200/737] Elapsed 0m 38s (remain 1m 41s) Loss: 0.1804(0.1522) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 22s) Loss: 0.2781(0.1583) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.1755(0.1613) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.1358(0.1639) \n","EVAL: [600/737] Elapsed 1m 52s (remain 0m 25s) Loss: 0.1505(0.1654) \n","EVAL: [700/737] Elapsed 2m 11s (remain 0m 6s) Loss: 0.1571(0.1623) \n","EVAL: [736/737] Elapsed 2m 18s (remain 0m 0s) Loss: 0.1501(0.1605) \n","f1 score : 0.4243446956913038\n","recall score : 0.28895357744752564\n","precision score : 0.7984758679085521\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.1652  avg_val_loss: 0.1605  time: 1065s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1652  avg_val_loss: 0.1605  time: 1065s\n","Epoch 2 - Score: 0.4243\n","INFO:__main__:Epoch 2 - Score: 0.4243\n","Epoch 2 - Save Best Score: 0.5332 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5332 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 64m 12s) Loss: 0.0753(0.0753) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 17s (remain 16m 54s) Loss: 0.1285(0.1461) Grad: 0.9974  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 33s (remain 15m 54s) Loss: 0.1888(0.1524) Grad: 1.5031  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 49s (remain 15m 12s) Loss: 0.1177(0.1500) Grad: 1.0957  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 1m 4s (remain 14m 49s) Loss: 0.2148(0.1542) Grad: 0.6620  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 1m 20s (remain 14m 27s) Loss: 0.3372(0.1544) Grad: 1.3960  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 1m 36s (remain 14m 7s) Loss: 0.1011(0.1551) Grad: 0.5530  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 51s (remain 13m 48s) Loss: 0.1385(0.1573) Grad: 1.1871  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 2m 7s (remain 13m 29s) Loss: 0.1154(0.1578) Grad: 1.1110  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 2m 25s (remain 13m 24s) Loss: 0.0790(0.1568) Grad: 1.0820  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 2m 41s (remain 13m 7s) Loss: 0.1230(0.1556) Grad: 1.0210  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 2m 56s (remain 12m 47s) Loss: 0.0513(0.1551) Grad: 0.9996  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 3m 11s (remain 12m 29s) Loss: 0.1661(0.1537) Grad: 0.8693  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 3m 27s (remain 12m 10s) Loss: 0.1863(0.1531) Grad: 0.8531  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 3m 42s (remain 11m 53s) Loss: 0.2515(0.1533) Grad: 1.2751  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 3m 58s (remain 11m 36s) Loss: 0.1447(0.1535) Grad: 0.6507  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 4m 13s (remain 11m 19s) Loss: 0.1998(0.1532) Grad: 0.8834  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 4m 28s (remain 11m 2s) Loss: 0.1138(0.1532) Grad: 0.3888  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 4m 44s (remain 10m 45s) Loss: 0.0604(0.1530) Grad: 1.0927  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 5m 2s (remain 10m 34s) Loss: 0.2561(0.1531) Grad: 1.3952  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 5m 18s (remain 10m 19s) Loss: 0.1360(0.1538) Grad: 0.5056  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 5m 33s (remain 10m 2s) Loss: 0.2546(0.1537) Grad: 0.8551  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 5m 49s (remain 9m 45s) Loss: 0.1074(0.1533) Grad: 0.5818  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 6m 4s (remain 9m 29s) Loss: 0.2057(0.1541) Grad: 0.9385  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 6m 20s (remain 9m 12s) Loss: 0.2380(0.1540) Grad: 1.3597  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 6m 35s (remain 8m 55s) Loss: 0.1725(0.1537) Grad: 0.5657  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 6m 51s (remain 8m 39s) Loss: 0.1697(0.1535) Grad: 0.9510  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 7m 6s (remain 8m 23s) Loss: 0.0753(0.1534) Grad: 0.7894  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 7m 22s (remain 8m 7s) Loss: 0.2563(0.1536) Grad: 1.2309  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 7m 39s (remain 7m 53s) Loss: 0.0865(0.1534) Grad: 0.3961  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 7m 55s (remain 7m 38s) Loss: 0.0976(0.1532) Grad: 0.7130  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 8m 11s (remain 7m 22s) Loss: 0.1989(0.1531) Grad: 0.7908  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 8m 26s (remain 7m 5s) Loss: 0.1224(0.1531) Grad: 1.0190  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 8m 42s (remain 6m 49s) Loss: 0.2959(0.1530) Grad: 1.6123  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 8m 57s (remain 6m 33s) Loss: 0.2458(0.1534) Grad: 1.3280  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 9m 13s (remain 6m 17s) Loss: 0.1520(0.1534) Grad: 0.6103  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 9m 29s (remain 6m 1s) Loss: 0.2205(0.1535) Grad: 0.8954  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 9m 44s (remain 5m 46s) Loss: 0.1245(0.1536) Grad: 0.5235  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 10m 0s (remain 5m 30s) Loss: 0.0737(0.1535) Grad: 1.2864  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 10m 19s (remain 5m 15s) Loss: 0.2186(0.1536) Grad: 0.9114  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 10m 34s (remain 4m 59s) Loss: 0.0982(0.1536) Grad: 0.8930  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 10m 50s (remain 4m 43s) Loss: 0.1251(0.1536) Grad: 0.6471  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 11m 5s (remain 4m 27s) Loss: 0.2927(0.1535) Grad: 1.0269  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 11m 21s (remain 4m 11s) Loss: 0.1124(0.1537) Grad: 0.6119  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 11m 36s (remain 3m 55s) Loss: 0.0792(0.1538) Grad: 0.6299  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 11m 52s (remain 3m 39s) Loss: 0.3184(0.1539) Grad: 2.0568  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 12m 7s (remain 3m 24s) Loss: 0.0925(0.1537) Grad: 0.5829  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 12m 23s (remain 3m 8s) Loss: 0.0728(0.1534) Grad: 0.7928  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 12m 38s (remain 2m 52s) Loss: 0.1824(0.1535) Grad: 0.9504  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 12m 56s (remain 2m 36s) Loss: 0.2324(0.1534) Grad: 0.8023  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 13m 11s (remain 2m 20s) Loss: 0.0788(0.1535) Grad: 1.1762  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 13m 27s (remain 2m 4s) Loss: 0.2522(0.1535) Grad: 1.3087  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 13m 42s (remain 1m 49s) Loss: 0.0671(0.1534) Grad: 0.5179  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 13m 57s (remain 1m 33s) Loss: 0.1110(0.1531) Grad: 0.3973  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 14m 12s (remain 1m 17s) Loss: 0.2085(0.1533) Grad: 1.5614  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 14m 27s (remain 1m 1s) Loss: 0.0944(0.1533) Grad: 0.6241  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 14m 43s (remain 0m 45s) Loss: 0.1023(0.1532) Grad: 0.9849  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 14m 58s (remain 0m 29s) Loss: 0.2018(0.1531) Grad: 0.7447  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 15m 14s (remain 0m 14s) Loss: 0.2649(0.1532) Grad: 0.9919  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 15m 30s (remain 0m 0s) Loss: 0.1735(0.1532) Grad: 0.6295  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 10m 3s) Loss: 0.1128(0.1128) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 2s) Loss: 0.1453(0.1269) \n","EVAL: [200/737] Elapsed 0m 38s (remain 1m 41s) Loss: 0.1881(0.1476) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 22s) Loss: 0.2566(0.1526) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.1703(0.1557) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.1201(0.1581) \n","EVAL: [600/737] Elapsed 1m 53s (remain 0m 25s) Loss: 0.1544(0.1595) \n","EVAL: [700/737] Elapsed 2m 12s (remain 0m 6s) Loss: 0.1480(0.1567) \n","EVAL: [736/737] Elapsed 2m 18s (remain 0m 0s) Loss: 0.1509(0.1551) \n","f1 score : 0.48867380560131796\n","recall score : 0.36356672284357283\n","precision score : 0.7450549450549451\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1532  avg_val_loss: 0.1551  time: 1074s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1532  avg_val_loss: 0.1551  time: 1074s\n","Epoch 3 - Score: 0.4887\n","INFO:__main__:Epoch 3 - Score: 0.4887\n","Epoch 3 - Save Best Score: 0.5494 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5494 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 62m 12s) Loss: 0.1335(0.1335) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 21s (remain 20m 47s) Loss: 0.1476(0.1479) Grad: 0.9779  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 37s (remain 17m 37s) Loss: 0.1387(0.1526) Grad: 0.7977  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 52s (remain 16m 17s) Loss: 0.1864(0.1517) Grad: 0.9846  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 1m 7s (remain 15m 28s) Loss: 0.1831(0.1495) Grad: 1.1340  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 1m 22s (remain 14m 51s) Loss: 0.0878(0.1482) Grad: 0.5445  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 1m 37s (remain 14m 22s) Loss: 0.1320(0.1467) Grad: 1.0683  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 53s (remain 13m 58s) Loss: 0.1790(0.1471) Grad: 0.8514  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 2m 8s (remain 13m 36s) Loss: 0.1327(0.1450) Grad: 0.7393  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 2m 23s (remain 13m 15s) Loss: 0.2262(0.1444) Grad: 1.4224  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 2m 38s (remain 12m 55s) Loss: 0.1648(0.1449) Grad: 0.6862  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 2m 55s (remain 12m 42s) Loss: 0.0737(0.1450) Grad: 0.6106  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 3m 12s (remain 12m 32s) Loss: 0.1608(0.1442) Grad: 1.0478  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 3m 28s (remain 12m 14s) Loss: 0.1714(0.1439) Grad: 0.6717  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 3m 43s (remain 11m 56s) Loss: 0.1290(0.1438) Grad: 0.7772  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 3m 58s (remain 11m 38s) Loss: 0.1619(0.1436) Grad: 0.8550  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 4m 14s (remain 11m 21s) Loss: 0.0479(0.1435) Grad: 0.5460  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 4m 29s (remain 11m 4s) Loss: 0.1240(0.1431) Grad: 0.6983  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 4m 45s (remain 10m 47s) Loss: 0.1053(0.1428) Grad: 0.8374  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 5m 0s (remain 10m 31s) Loss: 0.1467(0.1427) Grad: 1.9349  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 5m 15s (remain 10m 14s) Loss: 0.2585(0.1429) Grad: 1.7523  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 5m 31s (remain 9m 57s) Loss: 0.2095(0.1430) Grad: 1.2945  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 5m 48s (remain 9m 44s) Loss: 0.2305(0.1427) Grad: 1.6900  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 6m 4s (remain 9m 27s) Loss: 0.1139(0.1428) Grad: 1.1834  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 6m 19s (remain 9m 10s) Loss: 0.0566(0.1427) Grad: 0.7804  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 6m 33s (remain 8m 54s) Loss: 0.2452(0.1432) Grad: 1.1716  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 6m 48s (remain 8m 37s) Loss: 0.1177(0.1436) Grad: 0.9777  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 7m 3s (remain 8m 20s) Loss: 0.0706(0.1438) Grad: 0.6606  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 7m 19s (remain 8m 4s) Loss: 0.1808(0.1438) Grad: 0.8733  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 7m 34s (remain 7m 48s) Loss: 0.1443(0.1440) Grad: 0.6397  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 7m 49s (remain 7m 32s) Loss: 0.2222(0.1438) Grad: 0.9415  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 8m 4s (remain 7m 16s) Loss: 0.0930(0.1440) Grad: 1.0354  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 8m 21s (remain 7m 1s) Loss: 0.1313(0.1445) Grad: 1.1542  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 8m 37s (remain 6m 46s) Loss: 0.1694(0.1444) Grad: 0.9220  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 8m 52s (remain 6m 29s) Loss: 0.2284(0.1445) Grad: 0.9220  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 9m 7s (remain 6m 13s) Loss: 0.1522(0.1445) Grad: 1.1053  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 9m 22s (remain 5m 57s) Loss: 0.1066(0.1444) Grad: 1.3485  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 9m 37s (remain 5m 41s) Loss: 0.0649(0.1449) Grad: 0.5355  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 9m 52s (remain 5m 25s) Loss: 0.1400(0.1450) Grad: 0.6963  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 10m 7s (remain 5m 9s) Loss: 0.1237(0.1450) Grad: 0.7542  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 10m 22s (remain 4m 54s) Loss: 0.0372(0.1450) Grad: 0.9824  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 10m 37s (remain 4m 38s) Loss: 0.0587(0.1450) Grad: 0.8575  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 10m 52s (remain 4m 22s) Loss: 0.0924(0.1449) Grad: 1.5380  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 11m 9s (remain 4m 7s) Loss: 0.1587(0.1445) Grad: 0.6833  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 11m 24s (remain 3m 51s) Loss: 0.1342(0.1447) Grad: 0.8414  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 11m 39s (remain 3m 36s) Loss: 0.2155(0.1448) Grad: 1.2068  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 11m 54s (remain 3m 20s) Loss: 0.0504(0.1447) Grad: 1.1403  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 12m 9s (remain 3m 4s) Loss: 0.1201(0.1446) Grad: 0.8724  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 12m 24s (remain 2m 49s) Loss: 0.1116(0.1444) Grad: 0.5586  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 12m 39s (remain 2m 33s) Loss: 0.0313(0.1443) Grad: 0.7302  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 12m 54s (remain 2m 17s) Loss: 0.2427(0.1443) Grad: 1.5989  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 13m 9s (remain 2m 2s) Loss: 0.1296(0.1443) Grad: 0.6366  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 13m 24s (remain 1m 46s) Loss: 0.1545(0.1446) Grad: 0.8251  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 13m 42s (remain 1m 31s) Loss: 0.3154(0.1446) Grad: 2.3243  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 13m 57s (remain 1m 16s) Loss: 0.2075(0.1446) Grad: 1.3358  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 14m 12s (remain 1m 0s) Loss: 0.1274(0.1447) Grad: 1.2316  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 14m 27s (remain 0m 44s) Loss: 0.0605(0.1446) Grad: 1.4459  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 14m 42s (remain 0m 29s) Loss: 0.0695(0.1445) Grad: 1.0097  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 14m 57s (remain 0m 13s) Loss: 0.1948(0.1444) Grad: 0.9415  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 15m 10s (remain 0m 0s) Loss: 0.1874(0.1444) Grad: 1.1405  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 8m 3s) Loss: 0.1059(0.1059) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 1s) Loss: 0.1403(0.1282) \n","EVAL: [200/737] Elapsed 0m 37s (remain 1m 41s) Loss: 0.1876(0.1483) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 22s) Loss: 0.2624(0.1527) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.1664(0.1556) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.1160(0.1578) \n","EVAL: [600/737] Elapsed 1m 53s (remain 0m 25s) Loss: 0.1583(0.1592) \n","EVAL: [700/737] Elapsed 2m 12s (remain 0m 6s) Loss: 0.1474(0.1567) \n","EVAL: [736/737] Elapsed 2m 18s (remain 0m 0s) Loss: 0.1549(0.1551) \n","f1 score : 0.5068870523415978\n","recall score : 0.3946683009039375\n","precision score : 0.7082760516909541\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.1444  avg_val_loss: 0.1551  time: 1052s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.1444  avg_val_loss: 0.1551  time: 1052s\n","Epoch 4 - Score: 0.5069\n","INFO:__main__:Epoch 4 - Score: 0.5069\n","Epoch 4 - Save Best Score: 0.5525 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.5525 Model\n","========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.5068870523415978\n","recall score : 0.3946683009039375\n","precision score : 0.7082760516909541\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.5069\n","INFO:__main__:Score: 0.5069\n","F1 BEST Score: 0.5525\n","INFO:__main__:F1 BEST Score: 0.5525\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.0\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 1s (remain 102m 48s) Loss: 0.5527(0.5527) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 17s (remain 16m 37s) Loss: 0.3123(0.2600) Grad: 1.4306  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 32s (remain 15m 16s) Loss: 0.1120(0.2404) Grad: 1.3881  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 47s (remain 14m 39s) Loss: 0.2052(0.2329) Grad: 1.2028  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 1m 4s (remain 14m 37s) Loss: 0.2404(0.2298) Grad: 0.8147  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 1m 20s (remain 14m 29s) Loss: 0.3352(0.2265) Grad: 0.8317  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 1m 36s (remain 14m 5s) Loss: 0.1954(0.2246) Grad: 0.6389  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 51s (remain 13m 43s) Loss: 0.1691(0.2245) Grad: 0.5348  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 2m 6s (remain 13m 23s) Loss: 0.1844(0.2223) Grad: 0.2452  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 2m 21s (remain 13m 3s) Loss: 0.2220(0.2218) Grad: 1.0947  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 2m 36s (remain 12m 44s) Loss: 0.2837(0.2212) Grad: 0.6439  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 2m 51s (remain 12m 27s) Loss: 0.4661(0.2188) Grad: 2.7747  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 3m 7s (remain 12m 10s) Loss: 0.1656(0.2166) Grad: 0.6455  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 3m 22s (remain 11m 53s) Loss: 0.0998(0.2156) Grad: 0.6944  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 3m 39s (remain 11m 42s) Loss: 0.1770(0.2133) Grad: 0.6331  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 3m 55s (remain 11m 28s) Loss: 0.2321(0.2126) Grad: 0.5491  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 4m 10s (remain 11m 11s) Loss: 0.1084(0.2116) Grad: 1.1367  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 4m 25s (remain 10m 55s) Loss: 0.1780(0.2110) Grad: 0.6108  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 4m 41s (remain 10m 38s) Loss: 0.2079(0.2104) Grad: 1.0593  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 4m 55s (remain 10m 21s) Loss: 0.1324(0.2090) Grad: 0.3364  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 5m 10s (remain 10m 4s) Loss: 0.1384(0.2077) Grad: 0.5960  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 5m 26s (remain 9m 48s) Loss: 0.2393(0.2076) Grad: 1.1551  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 5m 41s (remain 9m 31s) Loss: 0.0834(0.2069) Grad: 1.8429  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 5m 56s (remain 9m 16s) Loss: 0.1064(0.2057) Grad: 0.4485  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 6m 11s (remain 9m 0s) Loss: 0.1927(0.2047) Grad: 0.5381  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 6m 29s (remain 8m 48s) Loss: 0.1970(0.2040) Grad: 0.9377  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 6m 44s (remain 8m 32s) Loss: 0.1957(0.2032) Grad: 0.5349  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 7m 0s (remain 8m 16s) Loss: 0.2262(0.2027) Grad: 1.0084  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 7m 15s (remain 8m 0s) Loss: 0.2817(0.2026) Grad: 0.8767  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 7m 30s (remain 7m 44s) Loss: 0.1484(0.2017) Grad: 0.6337  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 7m 45s (remain 7m 28s) Loss: 0.2018(0.2011) Grad: 0.5939  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 8m 0s (remain 7m 12s) Loss: 0.1318(0.2009) Grad: 0.5492  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 8m 15s (remain 6m 56s) Loss: 0.1126(0.2006) Grad: 1.1360  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 8m 30s (remain 6m 40s) Loss: 0.2496(0.2002) Grad: 0.8026  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 8m 45s (remain 6m 24s) Loss: 0.2214(0.1996) Grad: 1.2538  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 9m 3s (remain 6m 10s) Loss: 0.0727(0.1989) Grad: 0.5643  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 9m 18s (remain 5m 55s) Loss: 0.2284(0.1983) Grad: 1.1522  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 9m 33s (remain 5m 39s) Loss: 0.1749(0.1980) Grad: 0.6791  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 9m 48s (remain 5m 23s) Loss: 0.1157(0.1978) Grad: 1.1792  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 10m 4s (remain 5m 8s) Loss: 0.2417(0.1974) Grad: 1.0797  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 10m 19s (remain 4m 52s) Loss: 0.0602(0.1970) Grad: 1.4289  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 10m 34s (remain 4m 37s) Loss: 0.2240(0.1964) Grad: 0.8938  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 10m 49s (remain 4m 21s) Loss: 0.0979(0.1961) Grad: 1.0912  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 11m 5s (remain 4m 5s) Loss: 0.2131(0.1958) Grad: 0.7738  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 11m 20s (remain 3m 50s) Loss: 0.2080(0.1955) Grad: 0.7991  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 11m 38s (remain 3m 35s) Loss: 0.0562(0.1953) Grad: 1.1312  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 11m 53s (remain 3m 20s) Loss: 0.2061(0.1951) Grad: 0.5488  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 12m 8s (remain 3m 4s) Loss: 0.1921(0.1949) Grad: 0.6169  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 12m 23s (remain 2m 48s) Loss: 0.1974(0.1946) Grad: 1.1025  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 12m 38s (remain 2m 33s) Loss: 0.2529(0.1943) Grad: 0.4951  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 12m 53s (remain 2m 17s) Loss: 0.1401(0.1940) Grad: 0.8674  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 13m 7s (remain 2m 1s) Loss: 0.1736(0.1937) Grad: 0.8105  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 13m 22s (remain 1m 46s) Loss: 0.1802(0.1934) Grad: 1.0341  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 13m 37s (remain 1m 30s) Loss: 0.1919(0.1932) Grad: 0.7882  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 13m 52s (remain 1m 15s) Loss: 0.1675(0.1931) Grad: 0.4371  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 14m 7s (remain 1m 0s) Loss: 0.1025(0.1927) Grad: 0.6943  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 14m 24s (remain 0m 44s) Loss: 0.1300(0.1925) Grad: 0.7264  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 14m 40s (remain 0m 29s) Loss: 0.1525(0.1920) Grad: 0.6987  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 14m 56s (remain 0m 13s) Loss: 0.1882(0.1917) Grad: 0.8439  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 15m 9s (remain 0m 0s) Loss: 0.1196(0.1913) Grad: 0.4366  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 9m 10s) Loss: 0.2364(0.2364) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 1s) Loss: 0.1786(0.1366) \n","EVAL: [200/737] Elapsed 0m 37s (remain 1m 41s) Loss: 0.2616(0.1646) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 21s) Loss: 0.1871(0.1797) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.1132(0.1796) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.2449(0.1833) \n","EVAL: [600/737] Elapsed 1m 52s (remain 0m 25s) Loss: 0.1697(0.1831) \n","EVAL: [700/737] Elapsed 2m 11s (remain 0m 6s) Loss: 0.1475(0.1792) \n","EVAL: [736/737] Elapsed 2m 18s (remain 0m 0s) Loss: 0.0624(0.1776) \n","f1 score : 0.3750567923671059\n","recall score : 0.25298804780876494\n","precision score : 0.7247585601404741\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.1913  avg_val_loss: 0.1776  time: 1051s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.1913  avg_val_loss: 0.1776  time: 1051s\n","Epoch 1 - Score: 0.3751\n","INFO:__main__:Epoch 1 - Score: 0.3751\n","Epoch 1 - Save Best Score: 0.4869 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4869 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 89m 49s) Loss: 0.1060(0.1060) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 17s (remain 16m 22s) Loss: 0.2073(0.1626) Grad: 0.7751  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 32s (remain 15m 28s) Loss: 0.1410(0.1636) Grad: 0.7628  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 48s (remain 14m 59s) Loss: 0.1379(0.1677) Grad: 0.7789  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 1m 3s (remain 14m 34s) Loss: 0.1859(0.1664) Grad: 0.7795  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 1m 19s (remain 14m 16s) Loss: 0.1138(0.1651) Grad: 0.6006  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 1m 35s (remain 14m 0s) Loss: 0.1056(0.1680) Grad: 0.8392  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 52s (remain 13m 50s) Loss: 0.1796(0.1682) Grad: 0.6154  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 2m 9s (remain 13m 41s) Loss: 0.1862(0.1678) Grad: 1.4302  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 2m 25s (remain 13m 23s) Loss: 0.0738(0.1669) Grad: 0.3345  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 2m 41s (remain 13m 7s) Loss: 0.1763(0.1670) Grad: 0.9267  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 2m 57s (remain 12m 50s) Loss: 0.2130(0.1662) Grad: 0.7939  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 3m 12s (remain 12m 33s) Loss: 0.1229(0.1662) Grad: 0.3616  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 3m 28s (remain 12m 15s) Loss: 0.1458(0.1664) Grad: 0.6251  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 3m 44s (remain 11m 59s) Loss: 0.1151(0.1669) Grad: 0.5947  LR: 0.00001563  \n","Epoch: [2][1600/5891] Elapsed 4m 15s (remain 11m 24s) Loss: 0.2834(0.1657) Grad: 1.1515  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 4m 33s (remain 11m 14s) Loss: 0.1301(0.1646) Grad: 0.5499  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 4m 50s (remain 10m 59s) Loss: 0.0887(0.1642) Grad: 0.5374  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 5m 6s (remain 10m 42s) Loss: 0.0644(0.1644) Grad: 0.9381  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 5m 22s (remain 10m 26s) Loss: 0.2469(0.1644) Grad: 1.6971  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 5m 38s (remain 10m 10s) Loss: 0.2145(0.1643) Grad: 0.8585  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 5m 54s (remain 9m 53s) Loss: 0.2230(0.1645) Grad: 0.9168  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 6m 9s (remain 9m 36s) Loss: 0.2087(0.1648) Grad: 1.5308  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 6m 25s (remain 9m 20s) Loss: 0.1044(0.1650) Grad: 1.1215  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 6m 41s (remain 9m 3s) Loss: 0.2494(0.1650) Grad: 0.9528  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 6m 56s (remain 8m 47s) Loss: 0.2050(0.1653) Grad: 1.0753  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 7m 14s (remain 8m 33s) Loss: 0.0659(0.1654) Grad: 1.3923  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 7m 31s (remain 8m 17s) Loss: 0.2473(0.1652) Grad: 0.9381  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 7m 47s (remain 8m 1s) Loss: 0.2013(0.1655) Grad: 0.8818  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 8m 3s (remain 7m 45s) Loss: 0.0698(0.1658) Grad: 1.0480  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 8m 19s (remain 7m 29s) Loss: 0.1849(0.1660) Grad: 0.5809  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 8m 35s (remain 7m 13s) Loss: 0.1329(0.1662) Grad: 0.5727  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 8m 51s (remain 6m 57s) Loss: 0.0917(0.1662) Grad: 1.1245  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 9m 7s (remain 6m 40s) Loss: 0.2717(0.1662) Grad: 1.3945  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 9m 22s (remain 6m 24s) Loss: 0.1295(0.1658) Grad: 0.4538  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 9m 38s (remain 6m 7s) Loss: 0.0866(0.1656) Grad: 0.5076  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 9m 57s (remain 5m 53s) Loss: 0.1141(0.1654) Grad: 0.6638  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 10m 13s (remain 5m 37s) Loss: 0.1581(0.1655) Grad: 0.5836  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 10m 29s (remain 5m 20s) Loss: 0.1600(0.1655) Grad: 0.5871  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 10m 44s (remain 5m 4s) Loss: 0.1298(0.1653) Grad: 0.6677  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 11m 0s (remain 4m 48s) Loss: 0.1771(0.1651) Grad: 0.5726  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 11m 15s (remain 4m 31s) Loss: 0.0823(0.1650) Grad: 1.1763  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 11m 31s (remain 4m 15s) Loss: 0.1832(0.1648) Grad: 0.7087  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 11m 46s (remain 3m 59s) Loss: 0.1351(0.1647) Grad: 0.6918  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 12m 2s (remain 3m 42s) Loss: 0.1691(0.1643) Grad: 0.8400  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 12m 17s (remain 3m 26s) Loss: 0.1523(0.1645) Grad: 0.5325  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 12m 32s (remain 3m 10s) Loss: 0.1370(0.1647) Grad: 0.7401  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 12m 51s (remain 2m 55s) Loss: 0.1564(0.1644) Grad: 0.4640  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 13m 6s (remain 2m 38s) Loss: 0.3005(0.1645) Grad: 1.3153  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 13m 22s (remain 2m 22s) Loss: 0.2219(0.1645) Grad: 0.8275  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 13m 37s (remain 2m 6s) Loss: 0.1306(0.1644) Grad: 0.6374  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 13m 52s (remain 1m 50s) Loss: 0.1227(0.1642) Grad: 0.6787  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 14m 7s (remain 1m 34s) Loss: 0.1381(0.1639) Grad: 0.4692  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 14m 23s (remain 1m 18s) Loss: 0.1702(0.1638) Grad: 0.7739  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 14m 39s (remain 1m 2s) Loss: 0.3625(0.1640) Grad: 2.3812  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 14m 54s (remain 0m 46s) Loss: 0.0635(0.1640) Grad: 0.7450  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 15m 9s (remain 0m 30s) Loss: 0.1378(0.1639) Grad: 0.4601  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 15m 26s (remain 0m 14s) Loss: 0.1340(0.1637) Grad: 0.6770  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 15m 41s (remain 0m 0s) Loss: 0.1181(0.1638) Grad: 1.1638  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 10m 46s) Loss: 0.2172(0.2172) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 2s) Loss: 0.1385(0.1221) \n","EVAL: [200/737] Elapsed 0m 38s (remain 1m 41s) Loss: 0.2339(0.1484) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 22s) Loss: 0.1642(0.1604) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.1105(0.1610) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.2283(0.1644) \n","EVAL: [600/737] Elapsed 1m 53s (remain 0m 25s) Loss: 0.1509(0.1654) \n","EVAL: [700/737] Elapsed 2m 12s (remain 0m 6s) Loss: 0.1292(0.1627) \n","EVAL: [736/737] Elapsed 2m 18s (remain 0m 0s) Loss: 0.0528(0.1615) \n","f1 score : 0.4628710256681103\n","recall score : 0.33573398712840946\n","precision score : 0.7449846990819449\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.1638  avg_val_loss: 0.1615  time: 1083s\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-20-ffbd735fadca>\", line 15, in <cell line: 1>\n","    _oof_df = train_loop(train, fold)\n","  File \"<ipython-input-19-38f5fca6da2e>\", line 94, in train_loop\n","    LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","Message: 'Epoch 2 - avg_train_loss: 0.1638  avg_val_loss: 0.1615  time: 1083s'\n","Arguments: ()\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.1638  avg_val_loss: 0.1615  time: 1083s\n","Epoch 2 - Score: 0.4629\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-20-ffbd735fadca>\", line 15, in <cell line: 1>\n","    _oof_df = train_loop(train, fold)\n","  File \"<ipython-input-19-38f5fca6da2e>\", line 95, in train_loop\n","    LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","Message: 'Epoch 2 - Score: 0.4629'\n","Arguments: ()\n","INFO:__main__:Epoch 2 - Score: 0.4629\n","Epoch 2 - Save Best Score: 0.5315 Model\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-20-ffbd735fadca>\", line 15, in <cell line: 1>\n","    _oof_df = train_loop(train, fold)\n","  File \"<ipython-input-19-38f5fca6da2e>\", line 100, in train_loop\n","    LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","Message: 'Epoch 2 - Save Best Score: 0.5315 Model'\n","Arguments: ()\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5315 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 61m 3s) Loss: 0.1041(0.1041) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 21s (remain 20m 11s) Loss: 0.0437(0.1505) Grad: 1.0660  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 36s (remain 17m 20s) Loss: 0.1584(0.1565) Grad: 0.9417  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 51s (remain 16m 5s) Loss: 0.2031(0.1562) Grad: 0.9477  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 1m 7s (remain 15m 20s) Loss: 0.1356(0.1591) Grad: 0.6555  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 1m 22s (remain 14m 45s) Loss: 0.0690(0.1589) Grad: 1.2061  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 1m 37s (remain 14m 19s) Loss: 0.1558(0.1593) Grad: 1.2209  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 52s (remain 13m 54s) Loss: 0.2118(0.1579) Grad: 0.8173  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 2m 7s (remain 13m 31s) Loss: 0.1526(0.1592) Grad: 1.2247  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 2m 23s (remain 13m 12s) Loss: 0.0330(0.1589) Grad: 0.5683  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 2m 38s (remain 12m 54s) Loss: 0.0638(0.1574) Grad: 0.7485  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 2m 53s (remain 12m 35s) Loss: 0.1132(0.1574) Grad: 0.5966  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 3m 11s (remain 12m 26s) Loss: 0.1815(0.1575) Grad: 0.9315  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 3m 27s (remain 12m 10s) Loss: 0.1010(0.1567) Grad: 0.8481  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 3m 42s (remain 11m 51s) Loss: 0.2405(0.1564) Grad: 1.7748  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 3m 57s (remain 11m 33s) Loss: 0.1051(0.1564) Grad: 0.6339  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 4m 12s (remain 11m 15s) Loss: 0.1503(0.1553) Grad: 0.6124  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 4m 27s (remain 10m 58s) Loss: 0.2452(0.1549) Grad: 1.3130  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 4m 42s (remain 10m 41s) Loss: 0.0307(0.1545) Grad: 0.7688  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 4m 57s (remain 10m 24s) Loss: 0.1414(0.1539) Grad: 0.7454  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 5m 12s (remain 10m 8s) Loss: 0.1411(0.1533) Grad: 0.9031  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 5m 28s (remain 9m 51s) Loss: 0.1032(0.1532) Grad: 0.7135  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 5m 43s (remain 9m 35s) Loss: 0.0919(0.1528) Grad: 0.8830  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 5m 58s (remain 9m 19s) Loss: 0.1026(0.1528) Grad: 1.1179  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 6m 16s (remain 9m 7s) Loss: 0.1146(0.1524) Grad: 0.7464  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 6m 32s (remain 8m 52s) Loss: 0.1127(0.1523) Grad: 0.5222  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 6m 47s (remain 8m 35s) Loss: 0.0685(0.1519) Grad: 0.6312  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 7m 2s (remain 8m 18s) Loss: 0.1052(0.1520) Grad: 0.6564  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 7m 17s (remain 8m 2s) Loss: 0.2115(0.1520) Grad: 1.3117  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 7m 32s (remain 7m 46s) Loss: 0.0985(0.1517) Grad: 1.0318  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 7m 47s (remain 7m 29s) Loss: 0.2634(0.1515) Grad: 1.5648  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 8m 2s (remain 7m 13s) Loss: 0.0762(0.1515) Grad: 0.4598  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 8m 16s (remain 6m 57s) Loss: 0.1489(0.1516) Grad: 1.2637  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 8m 32s (remain 6m 41s) Loss: 0.0837(0.1515) Grad: 0.4978  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 8m 46s (remain 6m 25s) Loss: 0.2053(0.1518) Grad: 1.4632  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 9m 1s (remain 6m 9s) Loss: 0.1666(0.1517) Grad: 0.8787  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 9m 19s (remain 5m 55s) Loss: 0.2460(0.1519) Grad: 1.2417  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 9m 34s (remain 5m 39s) Loss: 0.2812(0.1521) Grad: 1.0463  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 9m 49s (remain 5m 24s) Loss: 0.2406(0.1522) Grad: 1.4488  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 10m 4s (remain 5m 8s) Loss: 0.1146(0.1522) Grad: 0.7937  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 10m 19s (remain 4m 52s) Loss: 0.1116(0.1524) Grad: 0.5057  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 10m 34s (remain 4m 37s) Loss: 0.1719(0.1525) Grad: 0.7208  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 10m 49s (remain 4m 21s) Loss: 0.0385(0.1524) Grad: 0.9349  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 11m 4s (remain 4m 5s) Loss: 0.1398(0.1523) Grad: 1.0607  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 11m 19s (remain 3m 49s) Loss: 0.1837(0.1524) Grad: 1.3375  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 11m 34s (remain 3m 34s) Loss: 0.1570(0.1521) Grad: 0.8375  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 11m 48s (remain 3m 18s) Loss: 0.0786(0.1518) Grad: 0.7126  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 12m 3s (remain 3m 3s) Loss: 0.0938(0.1517) Grad: 0.5430  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 12m 20s (remain 2m 48s) Loss: 0.0375(0.1516) Grad: 0.7625  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 12m 36s (remain 2m 32s) Loss: 0.2040(0.1515) Grad: 0.8327  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 12m 51s (remain 2m 17s) Loss: 0.0955(0.1511) Grad: 0.6807  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 13m 6s (remain 2m 1s) Loss: 0.2126(0.1512) Grad: 1.2892  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 13m 21s (remain 1m 46s) Loss: 0.0850(0.1512) Grad: 0.5994  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 13m 36s (remain 1m 30s) Loss: 0.1334(0.1512) Grad: 1.1148  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 13m 51s (remain 1m 15s) Loss: 0.0671(0.1512) Grad: 0.7268  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 14m 6s (remain 0m 59s) Loss: 0.1611(0.1512) Grad: 0.7566  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 14m 21s (remain 0m 44s) Loss: 0.1830(0.1512) Grad: 1.1747  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 14m 36s (remain 0m 29s) Loss: 0.1647(0.1510) Grad: 0.8040  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 14m 51s (remain 0m 13s) Loss: 0.1573(0.1509) Grad: 0.9928  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 15m 4s (remain 0m 0s) Loss: 0.3420(0.1509) Grad: 1.1949  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 9m 6s) Loss: 0.1961(0.1961) \n","EVAL: [100/737] Elapsed 0m 19s (remain 2m 3s) Loss: 0.1492(0.1197) \n","EVAL: [200/737] Elapsed 0m 38s (remain 1m 42s) Loss: 0.2288(0.1443) \n","EVAL: [300/737] Elapsed 0m 56s (remain 1m 22s) Loss: 0.1638(0.1559) \n","EVAL: [400/737] Elapsed 1m 15s (remain 1m 3s) Loss: 0.0987(0.1566) \n","EVAL: [500/737] Elapsed 1m 34s (remain 0m 44s) Loss: 0.2472(0.1602) \n","EVAL: [600/737] Elapsed 1m 53s (remain 0m 25s) Loss: 0.1562(0.1612) \n","EVAL: [700/737] Elapsed 2m 11s (remain 0m 6s) Loss: 0.1301(0.1585) \n","EVAL: [736/737] Elapsed 2m 18s (remain 0m 0s) Loss: 0.0503(0.1573) \n","f1 score : 0.49399899142713066\n","recall score : 0.375268158136684\n","precision score : 0.7226320448509885\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.1509  avg_val_loss: 0.1573  time: 1046s\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-20-ffbd735fadca>\", line 15, in <cell line: 1>\n","    _oof_df = train_loop(train, fold)\n","  File \"<ipython-input-19-38f5fca6da2e>\", line 94, in train_loop\n","    LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","Message: 'Epoch 3 - avg_train_loss: 0.1509  avg_val_loss: 0.1573  time: 1046s'\n","Arguments: ()\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.1509  avg_val_loss: 0.1573  time: 1046s\n","Epoch 3 - Score: 0.4940\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-20-ffbd735fadca>\", line 15, in <cell line: 1>\n","    _oof_df = train_loop(train, fold)\n","  File \"<ipython-input-19-38f5fca6da2e>\", line 95, in train_loop\n","    LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","Message: 'Epoch 3 - Score: 0.4940'\n","Arguments: ()\n","INFO:__main__:Epoch 3 - Score: 0.4940\n","Epoch 3 - Save Best Score: 0.5455 Model\n","--- Logging error ---\n","Traceback (most recent call last):\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1104, in emit\n","    self.flush()\n","  File \"/usr/lib/python3.10/logging/__init__.py\", line 1084, in flush\n","    self.stream.flush()\n","OSError: [Errno 107] Transport endpoint is not connected\n","Call stack:\n","  File \"/usr/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n","    return _run_code(code, main_globals, None,\n","  File \"/usr/lib/python3.10/runpy.py\", line 86, in _run_code\n","    exec(code, run_globals)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n","    app.launch_new_instance()\n","  File \"/usr/local/lib/python3.10/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n","    app.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n","    self.io_loop.start()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/platform/asyncio.py\", line 195, in start\n","    self.asyncio_loop.run_forever()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n","    self._run_once()\n","  File \"/usr/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n","    handle._run()\n","  File \"/usr/lib/python3.10/asyncio/events.py\", line 80, in _run\n","    self._context.run(self._callback, *self._args)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 685, in <lambda>\n","    lambda f: self._run_callback(functools.partial(callback, future))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/ioloop.py\", line 738, in _run_callback\n","    ret = callback()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 825, in inner\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 377, in dispatch_queue\n","    yield self.process_one()\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 250, in wrapper\n","    runner = Runner(ctx_run, result, future, yielded)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 748, in __init__\n","    self.ctx_run(self.run)\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 786, in run\n","    yielded = self.gen.send(value)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n","    yield gen.maybe_future(dispatch(*args))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n","    yield gen.maybe_future(handler(stream, idents, msg))\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n","    self.do_execute(\n","  File \"/usr/local/lib/python3.10/dist-packages/tornado/gen.py\", line 234, in wrapper\n","    yielded = ctx_run(next, result)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n","    res = shell.run_cell(code, store_history=store_history, silent=silent)\n","  File \"/usr/local/lib/python3.10/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n","    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n","    result = self._run_cell(\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n","    return runner(coro)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n","    coro.send(None)\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n","    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n","    if (await self.run_code(code, result,  async_=asy)):\n","  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n","    exec(code_obj, self.user_global_ns, self.user_ns)\n","  File \"<ipython-input-20-ffbd735fadca>\", line 15, in <cell line: 1>\n","    _oof_df = train_loop(train, fold)\n","  File \"<ipython-input-19-38f5fca6da2e>\", line 100, in train_loop\n","    LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","Message: 'Epoch 3 - Save Best Score: 0.5455 Model'\n","Arguments: ()\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5455 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 59m 58s) Loss: 0.1615(0.1615) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 16s (remain 15m 55s) Loss: 0.2340(0.1441) Grad: 1.0140  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 32s (remain 15m 23s) Loss: 0.1562(0.1427) Grad: 2.7502  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 48s (remain 14m 56s) Loss: 0.0551(0.1409) Grad: 0.8285  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 1m 6s (remain 15m 12s) Loss: 0.1566(0.1417) Grad: 1.1818  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 1m 22s (remain 14m 49s) Loss: 0.1167(0.1410) Grad: 0.5696  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 1m 38s (remain 14m 27s) Loss: 0.0549(0.1421) Grad: 1.1826  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 53s (remain 14m 0s) Loss: 0.2333(0.1423) Grad: 1.0366  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 2m 8s (remain 13m 37s) Loss: 0.1268(0.1405) Grad: 1.3311  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 2m 23s (remain 13m 15s) Loss: 0.2103(0.1407) Grad: 0.9453  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 2m 38s (remain 12m 53s) Loss: 0.0536(0.1413) Grad: 0.9743  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 2m 53s (remain 12m 34s) Loss: 0.1653(0.1414) Grad: 1.0853  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 3m 8s (remain 12m 16s) Loss: 0.0842(0.1411) Grad: 0.8502  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 3m 23s (remain 11m 57s) Loss: 0.1914(0.1409) Grad: 1.2662  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 3m 38s (remain 11m 39s) Loss: 0.2423(0.1409) Grad: 0.9771  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 3m 54s (remain 11m 26s) Loss: 0.2380(0.1411) Grad: 1.0406  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 4m 11s (remain 11m 13s) Loss: 0.1041(0.1408) Grad: 0.6237  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 4m 26s (remain 10m 55s) Loss: 0.2764(0.1406) Grad: 1.8209  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 4m 40s (remain 10m 37s) Loss: 0.0820(0.1408) Grad: 0.8206  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 4m 55s (remain 10m 20s) Loss: 0.1475(0.1406) Grad: 0.6422  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 5m 10s (remain 10m 4s) Loss: 0.0492(0.1409) Grad: 1.3266  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 5m 25s (remain 9m 47s) Loss: 0.0354(0.1412) Grad: 0.7915  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 5m 40s (remain 9m 31s) Loss: 0.1744(0.1409) Grad: 1.1477  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 5m 55s (remain 9m 14s) Loss: 0.0824(0.1411) Grad: 0.6857  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 6m 10s (remain 8m 58s) Loss: 0.1707(0.1412) Grad: 1.2872  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 6m 25s (remain 8m 42s) Loss: 0.2047(0.1411) Grad: 1.3295  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 6m 40s (remain 8m 26s) Loss: 0.1577(0.1414) Grad: 0.6773  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 6m 57s (remain 8m 12s) Loss: 0.1890(0.1415) Grad: 1.1072  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 7m 13s (remain 7m 57s) Loss: 0.0353(0.1412) Grad: 0.5482  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 7m 27s (remain 7m 41s) Loss: 0.2563(0.1413) Grad: 1.3195  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 7m 42s (remain 7m 25s) Loss: 0.1453(0.1411) Grad: 1.2772  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 7m 57s (remain 7m 9s) Loss: 0.1387(0.1412) Grad: 0.9558  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 8m 12s (remain 6m 53s) Loss: 0.1873(0.1411) Grad: 1.0325  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 8m 27s (remain 6m 37s) Loss: 0.0474(0.1408) Grad: 1.1440  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 8m 41s (remain 6m 22s) Loss: 0.0994(0.1409) Grad: 0.6645  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 8m 56s (remain 6m 6s) Loss: 0.2200(0.1410) Grad: 1.2966  LR: 0.00000050  \n"]}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"OotP5Fy0pmIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uj-f85L1tntx"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"V100","authorship_tag":"ABX9TyO1j/N+5Ah9rK/Ua9e+E7iS"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"5c11f8f3dcad453a9967d77ad8372f5f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ad7bc6073e4b435e909f85d2b73436d3","IPY_MODEL_360308e830904cdb86a2e4b4d8e1989b","IPY_MODEL_bb9c43313b9747569bf2fa7646641fae"],"layout":"IPY_MODEL_536ddfe6d93e4884a74308d7bc7e922a"}},"ad7bc6073e4b435e909f85d2b73436d3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b7d3b0f7da845e081a1b1f5e7e61655","placeholder":"​","style":"IPY_MODEL_bde7137acbb44c6ca8ba732a4af0a8a8","value":"Downloading (…)okenizer_config.json: 100%"}},"360308e830904cdb86a2e4b4d8e1989b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8fb2ce6535547b89dc12e2318099ca2","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a58ec279b1e443c0bca85ec5eac0f2b7","value":52}},"bb9c43313b9747569bf2fa7646641fae":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_58623b2481084e048abc0ba4b642367c","placeholder":"​","style":"IPY_MODEL_75a486cf3fca4495a5b6b537dd97b9c2","value":" 52.0/52.0 [00:00&lt;00:00, 2.01kB/s]"}},"536ddfe6d93e4884a74308d7bc7e922a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6b7d3b0f7da845e081a1b1f5e7e61655":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bde7137acbb44c6ca8ba732a4af0a8a8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8fb2ce6535547b89dc12e2318099ca2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a58ec279b1e443c0bca85ec5eac0f2b7":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"58623b2481084e048abc0ba4b642367c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75a486cf3fca4495a5b6b537dd97b9c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0232121ec17a4dde85beaf869b2db540":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3224ff4f92e549c4b22fb62738b85a97","IPY_MODEL_38e9b349c3ff49f99b14e9d66f618741","IPY_MODEL_c2ec9845ba734b8c82df1d5d6516a8be"],"layout":"IPY_MODEL_9c31fa911e3b434794a26568765dbb79"}},"3224ff4f92e549c4b22fb62738b85a97":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25d5efc7a33b42ddaa50e14be90654b4","placeholder":"​","style":"IPY_MODEL_09c32e5910704adaba90bac3db0c66b9","value":"Downloading (…)lve/main/config.json: 100%"}},"38e9b349c3ff49f99b14e9d66f618741":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b6d428fdbf04b52a39ae4a145f64375","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_34395be2fe494a95911b0d843a686c75","value":579}},"c2ec9845ba734b8c82df1d5d6516a8be":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8a0bc629e19e4d5f964becabf9c953cf","placeholder":"​","style":"IPY_MODEL_a18475c7048141d886b45060227fde49","value":" 579/579 [00:00&lt;00:00, 38.6kB/s]"}},"9c31fa911e3b434794a26568765dbb79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25d5efc7a33b42ddaa50e14be90654b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09c32e5910704adaba90bac3db0c66b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3b6d428fdbf04b52a39ae4a145f64375":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34395be2fe494a95911b0d843a686c75":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8a0bc629e19e4d5f964becabf9c953cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a18475c7048141d886b45060227fde49":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad7060badd164f008a4caf4fd87cedde":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_56dccb33d4b94c33bc746571b87f1593","IPY_MODEL_e8a61aa07ba54af1a0d569deed3da487","IPY_MODEL_902c88b71fc1470cb1b28a2ca9c69271"],"layout":"IPY_MODEL_4a5874d04ce1412a8c070da8e2ee4739"}},"56dccb33d4b94c33bc746571b87f1593":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_675b53d4c7ac49fda37b60a40be7dfc9","placeholder":"​","style":"IPY_MODEL_f6ebd36029574ad3a4652425b8401463","value":"Downloading spm.model: 100%"}},"e8a61aa07ba54af1a0d569deed3da487":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_28f4880b692b4adc8032ca2a44b402cf","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_113e3fb6ca084cc68a88795172bc7d67","value":2464616}},"902c88b71fc1470cb1b28a2ca9c69271":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5792d4b3968d48599cf3e9d5707f6821","placeholder":"​","style":"IPY_MODEL_96374946536c473e85d00cea2fc14256","value":" 2.46M/2.46M [00:00&lt;00:00, 50.1MB/s]"}},"4a5874d04ce1412a8c070da8e2ee4739":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"675b53d4c7ac49fda37b60a40be7dfc9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f6ebd36029574ad3a4652425b8401463":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28f4880b692b4adc8032ca2a44b402cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"113e3fb6ca084cc68a88795172bc7d67":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5792d4b3968d48599cf3e9d5707f6821":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"96374946536c473e85d00cea2fc14256":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4d64bf248f5d450382c526aca10dc959":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c1c91464643a423197f686ec3224d102","IPY_MODEL_b42bf0579b8d46ddbb76c254482c5bf4","IPY_MODEL_85972f0ad47b450f99e90b6e544880c2"],"layout":"IPY_MODEL_937ab54bdf4b417b88041c026b800b9f"}},"c1c91464643a423197f686ec3224d102":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79705da6978247f5a4070af6d0aa6464","placeholder":"​","style":"IPY_MODEL_cd69aa407e994503a9ec19df95d888e1","value":"Downloading pytorch_model.bin: 100%"}},"b42bf0579b8d46ddbb76c254482c5bf4":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_530d5a499da44537b047f360e6e7a331","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4f7cdcf5886d475a93efe571ce881b9e","value":371146213}},"85972f0ad47b450f99e90b6e544880c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c04ac063d14485f80722611c126d9f3","placeholder":"​","style":"IPY_MODEL_9f721ca58f484ea4bf723dd591173d0a","value":" 371M/371M [00:01&lt;00:00, 235MB/s]"}},"937ab54bdf4b417b88041c026b800b9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79705da6978247f5a4070af6d0aa6464":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cd69aa407e994503a9ec19df95d888e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"530d5a499da44537b047f360e6e7a331":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f7cdcf5886d475a93efe571ce881b9e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8c04ac063d14485f80722611c126d9f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9f721ca58f484ea4bf723dd591173d0a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}