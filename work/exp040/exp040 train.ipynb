{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17157,"status":"ok","timestamp":1693385651962,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"MM4dTYOWdrrK","outputId":"e50a7072-29a3-4de0-886c-afbfa68aab7d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install transformers\n","!pip install datasets\n","!pip install sentencepiece"],"metadata":{"id":"CD_RBZ2zbgMk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693385674450,"user_tz":-540,"elapsed":22490,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"1a7df89c-dab7-43a1-d992-4a294823e0ab"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers\n","  Downloading transformers-4.32.1-py3-none-any.whl (7.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n","Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n","  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m35.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m123.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n","  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n","Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.1\n","Collecting datasets\n","  Downloading datasets-2.14.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.3/519.3 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Collecting xxhash (from datasets)\n","  Downloading xxhash-3.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multiprocess (from datasets)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: xxhash, dill, multiprocess, datasets\n","Successfully installed datasets-2.14.4 dill-0.3.7 multiprocess-0.70.15 xxhash-3.3.0\n","Collecting sentencepiece\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","Successfully installed sentencepiece-0.1.99\n"]}]},{"cell_type":"code","source":["!nvidia-smi"],"metadata":{"id":"JK8PEmITblft","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693385674851,"user_tz":-540,"elapsed":405,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"0016b466-5503-4534-f83c-20574fcd4bc9"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Wed Aug 30 08:54:34 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  NVIDIA A100-SXM...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   32C    P0    46W / 400W |      0MiB / 40960MiB |      0%      Default |\n","|                               |                      |             Disabled |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gqVuaXRJeCOe","executionInfo":{"status":"ok","timestamp":1693385682364,"user_tz":-540,"elapsed":7515,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["import os\n","import gc\n","import math\n","import time\n","import random\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.simplefilter('ignore')\n","from tqdm import tqdm\n","import re\n","import html\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.optim import Adam, SGD, AdamW, RAdam\n","from torch.optim import lr_scheduler\n","from torch.utils.data import DataLoader, Dataset\n","\n","from sklearn.model_selection import StratifiedKFold,StratifiedGroupKFold,GroupKFold\n","from sklearn.metrics import log_loss,f1_score, recall_score, accuracy_score, precision_score\n","\n","from transformers import AutoModel, AutoConfig, AutoTokenizer, AdamW, DataCollatorWithPadding\n","from transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"jm5aYY3Qd6kO","executionInfo":{"status":"ok","timestamp":1693385683427,"user_tz":-540,"elapsed":1065,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["import os\n","\n","DIR = \"/content/drive/MyDrive/Competitions/Signate/MUFG2023\"\n","INPUT_DIR = os.path.join(DIR,\"input\")\n","OUTPUT_DIR = os.path.join(DIR,\"output\")\n","\n","if not os.path.exists(OUTPUT_DIR):\n","    os.makedirs(OUTPUT_DIR)\n","\n","\n","OUTPUT_EXP_DIR = DIR + '/output/EXP040/'\n","if not os.path.exists(OUTPUT_EXP_DIR):\n","    os.makedirs(OUTPUT_EXP_DIR)"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"cang6GVBAu94","executionInfo":{"status":"ok","timestamp":1693385683427,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["\n","\n","# ====================================================\n","# CFG\n","# ====================================================\n","class CFG:\n","    debug=False\n","    apex=True\n","    print_freq=100\n","    num_workers=4\n","    model=\"microsoft/deberta-v3-base\"\n","    # model='microsoft/deberta-base'\n","    # model='roberta-base'\n","    # model='roberta-large'\n","    # model='roberta-large-mnli'\n","    # model='xlnet-large-cased'\n","    # model='albert-xxlarge-v2'\n","    # model=\"microsoft/deberta-large\"\n","    # model=\"microsoft/deberta-v3-large\"\n","    # model='microsoft/deberta-v2-xlarge'\n","    # model='funnel-transformer/large'\n","    # model='funnel-transformer/medium'\n","    # model='albert-base-v2'\n","    # model='albert-large-v2'\n","    # model='google/electra-large-discriminator'\n","    # model='google/electra-base-discriminator'\n","    # model=\"facebook/bart-large-mnli\"\n","    # model=\"facebook/bart-large\"\n","    # model=\"facebook/bart-base\"\n","    scheduler='cosine' # ['linear', 'cosine']\n","    batch_scheduler=True\n","    num_cycles=0.5\n","    num_warmup_steps=0\n","    epochs=4\n","    encoder_lr=2e-5\n","    decoder_lr=2e-5\n","    min_lr=1e-6\n","    eps=1e-6\n","    betas=(0.9, 0.999)\n","    batch_size=64\n","    fc_dropout=0.2\n","    target=\"is_fraud?\"\n","    target_size=1\n","    max_len=256\n","    weight_decay=0.01\n","    gradient_accumulation_steps=1\n","    max_grad_norm=1000\n","    seed=42\n","    n_fold=5\n","    trn_fold=[0, 1, 2, 3, 4]\n","    train=True\n","    nth_awp_start_epoch=1\n","    gradient_checkpointing = False\n","    freezing = False\n","\n","if CFG.debug:\n","    CFG.epochs = 2\n","    CFG.trn_fold = [0, 1]"]},{"cell_type":"code","source":["def get_score(labels, outputs):\n","    thresh = 0.5\n","    y_pred = outputs\n","    y_true = labels\n","    f_score = f1_score(y_true, (y_pred>thresh).astype(int))\n","    r_score = recall_score(y_true, (y_pred>thresh).astype(int))\n","    p_score = precision_score(y_true, (y_pred>thresh).astype(int))\n","    print(f\"f1 score : {f_score}\")\n","    print(f\"recall score : {r_score}\")\n","    print(f\"precision score : {p_score}\")\n","    return f1_score(y_true, (y_pred>thresh).astype(int))\n","\n","def get_f1_score(labels, outputs):\n","    y_pred = outputs\n","    y_true = labels\n","    best_score = 0\n","    best_thresh = 0.5\n","    for thresh in np.arange(0.1, 0.80, 0.01):\n","        thresh = np.round(thresh, 2)\n","        score = f1_score(y_true, (y_pred>thresh).astype(int))\n","        #print(\"Accuracy score at threshold {0} is {1}\".format(thresh, score))\n","        if score > best_score:\n","          best_score = score\n","          best_thresh = thresh\n","    return f1_score(y_true, (y_pred>best_thresh).astype(int))\n","\n","\n","def get_logger(filename=OUTPUT_EXP_DIR+'train'):\n","    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n","    logger = getLogger(__name__)\n","    logger.setLevel(INFO)\n","    handler1 = StreamHandler()\n","    handler1.setFormatter(Formatter(\"%(message)s\"))\n","    handler2 = FileHandler(filename=f\"{filename}.log\")\n","    handler2.setFormatter(Formatter(\"%(message)s\"))\n","    logger.addHandler(handler1)\n","    logger.addHandler(handler2)\n","    return logger\n","\n","LOGGER = get_logger()\n","\n","def seed_everything(seed=CFG.seed):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(seed=CFG.seed)"],"metadata":{"id":"lOI-vnq5cDJP","executionInfo":{"status":"ok","timestamp":1693385683427,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def freeze(module):\n","    \"\"\"\n","    Freezes module's parameters.\n","    \"\"\"\n","\n","    for parameter in module.parameters():\n","        parameter.requires_grad = False\n","\n","def get_freezed_parameters(module):\n","    \"\"\"\n","    Returns names of freezed parameters of the given module.\n","    \"\"\"\n","\n","    freezed_parameters = []\n","    for name, parameter in module.named_parameters():\n","        if not parameter.requires_grad:\n","            freezed_parameters.append(name)\n","\n","    return freezed_parameters\n","\n","def set_embedding_parameters_bits(embeddings_path, optim_bits=32):\n","    \"\"\"\n","    https://github.com/huggingface/transformers/issues/14819#issuecomment-1003427930\n","    \"\"\"\n","\n","    embedding_types = (\"word\", \"position\", \"token_type\")\n","    for embedding_type in embedding_types:\n","        attr_name = f\"{embedding_type}_embeddings\"\n","\n","        if hasattr(embeddings_path, attr_name):\n","            bnb.optim.GlobalOptimManager.get_instance().register_module_override(\n","                getattr(embeddings_path, attr_name), 'weight', {'optim_bits': optim_bits}\n","            )"],"metadata":{"id":"3vZWA_5rcVEo","executionInfo":{"status":"ok","timestamp":1693385683661,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":950},"executionInfo":{"elapsed":2806,"status":"ok","timestamp":1693385686464,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"},"user_tz":-540},"id":"alfdMdcXeaGI","outputId":"3a9d7bc6-3419-4eb6-adc0-a028d181b314"},"outputs":[{"output_type":"stream","name":"stdout","text":["(471283, 12)\n"]},{"output_type":"display_data","data":{"text/plain":["   index  user_id  card_id  amount errors?  is_fraud?  merchant_id  \\\n","0      0     1721        0  $2.623      OK          0       209237   \n","1      1     1629        3    $6.4      OK          0         2568   \n","2      2      655        3  $123.5      OK          0       345310   \n","\n","  merchant_city merchant_state      zip   mcc           use_chip  \n","0        Joliet             IL  60436.0  5541  Swipe Transaction  \n","1      Edgerton             WI  53534.0  5814  Swipe Transaction  \n","2    Ridgefield             WA  98642.0  7538  Swipe Transaction  "],"text/html":["\n","  <div id=\"df-b51697d7-6b3d-4740-987a-74675980de87\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>user_id</th>\n","      <th>card_id</th>\n","      <th>amount</th>\n","      <th>errors?</th>\n","      <th>is_fraud?</th>\n","      <th>merchant_id</th>\n","      <th>merchant_city</th>\n","      <th>merchant_state</th>\n","      <th>zip</th>\n","      <th>mcc</th>\n","      <th>use_chip</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>1721</td>\n","      <td>0</td>\n","      <td>$2.623</td>\n","      <td>OK</td>\n","      <td>0</td>\n","      <td>209237</td>\n","      <td>Joliet</td>\n","      <td>IL</td>\n","      <td>60436.0</td>\n","      <td>5541</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1629</td>\n","      <td>3</td>\n","      <td>$6.4</td>\n","      <td>OK</td>\n","      <td>0</td>\n","      <td>2568</td>\n","      <td>Edgerton</td>\n","      <td>WI</td>\n","      <td>53534.0</td>\n","      <td>5814</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>655</td>\n","      <td>3</td>\n","      <td>$123.5</td>\n","      <td>OK</td>\n","      <td>0</td>\n","      <td>345310</td>\n","      <td>Ridgefield</td>\n","      <td>WA</td>\n","      <td>98642.0</td>\n","      <td>7538</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b51697d7-6b3d-4740-987a-74675980de87')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-b51697d7-6b3d-4740-987a-74675980de87 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-b51697d7-6b3d-4740-987a-74675980de87');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(457958, 11)\n"]},{"output_type":"display_data","data":{"text/plain":["    index  user_id  card_id    amount errors?  merchant_id      merchant_city  \\\n","0  471283      541        3  $113.278      OK       324189            Orlando   \n","1  471284      655        1  $293.944      OK        81219         Ridgefield   \n","2  471285      492        0     $47.4      OK       274755  Arlington Heights   \n","\n","  merchant_state      zip   mcc           use_chip  \n","0             FL  32821.0  4814  Swipe Transaction  \n","1             WA  98642.0  7538   Chip Transaction  \n","2             IL  60004.0  5719  Swipe Transaction  "],"text/html":["\n","  <div id=\"df-ba390282-8d20-4619-985d-4181a230d575\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>index</th>\n","      <th>user_id</th>\n","      <th>card_id</th>\n","      <th>amount</th>\n","      <th>errors?</th>\n","      <th>merchant_id</th>\n","      <th>merchant_city</th>\n","      <th>merchant_state</th>\n","      <th>zip</th>\n","      <th>mcc</th>\n","      <th>use_chip</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>471283</td>\n","      <td>541</td>\n","      <td>3</td>\n","      <td>$113.278</td>\n","      <td>OK</td>\n","      <td>324189</td>\n","      <td>Orlando</td>\n","      <td>FL</td>\n","      <td>32821.0</td>\n","      <td>4814</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>471284</td>\n","      <td>655</td>\n","      <td>1</td>\n","      <td>$293.944</td>\n","      <td>OK</td>\n","      <td>81219</td>\n","      <td>Ridgefield</td>\n","      <td>WA</td>\n","      <td>98642.0</td>\n","      <td>7538</td>\n","      <td>Chip Transaction</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>471285</td>\n","      <td>492</td>\n","      <td>0</td>\n","      <td>$47.4</td>\n","      <td>OK</td>\n","      <td>274755</td>\n","      <td>Arlington Heights</td>\n","      <td>IL</td>\n","      <td>60004.0</td>\n","      <td>5719</td>\n","      <td>Swipe Transaction</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba390282-8d20-4619-985d-4181a230d575')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-ba390282-8d20-4619-985d-4181a230d575 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-ba390282-8d20-4619-985d-4181a230d575');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(416, 10)\n"]},{"output_type":"display_data","data":{"text/plain":["   user_id  card_id card_brand card_type  expires has_chip  cards_issued  \\\n","0       39        0       Visa     Debit  09/2021      YES             1   \n","1       39        1       Amex    Credit  11/2024      YES             2   \n","2       41        0   Discover    Credit  03/2022      YES             2   \n","\n","  credit_limit acct_open_date  year_pin_last_changed  \n","0       $17117        05/2007                   2010  \n","1        $5400        10/2015                   2015  \n","2       $14800        12/2010                   2011  "],"text/html":["\n","  <div id=\"df-fa750533-8dcd-4668-84aa-af03937d5e53\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>card_id</th>\n","      <th>card_brand</th>\n","      <th>card_type</th>\n","      <th>expires</th>\n","      <th>has_chip</th>\n","      <th>cards_issued</th>\n","      <th>credit_limit</th>\n","      <th>acct_open_date</th>\n","      <th>year_pin_last_changed</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>0</td>\n","      <td>Visa</td>\n","      <td>Debit</td>\n","      <td>09/2021</td>\n","      <td>YES</td>\n","      <td>1</td>\n","      <td>$17117</td>\n","      <td>05/2007</td>\n","      <td>2010</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>39</td>\n","      <td>1</td>\n","      <td>Amex</td>\n","      <td>Credit</td>\n","      <td>11/2024</td>\n","      <td>YES</td>\n","      <td>2</td>\n","      <td>$5400</td>\n","      <td>10/2015</td>\n","      <td>2015</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>41</td>\n","      <td>0</td>\n","      <td>Discover</td>\n","      <td>Credit</td>\n","      <td>03/2022</td>\n","      <td>YES</td>\n","      <td>2</td>\n","      <td>$14800</td>\n","      <td>12/2010</td>\n","      <td>2011</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa750533-8dcd-4668-84aa-af03937d5e53')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fa750533-8dcd-4668-84aa-af03937d5e53 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fa750533-8dcd-4668-84aa-af03937d5e53');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(97, 17)\n"]},{"output_type":"display_data","data":{"text/plain":["   user_id  current_age  retirement_age  birth_year  birth_month  gender  \\\n","0       39           57              64        1962           12  Female   \n","1       41           39              66        1980           10  Female   \n","2       47           40              67        1979            5  Female   \n","\n","               address       city state  zipcode  latitude  longitude  \\\n","0  442 Burns Boulevard  Mansfield    MA     2048     42.02     -71.21   \n","1    3863 River Avenue    Lincoln    CA    95648     38.93    -121.25   \n","2      8799 Elm Avenue   Mckinney    TX    75069     33.20     -96.65   \n","\n","  per_capita_income_zipcode yearly_income_person total_debt  fico_score  \\\n","0                    $37407               $76274    $102611         698   \n","1                    $21829               $44506     $57994         849   \n","2                    $24684               $50329     $76759         625   \n","\n","   num_credit_cards  \n","0                 2  \n","1                 3  \n","2                 4  "],"text/html":["\n","  <div id=\"df-bbe001c7-2159-4a9e-bbba-05d0d2ec682e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_id</th>\n","      <th>current_age</th>\n","      <th>retirement_age</th>\n","      <th>birth_year</th>\n","      <th>birth_month</th>\n","      <th>gender</th>\n","      <th>address</th>\n","      <th>city</th>\n","      <th>state</th>\n","      <th>zipcode</th>\n","      <th>latitude</th>\n","      <th>longitude</th>\n","      <th>per_capita_income_zipcode</th>\n","      <th>yearly_income_person</th>\n","      <th>total_debt</th>\n","      <th>fico_score</th>\n","      <th>num_credit_cards</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>39</td>\n","      <td>57</td>\n","      <td>64</td>\n","      <td>1962</td>\n","      <td>12</td>\n","      <td>Female</td>\n","      <td>442 Burns Boulevard</td>\n","      <td>Mansfield</td>\n","      <td>MA</td>\n","      <td>2048</td>\n","      <td>42.02</td>\n","      <td>-71.21</td>\n","      <td>$37407</td>\n","      <td>$76274</td>\n","      <td>$102611</td>\n","      <td>698</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>41</td>\n","      <td>39</td>\n","      <td>66</td>\n","      <td>1980</td>\n","      <td>10</td>\n","      <td>Female</td>\n","      <td>3863 River Avenue</td>\n","      <td>Lincoln</td>\n","      <td>CA</td>\n","      <td>95648</td>\n","      <td>38.93</td>\n","      <td>-121.25</td>\n","      <td>$21829</td>\n","      <td>$44506</td>\n","      <td>$57994</td>\n","      <td>849</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>47</td>\n","      <td>40</td>\n","      <td>67</td>\n","      <td>1979</td>\n","      <td>5</td>\n","      <td>Female</td>\n","      <td>8799 Elm Avenue</td>\n","      <td>Mckinney</td>\n","      <td>TX</td>\n","      <td>75069</td>\n","      <td>33.20</td>\n","      <td>-96.65</td>\n","      <td>$24684</td>\n","      <td>$50329</td>\n","      <td>$76759</td>\n","      <td>625</td>\n","      <td>4</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bbe001c7-2159-4a9e-bbba-05d0d2ec682e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bbe001c7-2159-4a9e-bbba-05d0d2ec682e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bbe001c7-2159-4a9e-bbba-05d0d2ec682e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["(457958, 2)\n"]},{"output_type":"display_data","data":{"text/plain":["        0  1\n","0  471283  0\n","1  471284  1\n","2  471285  0"],"text/html":["\n","  <div id=\"df-0459265d-029e-4ed2-9b06-fa5f03ac192d\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>471283</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>471284</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>471285</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0459265d-029e-4ed2-9b06-fa5f03ac192d')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-0459265d-029e-4ed2-9b06-fa5f03ac192d button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-0459265d-029e-4ed2-9b06-fa5f03ac192d');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{}}],"source":["import pandas as pd\n","import numpy as np\n","\n","\n","train = pd.read_csv(os.path.join(INPUT_DIR,\"train.csv\"))\n","test = pd.read_csv(os.path.join(INPUT_DIR,\"test.csv\"))\n","card = pd.read_csv(os.path.join(INPUT_DIR, \"card.csv\"))\n","user = pd.read_csv(os.path.join(INPUT_DIR, \"user.csv\"))\n","sub = pd.read_csv(os.path.join(INPUT_DIR, \"sample_submit.csv\"), header=None)\n","\n","print(train.shape)\n","display(train.head(3))\n","\n","print(test.shape)\n","display(test.head(3))\n","\n","print(card.shape)\n","display(card.head(3))\n","\n","print(user.shape)\n","display(user.head(3))\n","\n","print(sub.shape)\n","display(sub.head(3))"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"i83_oAMoA1LW","executionInfo":{"status":"ok","timestamp":1693385686827,"user_tz":-540,"elapsed":367,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"outputs":[],"source":["train = train.merge(card, how=\"left\", on=[\"user_id\", \"card_id\"]).merge(user, how=\"left\", on=\"user_id\")"]},{"cell_type":"code","source":["month_dict = {\n","   \"01\": \"January\",\n","   \"02\": \"February\",\n","   \"03\": \"March\",\n","   \"04\": \"April\",\n","   \"05\": \"May\",\n","   \"06\": \"June\",\n","   \"07\": \"July\",\n","   \"08\": \"August\",\n","   \"09\": \"September\",\n","   \"10\": \"October\",\n","   \"11\": \"November\",\n","   \"12\": \"December\"\n","}\n","\n","def get_expires_values(df):\n","  _df = df[\"expires\"].str.split('/').apply(pd.Series)\n","  _df.columns = [\"month\",\"years\"]\n","  df[\"expires_month\"] = _df[\"month\"].astype(str)\n","  df[\"expires_years\"] = _df[\"years\"].astype(str)\n","  return df\n","\n","def get_acct_open_date_values(df):\n","  _df = df[\"acct_open_date\"].str.split('/').apply(pd.Series)\n","  _df.columns = [\"month\",\"years\"]\n","  df[\"acct_open_date_month\"] = _df[\"month\"].astype(str)\n","  df[\"acct_open_date_years\"] = _df[\"years\"].astype(str)\n","  return df\n","\n","train = get_expires_values(train)\n","train = get_acct_open_date_values(train)\n","train[\"expires_month\"] = train[\"expires_month\"].map(month_dict)\n","train[\"acct_open_date_month\"] = train[\"acct_open_date_month\"].map(month_dict)"],"metadata":{"id":"fA0Gj3oTfYow","executionInfo":{"status":"ok","timestamp":1693385792902,"user_tz":-540,"elapsed":106079,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["train.fillna('unknown', inplace = True)\n","\n","train[\"texts\"] = \"merchant\" + \"[SEP]\" + train[\"amount\"] + \"[SEP]\" + train[\"errors?\"] + \"[SEP]\" + train[\"merchant_city\"] + \"[SEP]\" + train[\"merchant_state\"] + \"[SEP]\" + train[\"use_chip\"] + \"[SEP]\" \\\n","+ \"card\" + \"[SEP]\" + train[\"card_brand\"] + \"[SEP]\" + train[\"card_type\"] + \"[SEP]\" + train[\"expires_month\"] + \" \" + train[\"expires_years\"] + \"[SEP]\" + train[\"has_chip\"] + \"[SEP]\" + train[\"acct_open_date_month\"] + \" \" + train[\"acct_open_date_years\"] + \"[SEP]\" + train[\"year_pin_last_changed\"].astype(str) + \"[SEP]\" \\\n","\"user\" + \"[SEP]\" + train[\"current_age\"].astype(str) + \" year old \" + train[\"gender\"] + \"[SEP]\" + \"retired at age \" + train[\"retirement_age\"].astype(str) + \"[SEP]\" + train[\"address\"] + \"[SEP]\" + train[\"city\"] + \"[SEP]\" + train[\"state\"] + \"[SEP]\" + train[\"per_capita_income_zipcode\"] + \"[SEP]\" + train[\"yearly_income_person\"] + \"[SEP]\" + train[\"total_debt\"]"],"metadata":{"id":"ZYevLBPI7-FT","executionInfo":{"status":"ok","timestamp":1693385797630,"user_tz":-540,"elapsed":4730,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["skf = StratifiedKFold(n_splits=CFG.n_fold,shuffle=True,random_state=CFG.seed)\n","for fold, ( _, val_) in enumerate(skf.split(train, train[CFG.target])):\n","    train.loc[val_ , \"kfold\"] = int(fold)\n","\n","train[\"kfold\"] = train[\"kfold\"].astype(int)\n","\n","if CFG.debug:\n","    display(train.groupby('kfold').size())\n","    train = train.sample(n=500, random_state=0).reset_index(drop=True)\n","    display(train.groupby('kfold').size())"],"metadata":{"id":"ZSX1VrbRlwwt","executionInfo":{"status":"ok","timestamp":1693385797631,"user_tz":-540,"elapsed":3,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# tokenizer\n","# ====================================================\n","tokenizer = AutoTokenizer.from_pretrained(CFG.model)\n","tokenizer.save_pretrained(OUTPUT_EXP_DIR+'tokenizer/')\n","CFG.tokenizer = tokenizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":149,"referenced_widgets":["818b9179fa9f4fb0b38288772d9d41dd","dee828389b7d48d8aad92c74abdf45e4","93533d041a76472598296d839a0adbae","bc09b428eb9543d0a5e696155b835dd4","9c30403f2cdb41239b05ae99f5840454","e110a57be1c040ec9029d9f5adf6515f","222e25829d22482db7054bda281e537d","7dfc386dd18545a6a89e98712d0caee3","bd5b1e9b01a543b5b0f233f65211e739","35b86a9a30054c0a850987841d91d22f","dc1fd44e5f1e47ecb1297e9efd360b51","8861f834d6184fc0ab6124b3268d107c","3cb2be1cfff946e08a010f111ef963a9","ee827dbdc0c14efc9f77faeb9b500304","1d7d82350521422d92295e12946eda38","6e8c9433f95c48b082e6b38d062f0d71","3e33d2927a6a484ba8e287468ccd8f35","186a627494d04be3ae518e637b12858b","54d14046e8194ae0afa0172978b79c79","0212059ce02c4775aa4f6d4fa8a986ec","ff13ea8f58d449728868d6095c90c1a6","22e805d89ab34890a2aa524b69e45805","8f5c94de514f469783333e5599727b13","09647192d6d3434f8e2ae88893dcf335","ff77f8500a884fb58f68d8233d7aec5d","81281e39d73d492083dc199521d75344","adcc792e668647ab8e03e22295e4c8cc","27374433b56447c782aaa28e515fb6e3","2df97483482941468b7a2b8239d81c66","a8f0a5744a84424bbfe438c8c341a35d","f5ba7c0ddc384881b7548d60da0db52c","f1542b28b6b14e5280c5df540eefdf62","c549d1f03c42430085fba5d9425af756"]},"id":"J8ohdOJCmB4m","executionInfo":{"status":"ok","timestamp":1693385801584,"user_tz":-540,"elapsed":3955,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"c709252f-b2c6-4a1f-8646-dee24b0343c8"},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"818b9179fa9f4fb0b38288772d9d41dd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/579 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8861f834d6184fc0ab6124b3268d107c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading spm.model:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8f5c94de514f469783333e5599727b13"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Define max_len\n","# ====================================================\n","lengths = []\n","tk0 = tqdm(train['texts'].fillna(\"\").values, total=len(train))\n","for text in tk0:\n","    length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n","    lengths.append(length)\n","CFG.max_len = max(lengths) + 23 # cls\n","LOGGER.info(f\"max_len: {CFG.max_len}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NZyGX8bXmFgI","executionInfo":{"status":"ok","timestamp":1693385892393,"user_tz":-540,"elapsed":90811,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}},"outputId":"65dd16a1-c7ba-4ac2-bdae-e5aaef2f5d22"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 471283/471283 [01:30<00:00, 5193.19it/s]\n","max_len: 97\n","INFO:__main__:max_len: 97\n"]}]},{"cell_type":"code","source":["# ====================================================\n","# Dataset\n","# ====================================================\n","def prepare_input(cfg, text):\n","    inputs = cfg.tokenizer(text,\n","                           add_special_tokens=True,\n","                           max_length=cfg.max_len,\n","                           padding=\"max_length\",\n","                           return_offsets_mapping=False,\n","                           truncation=True)\n","    for k, v in inputs.items():\n","        inputs[k] = torch.tensor(v, dtype=torch.long)\n","    return inputs\n","\n","\n","class TrainDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df[CFG.target].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.half)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","class ValidDataset(Dataset):\n","    def __init__(self, cfg, df):\n","        self.cfg = cfg\n","        self.inputs = df['texts'].values\n","        self.labels = df[CFG.target].values\n","\n","    def __len__(self):\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        inputs = prepare_input(self.cfg, self.inputs[item])\n","        label = torch.tensor(self.labels[item], dtype=torch.float)\n","        return inputs, label\n","\n","def collate(inputs):\n","    mask_len = int(inputs[\"attention_mask\"].sum(axis=1).max())\n","    for k, v in inputs.items():\n","        inputs[k] = inputs[k][:,:mask_len]\n","    return inputs\n","\n","#collate_fn = DataCollatorWithPadding(tokenizer=tokenizer)"],"metadata":{"id":"HOhlEza3o2pR","executionInfo":{"status":"ok","timestamp":1693385892626,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Model\n","# ====================================================\n","class MeanPooling(nn.Module):\n","    def __init__(self):\n","        super(MeanPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n","        sum_mask = input_mask_expanded.sum(1)\n","        sum_mask = torch.clamp(sum_mask, min=1e-9)\n","        mean_embeddings = sum_embeddings / sum_mask\n","        return mean_embeddings\n","\n","class MaxPooling(nn.Module):\n","    def __init__(self):\n","        super(MaxPooling, self).__init__()\n","\n","    def forward(self, last_hidden_state, attention_mask):\n","        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n","        embeddings = last_hidden_state.clone()\n","        embeddings[input_mask_expanded == 0] = -1e4\n","        max_embeddings, _ = torch.max(embeddings, dim=1)\n","        return max_embeddings\n","\n","\n","class CustomModel(nn.Module):\n","    def __init__(self, cfg, config_path=None, pretrained=False):\n","        super().__init__()\n","        self.cfg = cfg\n","        if config_path is None:\n","            self.config = AutoConfig.from_pretrained(cfg.model, output_hidden_states=True)\n","            self.config.hidden_dropout = 0.\n","            self.config.hidden_dropout_prob = 0.\n","            self.config.attention_dropout = 0.\n","            self.config.attention_probs_dropout_prob = 0.\n","            LOGGER.info(self.config)\n","        else:\n","            self.config = torch.load(config_path)\n","        if pretrained:\n","            self.model = AutoModel.from_pretrained(cfg.model, config=self.config)\n","        else:\n","            self.model = AutoModel(self.config)\n","        if self.cfg.gradient_checkpointing:\n","            self.model.gradient_checkpointing_enable()\n","\n","        # Freezing\n","        if cfg.freezing:\n","            # freezing embeddings and first 2 layers of encoder\n","            freeze((self.model).embeddings)\n","            freeze((self.model).encoder.layer[:2])\n","            cfg.after_freezed_parameters = filter(lambda parameter: parameter.requires_grad, (self.model).parameters())\n","\n","        self.pool = MeanPooling()\n","        self.fc = nn.Linear(self.config.hidden_size, cfg.target_size)\n","        self._init_weights(self.fc)\n","        self.layer_norm1 = nn.LayerNorm(self.config.hidden_size)\n","        self.sig = nn.Sigmoid()\n","\n","    def _init_weights(self, module):\n","        if isinstance(module, nn.Linear):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.bias is not None:\n","                module.bias.data.zero_()\n","        elif isinstance(module, nn.Embedding):\n","            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n","            if module.padding_idx is not None:\n","                module.weight.data[module.padding_idx].zero_()\n","        elif isinstance(module, nn.LayerNorm):\n","            module.bias.data.zero_()\n","            module.weight.data.fill_(1.0)\n","\n","    def feature(self, inputs):\n","        outputs = self.model(**inputs)\n","        last_hidden_states = outputs[0]\n","        feature = self.pool(last_hidden_states, inputs['attention_mask'])\n","        return feature\n","\n","    def forward(self, inputs):\n","        feature = self.feature(inputs)\n","        feature = self.layer_norm1(feature)\n","        output = self.fc(feature)\n","        #output = self.sig(output)\n","        return output"],"metadata":{"id":"bhk-PK8Mo-ia","executionInfo":{"status":"ok","timestamp":1693385892627,"user_tz":-540,"elapsed":7,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["class Focal_MultiLabel_Loss(nn.Module):\n","    def __init__(self, gamma):\n","      super(Focal_MultiLabel_Loss, self).__init__()\n","      self.gamma = gamma\n","      self.bceloss = nn.BCEWithLogitsLoss()\n","\n","    def forward(self, outputs, targets):\n","      bce = self.bceloss(outputs.view(-1, 1), targets.view(-1, 1))\n","      bce_exp = torch.exp(-bce)\n","      focal_loss = (1-bce_exp)**self.gamma * bce\n","      return focal_loss.mean()"],"metadata":{"id":"1ipHUbDknoqK","executionInfo":{"status":"ok","timestamp":1693385892627,"user_tz":-540,"elapsed":6,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# Helper functions\n","# ====================================================\n","class AverageMeter(object):\n","    \"\"\"Computes and stores the average and current value\"\"\"\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count\n","\n","\n","def asMinutes(s):\n","    m = math.floor(s / 60)\n","    s -= m * 60\n","    return '%dm %ds' % (m, s)\n","\n","\n","def timeSince(since, percent):\n","    now = time.time()\n","    s = now - since\n","    es = s / (percent)\n","    rs = es - s\n","    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n","\n","\n","def train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n","    model.train()\n","    scaler = torch.cuda.amp.GradScaler(enabled=CFG.apex)\n","    losses = AverageMeter()\n","    start = end = time.time()\n","    global_step = 0\n","    for step, (inputs, labels) in enumerate(train_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.cuda.amp.autocast(enabled=CFG.apex):\n","            y_preds = model(inputs)\n","        #print(y_preds.sigmoid().squeeze().view(1, -1))\n","        loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        scaler.scale(loss).backward()\n","        scaler.unscale_(optimizer)\n","        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n","        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n","            scaler.step(optimizer)\n","            scaler.update()\n","            optimizer.zero_grad()\n","            global_step += 1\n","            if CFG.batch_scheduler:\n","                scheduler.step()\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n","            print('Epoch: [{0}][{1}/{2}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  'Grad: {grad_norm:.4f}  '\n","                  'LR: {lr:.8f}  '\n","                  .format(epoch+1, step, len(train_loader),\n","                          remain=timeSince(start, float(step+1)/len(train_loader)),\n","                          loss=losses,\n","                          grad_norm=grad_norm,\n","                          lr=scheduler.get_lr()[0]))\n","\n","    return losses.avg\n","\n","\n","def valid_fn(valid_loader, model, criterion, device):\n","    losses = AverageMeter()\n","    model.eval()\n","    preds = []\n","    start = end = time.time()\n","    for step, (inputs, labels) in enumerate(valid_loader):\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        labels = labels.to(device)\n","        batch_size = labels.size(0)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        loss = criterion(y_preds, labels)\n","        if CFG.gradient_accumulation_steps > 1:\n","            loss = loss / CFG.gradient_accumulation_steps\n","        losses.update(loss.item(), batch_size)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","        end = time.time()\n","        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n","            print('EVAL: [{0}/{1}] '\n","                  'Elapsed {remain:s} '\n","                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n","                  .format(step, len(valid_loader),\n","                          loss=losses,\n","                          remain=timeSince(start, float(step+1)/len(valid_loader))))\n","    predictions = np.concatenate(preds)\n","    predictions = np.concatenate(predictions)\n","    return losses.avg, predictions\n","\n","\n","def inference_fn(test_loader, model, device):\n","    preds = []\n","    model.eval()\n","    model.to(device)\n","    tk0 = tqdm(test_loader, total=len(test_loader))\n","    for inputs in tk0:\n","        inputs = collate(inputs)\n","        for k, v in inputs.items():\n","            inputs[k] = v.to(device)\n","        with torch.no_grad():\n","            y_preds = model(inputs)\n","        preds.append(y_preds.sigmoid().to('cpu').numpy())\n","    predictions = np.concatenate(preds)\n","    return predictions"],"metadata":{"id":"vA_8DWfOpFRu","executionInfo":{"status":"ok","timestamp":1693385892627,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["# ====================================================\n","# train loop\n","# ====================================================\n","def train_loop(folds, fold):\n","\n","    LOGGER.info(f\"========== fold: {fold} training ==========\")\n","\n","    # ====================================================\n","    # loader\n","    # ====================================================\n","    train_folds = folds[folds['kfold'] != fold].reset_index(drop=True)\n","    valid_folds = folds[folds['kfold'] == fold].reset_index(drop=True)\n","    valid_labels = valid_folds[CFG.target].values\n","\n","    train_dataset = TrainDataset(CFG, train_folds)\n","    valid_dataset = ValidDataset(CFG, valid_folds)\n","\n","\n","    train_loader = DataLoader(train_dataset,\n","                              batch_size=CFG.batch_size,\n","                              shuffle=True,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n","    valid_loader = DataLoader(valid_dataset,\n","                              batch_size=CFG.batch_size*2,\n","                              shuffle=False,\n","                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n","\n","    # ====================================================\n","    # model & optimizer\n","    # ====================================================\n","    model = CustomModel(CFG, config_path=None, pretrained=True)\n","    torch.save(model.config, OUTPUT_EXP_DIR+'config.pth')\n","    model.to(device)\n","\n","    def get_optimizer_params(model, encoder_lr, decoder_lr, weight_decay=0.0):\n","        param_optimizer = list(model.named_parameters())\n","        no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n","        optimizer_parameters = [\n","            {'params': [p for n, p in model.model.named_parameters() if not any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': weight_decay},\n","            {'params': [p for n, p in model.model.named_parameters() if any(nd in n for nd in no_decay)],\n","             'lr': encoder_lr, 'weight_decay': 0.0},\n","            {'params': [p for n, p in model.named_parameters() if \"model\" not in n],\n","             'lr': decoder_lr, 'weight_decay': 0.0}\n","        ]\n","        return optimizer_parameters\n","\n","    optimizer_parameters = get_optimizer_params(model,\n","                                                encoder_lr=CFG.encoder_lr,\n","                                                decoder_lr=CFG.decoder_lr,\n","                                                weight_decay=CFG.weight_decay)\n","    optimizer = AdamW(optimizer_parameters, lr=CFG.encoder_lr, eps=CFG.eps, betas=CFG.betas)\n","\n","    # ====================================================\n","    # scheduler\n","    # ====================================================\n","    def get_scheduler(cfg, optimizer, num_train_steps):\n","        if cfg.scheduler == 'linear':\n","            scheduler = get_linear_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps\n","            )\n","        elif cfg.scheduler == 'cosine':\n","            scheduler = get_cosine_schedule_with_warmup(\n","                optimizer, num_warmup_steps=cfg.num_warmup_steps, num_training_steps=num_train_steps, num_cycles=cfg.num_cycles\n","            )\n","        return scheduler\n","\n","    num_train_steps = int(len(train_folds) / CFG.batch_size * CFG.epochs)\n","    scheduler = get_scheduler(CFG, optimizer, num_train_steps)\n","\n","    # ====================================================\n","    # loop\n","    # ====================================================\n","    criterion = Focal_MultiLabel_Loss(gamma=2.0)\n","\n","    best_score = -1.\n","\n","    for epoch in range(CFG.epochs):\n","\n","        start_time = time.time()\n","\n","        # train\n","        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n","\n","        # eval\n","        avg_val_loss, predictions = valid_fn(valid_loader, model, criterion, device)\n","\n","        # scoring\n","        score = get_score(valid_labels, predictions)\n","        f1_score = get_f1_score(valid_labels, predictions)\n","\n","        elapsed = time.time() - start_time\n","\n","        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n","        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n","\n","\n","        if best_score < f1_score:\n","            best_score = f1_score\n","            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n","            torch.save({'model': model.state_dict(),\n","                        'predictions': predictions},\n","                        OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\")\n","\n","    predictions = torch.load(OUTPUT_EXP_DIR+f\"{CFG.model.replace('/', '-')}_fold{fold}_best.pth\",\n","                             map_location=torch.device('cpu'))['predictions']\n","    valid_folds['pred'] = predictions\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    return valid_folds"],"metadata":{"id":"Au28-HoKpISb","executionInfo":{"status":"ok","timestamp":1693385892627,"user_tz":-540,"elapsed":5,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["if __name__ == '__main__':\n","\n","    def get_result(oof_df):\n","        labels = oof_df[CFG.target].values\n","        preds = oof_df['pred'].values\n","        score = get_score(labels, preds)\n","        f1_score = get_f1_score(labels, preds)\n","        LOGGER.info(f'Score: {score:<.4f}')\n","        LOGGER.info(f'F1 BEST Score: {f1_score:<.4f}')\n","\n","    if CFG.train:\n","        oof_df = pd.DataFrame()\n","        for fold in range(CFG.n_fold):\n","            if fold in CFG.trn_fold:\n","                _oof_df = train_loop(train, fold)\n","                oof_df = pd.concat([oof_df, _oof_df])\n","                LOGGER.info(f\"========== fold: {fold} result ==========\")\n","                get_result(_oof_df)\n","            #break\n","        oof_df = oof_df.reset_index(drop=True)\n","        LOGGER.info(f\"========== CV ==========\")\n","        get_result(oof_df)\n","        oof_df.to_pickle(OUTPUT_EXP_DIR+'oof_df.pkl')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["5020b2fec9f54586a8c91c4e27b6443e","723b6eafe6364207af42679bef0a8162","1826559c33bf4f54bf44743c547c93f6","def7d62d62f74a1d9abebe98ca24c290","86de5ad7938b49d5a9c6f2d5501ff4af","54764225c1164a38bfea9bbb19d7cda8","d9b3f6f2b61c426295b1e7c4e3e9ed15","7c3fb7c061ea43ccb9eba71dbd4354a8","c041fde973454bbbb76b9f2b94e4c9ea","a8e6d20db88f4da7b8067620ba7e1f26","9d3c2aeb41354c1ba0a5a0e5eed69923"]},"id":"cDCGpigkpcaI","outputId":"0af5cde9-884b-4fe9-d711-03a05197efd5","executionInfo":{"status":"ok","timestamp":1693398411876,"user_tz":-540,"elapsed":12519254,"user":{"displayName":"Tasuku Kuriki","userId":"00300535165227155816"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stderr","text":["========== fold: 0 training ==========\n","INFO:__main__:========== fold: 0 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/371M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5020b2fec9f54586a8c91c4e27b6443e"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 3s (remain 381m 56s) Loss: 0.3000(0.3000) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 12s (remain 12m 8s) Loss: 0.0195(0.0289) Grad: 0.0379  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 21s (remain 10m 7s) Loss: 0.0105(0.0211) Grad: 0.0638  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 30s (remain 9m 21s) Loss: 0.0079(0.0181) Grad: 0.1107  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 0m 39s (remain 8m 55s) Loss: 0.0054(0.0165) Grad: 0.1158  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 0m 47s (remain 8m 35s) Loss: 0.0126(0.0153) Grad: 0.1324  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 0m 56s (remain 8m 19s) Loss: 0.0025(0.0147) Grad: 0.0615  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 5s (remain 8m 6s) Loss: 0.0167(0.0141) Grad: 0.2039  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 1m 14s (remain 7m 52s) Loss: 0.0222(0.0139) Grad: 0.0454  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 1m 23s (remain 7m 40s) Loss: 0.0128(0.0133) Grad: 0.1556  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 1m 31s (remain 7m 28s) Loss: 0.0139(0.0128) Grad: 0.0998  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 1m 40s (remain 7m 18s) Loss: 0.0072(0.0126) Grad: 0.0678  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 1m 49s (remain 7m 7s) Loss: 0.0042(0.0124) Grad: 0.0920  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 1m 58s (remain 6m 57s) Loss: 0.0006(0.0121) Grad: 0.0374  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 2m 6s (remain 6m 46s) Loss: 0.0086(0.0119) Grad: 0.0512  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 2m 15s (remain 6m 36s) Loss: 0.0133(0.0117) Grad: 0.1148  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 2m 24s (remain 6m 27s) Loss: 0.0658(0.0115) Grad: 0.6452  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 2m 33s (remain 6m 17s) Loss: 0.0063(0.0112) Grad: 0.0591  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 2m 42s (remain 6m 8s) Loss: 0.0027(0.0111) Grad: 0.0850  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 2m 50s (remain 5m 58s) Loss: 0.0043(0.0109) Grad: 0.0406  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 2m 59s (remain 5m 49s) Loss: 0.0013(0.0108) Grad: 0.0367  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 3m 8s (remain 5m 39s) Loss: 0.0029(0.0107) Grad: 0.0414  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 3m 17s (remain 5m 30s) Loss: 0.0048(0.0106) Grad: 0.0351  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 3m 25s (remain 5m 21s) Loss: 0.0128(0.0105) Grad: 0.1383  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 3m 34s (remain 5m 12s) Loss: 0.0017(0.0103) Grad: 0.0329  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 3m 43s (remain 5m 2s) Loss: 0.0217(0.0103) Grad: 0.2198  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 3m 52s (remain 4m 53s) Loss: 0.0109(0.0102) Grad: 0.1199  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 4m 0s (remain 4m 44s) Loss: 0.0089(0.0100) Grad: 0.0944  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 4m 9s (remain 4m 35s) Loss: 0.0042(0.0100) Grad: 0.0422  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 4m 18s (remain 4m 26s) Loss: 0.0011(0.0099) Grad: 0.0356  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 4m 27s (remain 4m 17s) Loss: 0.0014(0.0098) Grad: 0.0537  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 4m 36s (remain 4m 8s) Loss: 0.0012(0.0097) Grad: 0.0374  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 4m 44s (remain 3m 59s) Loss: 0.0010(0.0097) Grad: 0.0425  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 4m 53s (remain 3m 50s) Loss: 0.0006(0.0096) Grad: 0.0115  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 5m 2s (remain 3m 41s) Loss: 0.0039(0.0095) Grad: 0.0529  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 5m 11s (remain 3m 32s) Loss: 0.0042(0.0095) Grad: 0.0409  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 5m 20s (remain 3m 23s) Loss: 0.0074(0.0094) Grad: 0.0866  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 5m 28s (remain 3m 14s) Loss: 0.0223(0.0093) Grad: 0.3711  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 5m 37s (remain 3m 5s) Loss: 0.0071(0.0093) Grad: 0.0542  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 5m 46s (remain 2m 56s) Loss: 0.0024(0.0092) Grad: 0.0350  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 5m 55s (remain 2m 47s) Loss: 0.0059(0.0091) Grad: 0.0606  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 6m 4s (remain 2m 38s) Loss: 0.0161(0.0091) Grad: 0.1681  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 6m 12s (remain 2m 29s) Loss: 0.0026(0.0090) Grad: 0.0839  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 6m 21s (remain 2m 21s) Loss: 0.0052(0.0090) Grad: 0.0535  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 6m 30s (remain 2m 12s) Loss: 0.0027(0.0089) Grad: 0.0514  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 6m 39s (remain 2m 3s) Loss: 0.0113(0.0089) Grad: 0.1373  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 6m 47s (remain 1m 54s) Loss: 0.0052(0.0088) Grad: 0.1199  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 6m 56s (remain 1m 45s) Loss: 0.0022(0.0088) Grad: 0.0450  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 7m 5s (remain 1m 36s) Loss: 0.0046(0.0087) Grad: 0.0628  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 7m 14s (remain 1m 27s) Loss: 0.0022(0.0087) Grad: 0.0197  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 7m 22s (remain 1m 18s) Loss: 0.0114(0.0086) Grad: 0.1233  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 7m 31s (remain 1m 9s) Loss: 0.0200(0.0086) Grad: 0.1387  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 7m 40s (remain 1m 1s) Loss: 0.0018(0.0086) Grad: 0.0286  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 7m 49s (remain 0m 52s) Loss: 0.0011(0.0085) Grad: 0.0351  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 7m 57s (remain 0m 43s) Loss: 0.0317(0.0085) Grad: 0.3744  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 8m 6s (remain 0m 34s) Loss: 0.0069(0.0085) Grad: 0.1996  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 8m 15s (remain 0m 25s) Loss: 0.0009(0.0085) Grad: 0.0277  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 8m 24s (remain 0m 16s) Loss: 0.0062(0.0085) Grad: 0.0523  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 8m 32s (remain 0m 7s) Loss: 0.0049(0.0084) Grad: 0.0529  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 8m 40s (remain 0m 0s) Loss: 0.0110(0.0084) Grad: 0.1850  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 29s) Loss: 0.0035(0.0035) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 25s) Loss: 0.0084(0.0030) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0108(0.0044) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0047(0.0052) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0101(0.0055) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0062(0.0058) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0045(0.0058) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0015(0.0055) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0001(0.0054) \n","f1 score : 0.3900748854364592\n","recall score : 0.2673919705792216\n","precision score : 0.7207765386204048\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.0084  avg_val_loss: 0.0054  time: 622s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.0084  avg_val_loss: 0.0054  time: 622s\n","Epoch 1 - Score: 0.3901\n","INFO:__main__:Epoch 1 - Score: 0.3901\n","Epoch 1 - Save Best Score: 0.4879 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4879 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 37m 46s) Loss: 0.0121(0.0121) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 9s (remain 8m 55s) Loss: 0.0005(0.0050) Grad: 0.0229  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 18s (remain 8m 36s) Loss: 0.0039(0.0058) Grad: 0.0689  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 27s (remain 8m 21s) Loss: 0.0097(0.0058) Grad: 0.2700  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 0m 35s (remain 8m 11s) Loss: 0.0003(0.0058) Grad: 0.0184  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 0m 44s (remain 8m 0s) Loss: 0.0024(0.0060) Grad: 0.0284  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 0m 53s (remain 7m 49s) Loss: 0.0169(0.0058) Grad: 0.2101  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 2s (remain 7m 40s) Loss: 0.0028(0.0059) Grad: 0.0387  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 1m 10s (remain 7m 30s) Loss: 0.0090(0.0058) Grad: 0.0961  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 1m 19s (remain 7m 21s) Loss: 0.0088(0.0058) Grad: 0.0955  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.0040(0.0057) Grad: 0.0641  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 1m 37s (remain 7m 2s) Loss: 0.0067(0.0056) Grad: 0.0941  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.0045(0.0057) Grad: 0.0665  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 1m 54s (remain 6m 44s) Loss: 0.0106(0.0057) Grad: 0.0698  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 2m 3s (remain 6m 35s) Loss: 0.0007(0.0057) Grad: 0.0261  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0020(0.0057) Grad: 0.1093  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.0086(0.0058) Grad: 0.0869  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 2m 29s (remain 6m 9s) Loss: 0.0001(0.0058) Grad: 0.0069  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.0197(0.0058) Grad: 0.1949  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 2m 47s (remain 5m 51s) Loss: 0.0009(0.0058) Grad: 0.0179  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 2m 56s (remain 5m 42s) Loss: 0.0008(0.0058) Grad: 0.0274  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 3m 5s (remain 5m 33s) Loss: 0.0058(0.0058) Grad: 0.0640  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 3m 13s (remain 5m 24s) Loss: 0.0204(0.0058) Grad: 0.1557  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.0067(0.0058) Grad: 0.1259  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0142(0.0058) Grad: 0.1275  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.0008(0.0058) Grad: 0.0280  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 3m 48s (remain 4m 49s) Loss: 0.0025(0.0058) Grad: 0.0367  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 3m 57s (remain 4m 40s) Loss: 0.0036(0.0058) Grad: 0.0430  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 4m 6s (remain 4m 31s) Loss: 0.0043(0.0058) Grad: 0.0385  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0023(0.0058) Grad: 0.0350  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 4m 23s (remain 4m 14s) Loss: 0.0029(0.0058) Grad: 0.0269  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 4m 32s (remain 4m 5s) Loss: 0.0030(0.0058) Grad: 0.0625  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 4m 41s (remain 3m 56s) Loss: 0.0264(0.0058) Grad: 0.2195  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 4m 50s (remain 3m 47s) Loss: 0.0022(0.0058) Grad: 0.0409  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 4m 58s (remain 3m 38s) Loss: 0.0013(0.0058) Grad: 0.0357  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 5m 7s (remain 3m 30s) Loss: 0.0065(0.0057) Grad: 0.0682  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 5m 16s (remain 3m 21s) Loss: 0.0052(0.0057) Grad: 0.0531  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 5m 25s (remain 3m 12s) Loss: 0.0050(0.0057) Grad: 0.1947  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 5m 34s (remain 3m 3s) Loss: 0.0031(0.0057) Grad: 0.0395  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 5m 42s (remain 2m 54s) Loss: 0.0087(0.0057) Grad: 0.1376  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 5m 51s (remain 2m 46s) Loss: 0.0005(0.0057) Grad: 0.0193  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 6m 0s (remain 2m 37s) Loss: 0.0050(0.0057) Grad: 0.0428  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 6m 9s (remain 2m 28s) Loss: 0.0113(0.0056) Grad: 0.2127  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 6m 17s (remain 2m 19s) Loss: 0.0034(0.0056) Grad: 0.0492  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 6m 26s (remain 2m 10s) Loss: 0.0042(0.0056) Grad: 0.0517  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 6m 35s (remain 2m 2s) Loss: 0.0037(0.0056) Grad: 0.0418  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 6m 44s (remain 1m 53s) Loss: 0.0019(0.0056) Grad: 0.0409  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.0016(0.0056) Grad: 0.0260  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 7m 1s (remain 1m 35s) Loss: 0.0012(0.0055) Grad: 0.0225  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 7m 10s (remain 1m 26s) Loss: 0.0021(0.0055) Grad: 0.0486  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 7m 19s (remain 1m 18s) Loss: 0.0048(0.0055) Grad: 0.0572  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 7m 28s (remain 1m 9s) Loss: 0.0092(0.0055) Grad: 0.1131  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.0077(0.0055) Grad: 0.0951  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 7m 45s (remain 0m 51s) Loss: 0.0016(0.0055) Grad: 0.0327  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 7m 54s (remain 0m 43s) Loss: 0.0092(0.0055) Grad: 0.1235  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 8m 3s (remain 0m 34s) Loss: 0.0009(0.0055) Grad: 0.0114  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 8m 12s (remain 0m 25s) Loss: 0.0028(0.0055) Grad: 0.0472  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 8m 20s (remain 0m 16s) Loss: 0.0019(0.0055) Grad: 0.0359  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 8m 29s (remain 0m 7s) Loss: 0.0024(0.0055) Grad: 0.0343  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 8m 37s (remain 0m 0s) Loss: 0.0140(0.0055) Grad: 0.1267  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 43s) Loss: 0.0036(0.0036) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 25s) Loss: 0.0098(0.0026) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0079(0.0037) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0033(0.0042) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0080(0.0046) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0058(0.0048) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0052(0.0048) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0012(0.0045) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0000(0.0045) \n","f1 score : 0.4396887159533074\n","recall score : 0.3116763714373276\n","precision score : 0.7461482024944974\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.0055  avg_val_loss: 0.0045  time: 619s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.0055  avg_val_loss: 0.0045  time: 619s\n","Epoch 2 - Score: 0.4397\n","INFO:__main__:Epoch 2 - Score: 0.4397\n","Epoch 2 - Save Best Score: 0.5300 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5300 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 37m 44s) Loss: 0.0082(0.0082) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 9s (remain 8m 49s) Loss: 0.0023(0.0043) Grad: 0.0268  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 18s (remain 8m 46s) Loss: 0.0051(0.0043) Grad: 0.0752  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 27s (remain 8m 29s) Loss: 0.0153(0.0045) Grad: 0.1691  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 0m 36s (remain 8m 15s) Loss: 0.0023(0.0048) Grad: 0.0414  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 0m 45s (remain 8m 4s) Loss: 0.0005(0.0047) Grad: 0.0170  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 0m 53s (remain 7m 54s) Loss: 0.0043(0.0047) Grad: 0.0402  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 2s (remain 7m 44s) Loss: 0.0089(0.0047) Grad: 0.1220  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 1m 11s (remain 7m 33s) Loss: 0.0043(0.0047) Grad: 0.0431  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 1m 20s (remain 7m 24s) Loss: 0.0088(0.0046) Grad: 0.0691  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 1m 29s (remain 7m 14s) Loss: 0.0031(0.0047) Grad: 0.0344  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 1m 37s (remain 7m 5s) Loss: 0.0018(0.0046) Grad: 0.0425  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 1m 46s (remain 6m 55s) Loss: 0.0018(0.0046) Grad: 0.0409  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 1m 55s (remain 6m 46s) Loss: 0.0009(0.0047) Grad: 0.0317  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 2m 3s (remain 6m 37s) Loss: 0.0017(0.0046) Grad: 0.0297  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 2m 12s (remain 6m 28s) Loss: 0.0007(0.0046) Grad: 0.0172  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 2m 21s (remain 6m 19s) Loss: 0.0018(0.0046) Grad: 0.0333  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 2m 30s (remain 6m 10s) Loss: 0.0057(0.0046) Grad: 0.0659  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 2m 39s (remain 6m 1s) Loss: 0.0004(0.0047) Grad: 0.0188  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 2m 47s (remain 5m 52s) Loss: 0.0009(0.0047) Grad: 0.0292  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 2m 56s (remain 5m 43s) Loss: 0.0049(0.0047) Grad: 0.0518  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 3m 5s (remain 5m 34s) Loss: 0.0043(0.0047) Grad: 0.0726  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 3m 14s (remain 5m 25s) Loss: 0.0022(0.0047) Grad: 0.0343  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 3m 23s (remain 5m 16s) Loss: 0.0067(0.0047) Grad: 0.0854  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0009(0.0047) Grad: 0.0226  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 3m 40s (remain 4m 59s) Loss: 0.0004(0.0046) Grad: 0.0147  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.0029(0.0046) Grad: 0.0700  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.0003(0.0046) Grad: 0.0106  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 4m 7s (remain 4m 32s) Loss: 0.0019(0.0046) Grad: 0.0547  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0057(0.0046) Grad: 0.0666  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.0120(0.0046) Grad: 0.1305  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 4m 33s (remain 4m 5s) Loss: 0.0006(0.0046) Grad: 0.0245  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0031(0.0046) Grad: 0.0875  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0013(0.0046) Grad: 0.0294  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.0035(0.0046) Grad: 0.0500  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0004(0.0046) Grad: 0.0197  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 5m 17s (remain 3m 21s) Loss: 0.0010(0.0046) Grad: 0.0285  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 5m 26s (remain 3m 12s) Loss: 0.0235(0.0046) Grad: 0.3492  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 5m 34s (remain 3m 4s) Loss: 0.0021(0.0046) Grad: 0.0469  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.0023(0.0046) Grad: 0.0364  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.0029(0.0046) Grad: 0.0480  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 6m 1s (remain 2m 37s) Loss: 0.0009(0.0046) Grad: 0.0403  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 6m 9s (remain 2m 28s) Loss: 0.0041(0.0046) Grad: 0.0554  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 6m 18s (remain 2m 19s) Loss: 0.0007(0.0046) Grad: 0.0232  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 6m 27s (remain 2m 11s) Loss: 0.0094(0.0046) Grad: 0.1264  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.0011(0.0046) Grad: 0.0400  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 6m 44s (remain 1m 53s) Loss: 0.0012(0.0046) Grad: 0.0296  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.0052(0.0046) Grad: 0.0442  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 7m 2s (remain 1m 35s) Loss: 0.0016(0.0046) Grad: 0.0404  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.0015(0.0046) Grad: 0.0421  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.0003(0.0046) Grad: 0.0183  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 7m 28s (remain 1m 9s) Loss: 0.0058(0.0046) Grad: 0.0469  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.0046(0.0046) Grad: 0.0435  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 7m 46s (remain 0m 51s) Loss: 0.0005(0.0046) Grad: 0.0129  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 7m 55s (remain 0m 43s) Loss: 0.0098(0.0046) Grad: 0.0911  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 8m 4s (remain 0m 34s) Loss: 0.0083(0.0046) Grad: 0.0810  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 8m 12s (remain 0m 25s) Loss: 0.0021(0.0045) Grad: 0.0614  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 8m 21s (remain 0m 16s) Loss: 0.0028(0.0045) Grad: 0.0481  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 8m 30s (remain 0m 7s) Loss: 0.0077(0.0045) Grad: 0.1177  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 8m 38s (remain 0m 0s) Loss: 0.0092(0.0045) Grad: 0.1133  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 28s) Loss: 0.0038(0.0038) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 25s) Loss: 0.0091(0.0025) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0058(0.0034) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0034(0.0039) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0081(0.0042) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0048(0.0044) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0042(0.0044) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0010(0.0042) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0000(0.0042) \n","f1 score : 0.4946021591363455\n","recall score : 0.37909898866074165\n","precision score : 0.7113283496262219\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0045  avg_val_loss: 0.0042  time: 620s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0045  avg_val_loss: 0.0042  time: 620s\n","Epoch 3 - Score: 0.4946\n","INFO:__main__:Epoch 3 - Score: 0.4946\n","Epoch 3 - Save Best Score: 0.5501 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5501 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 37m 21s) Loss: 0.0003(0.0003) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 9s (remain 8m 52s) Loss: 0.0065(0.0043) Grad: 0.0741  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 18s (remain 8m 40s) Loss: 0.0012(0.0040) Grad: 0.0154  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 27s (remain 8m 24s) Loss: 0.0012(0.0042) Grad: 0.0202  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 0m 35s (remain 8m 11s) Loss: 0.0118(0.0039) Grad: 0.1265  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 0m 44s (remain 8m 0s) Loss: 0.0083(0.0039) Grad: 0.0714  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 0m 53s (remain 7m 51s) Loss: 0.0008(0.0040) Grad: 0.0267  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 2s (remain 7m 41s) Loss: 0.0027(0.0040) Grad: 0.0481  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 1m 11s (remain 7m 31s) Loss: 0.0044(0.0040) Grad: 0.0634  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 1m 19s (remain 7m 22s) Loss: 0.0001(0.0040) Grad: 0.0073  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.0019(0.0041) Grad: 0.0709  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 1m 37s (remain 7m 3s) Loss: 0.0002(0.0040) Grad: 0.0144  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.0014(0.0040) Grad: 0.0290  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 1m 54s (remain 6m 45s) Loss: 0.0044(0.0040) Grad: 0.0398  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.0012(0.0039) Grad: 0.0198  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0041(0.0040) Grad: 0.0700  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.0014(0.0040) Grad: 0.0285  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 2m 30s (remain 6m 9s) Loss: 0.0010(0.0040) Grad: 0.0194  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.0147(0.0040) Grad: 0.1947  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 2m 47s (remain 5m 51s) Loss: 0.0045(0.0040) Grad: 0.0589  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 2m 56s (remain 5m 42s) Loss: 0.0002(0.0040) Grad: 0.0099  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 3m 5s (remain 5m 33s) Loss: 0.0047(0.0039) Grad: 0.0488  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 3m 13s (remain 5m 24s) Loss: 0.0052(0.0040) Grad: 0.0495  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.0047(0.0040) Grad: 0.0712  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0050(0.0039) Grad: 0.0960  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.0257(0.0039) Grad: 0.2805  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 3m 49s (remain 4m 49s) Loss: 0.0030(0.0039) Grad: 0.0639  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 3m 57s (remain 4m 40s) Loss: 0.0024(0.0039) Grad: 0.0690  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 4m 6s (remain 4m 32s) Loss: 0.0053(0.0039) Grad: 0.0761  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0002(0.0039) Grad: 0.0114  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.0017(0.0039) Grad: 0.0562  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 4m 33s (remain 4m 5s) Loss: 0.0022(0.0039) Grad: 0.0487  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 4m 41s (remain 3m 56s) Loss: 0.0014(0.0039) Grad: 0.0680  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 4m 50s (remain 3m 48s) Loss: 0.0031(0.0039) Grad: 0.0512  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.0044(0.0039) Grad: 0.0462  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0092(0.0039) Grad: 0.1259  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 5m 17s (remain 3m 21s) Loss: 0.0023(0.0039) Grad: 0.0414  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 5m 25s (remain 3m 12s) Loss: 0.0028(0.0040) Grad: 0.0490  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 5m 34s (remain 3m 3s) Loss: 0.0017(0.0039) Grad: 0.0283  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.0112(0.0039) Grad: 0.1863  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.0042(0.0039) Grad: 0.0564  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 6m 0s (remain 2m 37s) Loss: 0.0011(0.0040) Grad: 0.0216  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 6m 9s (remain 2m 28s) Loss: 0.0113(0.0039) Grad: 0.1217  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 6m 18s (remain 2m 19s) Loss: 0.0016(0.0040) Grad: 0.0360  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 6m 27s (remain 2m 11s) Loss: 0.0018(0.0040) Grad: 0.0292  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 6m 35s (remain 2m 2s) Loss: 0.0036(0.0040) Grad: 0.0829  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 6m 44s (remain 1m 53s) Loss: 0.0057(0.0040) Grad: 0.0940  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.0070(0.0040) Grad: 0.0953  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 7m 2s (remain 1m 35s) Loss: 0.0111(0.0040) Grad: 0.1463  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.0025(0.0040) Grad: 0.0301  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.0021(0.0040) Grad: 0.0516  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 7m 28s (remain 1m 9s) Loss: 0.0095(0.0040) Grad: 0.1180  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.0026(0.0040) Grad: 0.0426  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 7m 46s (remain 0m 51s) Loss: 0.0040(0.0040) Grad: 0.0655  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 7m 55s (remain 0m 43s) Loss: 0.0016(0.0040) Grad: 0.0362  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 8m 4s (remain 0m 34s) Loss: 0.0028(0.0039) Grad: 0.0566  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 8m 12s (remain 0m 25s) Loss: 0.0018(0.0039) Grad: 0.0273  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 8m 21s (remain 0m 16s) Loss: 0.0013(0.0039) Grad: 0.0357  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 8m 30s (remain 0m 7s) Loss: 0.0086(0.0039) Grad: 0.1276  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 8m 38s (remain 0m 0s) Loss: 0.0019(0.0039) Grad: 0.0390  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 26s) Loss: 0.0044(0.0044) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 26s) Loss: 0.0088(0.0025) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0055(0.0034) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0030(0.0039) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0076(0.0042) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0050(0.0044) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0037(0.0043) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0009(0.0041) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0000(0.0041) \n","f1 score : 0.49496981891348085\n","recall score : 0.37695372356726936\n","precision score : 0.7205623901581723\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0039  avg_val_loss: 0.0041  time: 620s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0039  avg_val_loss: 0.0041  time: 620s\n","Epoch 4 - Score: 0.4950\n","INFO:__main__:Epoch 4 - Score: 0.4950\n","Epoch 4 - Save Best Score: 0.5505 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.5505 Model\n","========== fold: 0 result ==========\n","INFO:__main__:========== fold: 0 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.49496981891348085\n","recall score : 0.37695372356726936\n","precision score : 0.7205623901581723\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.4950\n","INFO:__main__:Score: 0.4950\n","F1 BEST Score: 0.5505\n","INFO:__main__:F1 BEST Score: 0.5505\n","========== fold: 1 training ==========\n","INFO:__main__:========== fold: 1 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 0s (remain 39m 56s) Loss: 0.1646(0.1646) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 9s (remain 9m 25s) Loss: 0.0129(0.0210) Grad: 0.1377  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 18s (remain 8m 46s) Loss: 0.0040(0.0170) Grad: 0.0358  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 27s (remain 8m 28s) Loss: 0.0029(0.0148) Grad: 0.0601  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 0m 36s (remain 8m 14s) Loss: 0.0132(0.0135) Grad: 0.1076  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 0m 44s (remain 8m 3s) Loss: 0.0168(0.0129) Grad: 0.1722  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 0m 53s (remain 7m 52s) Loss: 0.0033(0.0120) Grad: 0.0391  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 2s (remain 7m 42s) Loss: 0.0313(0.0117) Grad: 0.2880  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 1m 11s (remain 7m 33s) Loss: 0.0048(0.0113) Grad: 0.1166  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 1m 20s (remain 7m 23s) Loss: 0.0054(0.0110) Grad: 0.0446  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 1m 28s (remain 7m 13s) Loss: 0.0060(0.0109) Grad: 0.0498  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 1m 37s (remain 7m 4s) Loss: 0.0036(0.0106) Grad: 0.1142  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 1m 46s (remain 6m 55s) Loss: 0.0240(0.0104) Grad: 0.1532  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 1m 55s (remain 6m 46s) Loss: 0.0243(0.0104) Grad: 0.1700  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 2m 3s (remain 6m 37s) Loss: 0.0028(0.0102) Grad: 0.0806  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 2m 12s (remain 6m 28s) Loss: 0.0087(0.0101) Grad: 0.0942  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 2m 21s (remain 6m 19s) Loss: 0.0048(0.0100) Grad: 0.0933  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 2m 30s (remain 6m 10s) Loss: 0.0041(0.0099) Grad: 0.0538  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 2m 39s (remain 6m 1s) Loss: 0.0057(0.0098) Grad: 0.1327  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 2m 48s (remain 5m 52s) Loss: 0.0058(0.0097) Grad: 0.0388  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 2m 56s (remain 5m 43s) Loss: 0.0036(0.0096) Grad: 0.1046  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 3m 5s (remain 5m 34s) Loss: 0.0046(0.0096) Grad: 0.1127  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 3m 14s (remain 5m 26s) Loss: 0.0083(0.0096) Grad: 0.0657  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 3m 23s (remain 5m 17s) Loss: 0.0036(0.0095) Grad: 0.0707  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.0063(0.0094) Grad: 0.0547  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 3m 40s (remain 4m 59s) Loss: 0.0083(0.0094) Grad: 0.0733  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.0214(0.0094) Grad: 0.1375  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.0137(0.0093) Grad: 0.1427  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 4m 7s (remain 4m 32s) Loss: 0.0062(0.0092) Grad: 0.0676  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 4m 16s (remain 4m 23s) Loss: 0.0078(0.0092) Grad: 0.0734  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.0008(0.0091) Grad: 0.0260  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 4m 33s (remain 4m 6s) Loss: 0.0016(0.0091) Grad: 0.0386  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0208(0.0090) Grad: 0.3024  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0044(0.0089) Grad: 0.0763  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 5m 0s (remain 3m 39s) Loss: 0.0019(0.0089) Grad: 0.0394  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0060(0.0088) Grad: 0.0558  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 5m 17s (remain 3m 22s) Loss: 0.0226(0.0088) Grad: 0.2694  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 5m 26s (remain 3m 13s) Loss: 0.0010(0.0087) Grad: 0.0425  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0036(0.0087) Grad: 0.0526  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 5m 44s (remain 2m 55s) Loss: 0.0027(0.0087) Grad: 0.1006  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 5m 53s (remain 2m 46s) Loss: 0.0035(0.0086) Grad: 0.0386  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 6m 2s (remain 2m 38s) Loss: 0.0062(0.0086) Grad: 0.0580  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 6m 10s (remain 2m 29s) Loss: 0.0072(0.0085) Grad: 0.0595  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.0114(0.0085) Grad: 0.1409  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.0053(0.0085) Grad: 0.0805  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 6m 37s (remain 2m 2s) Loss: 0.0005(0.0084) Grad: 0.0227  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 6m 46s (remain 1m 53s) Loss: 0.0094(0.0084) Grad: 0.0772  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 6m 54s (remain 1m 45s) Loss: 0.0109(0.0084) Grad: 0.0989  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 7m 3s (remain 1m 36s) Loss: 0.0023(0.0084) Grad: 0.1052  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 7m 12s (remain 1m 27s) Loss: 0.0082(0.0084) Grad: 0.0701  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 7m 21s (remain 1m 18s) Loss: 0.0136(0.0083) Grad: 0.1071  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 7m 30s (remain 1m 9s) Loss: 0.0013(0.0083) Grad: 0.0185  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 7m 38s (remain 1m 0s) Loss: 0.0312(0.0083) Grad: 0.4652  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 7m 47s (remain 0m 52s) Loss: 0.0072(0.0082) Grad: 0.0697  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 7m 56s (remain 0m 43s) Loss: 0.0146(0.0082) Grad: 0.1655  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 8m 5s (remain 0m 34s) Loss: 0.0471(0.0081) Grad: 0.5626  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 8m 14s (remain 0m 25s) Loss: 0.0048(0.0081) Grad: 0.0456  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 8m 22s (remain 0m 16s) Loss: 0.0013(0.0081) Grad: 0.0239  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 8m 31s (remain 0m 7s) Loss: 0.0012(0.0080) Grad: 0.0433  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0159(0.0080) Grad: 0.1266  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 38s) Loss: 0.0039(0.0039) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 25s) Loss: 0.0019(0.0032) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0117(0.0047) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0019(0.0053) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0064(0.0058) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0049(0.0060) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0060(0.0059) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0024(0.0058) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0017(0.0057) \n","f1 score : 0.4339582894459659\n","recall score : 0.31566043518234754\n","precision score : 0.6940700808625337\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.0080  avg_val_loss: 0.0057  time: 621s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.0080  avg_val_loss: 0.0057  time: 621s\n","Epoch 1 - Score: 0.4340\n","INFO:__main__:Epoch 1 - Score: 0.4340\n","Epoch 1 - Save Best Score: 0.5025 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.5025 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 38m 2s) Loss: 0.0026(0.0026) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 9s (remain 8m 47s) Loss: 0.0023(0.0052) Grad: 0.0717  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 18s (remain 8m 44s) Loss: 0.0026(0.0055) Grad: 0.0427  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 27s (remain 8m 29s) Loss: 0.0016(0.0055) Grad: 0.0294  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 0m 36s (remain 8m 15s) Loss: 0.0184(0.0055) Grad: 0.3364  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 0m 44s (remain 8m 3s) Loss: 0.0014(0.0055) Grad: 0.0161  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 0m 53s (remain 7m 52s) Loss: 0.0006(0.0057) Grad: 0.0241  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 2s (remain 7m 42s) Loss: 0.0020(0.0057) Grad: 0.0244  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 1m 11s (remain 7m 32s) Loss: 0.0135(0.0058) Grad: 0.1063  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 1m 20s (remain 7m 23s) Loss: 0.0010(0.0058) Grad: 0.0263  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 1m 28s (remain 7m 14s) Loss: 0.0041(0.0059) Grad: 0.0436  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 1m 37s (remain 7m 5s) Loss: 0.0008(0.0058) Grad: 0.0252  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 1m 46s (remain 6m 56s) Loss: 0.0020(0.0058) Grad: 0.0303  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 1m 55s (remain 6m 47s) Loss: 0.0023(0.0058) Grad: 0.0313  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 2m 4s (remain 6m 38s) Loss: 0.0016(0.0058) Grad: 0.0358  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 2m 13s (remain 6m 29s) Loss: 0.0021(0.0058) Grad: 0.0492  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 2m 21s (remain 6m 20s) Loss: 0.0034(0.0058) Grad: 0.0475  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 2m 30s (remain 6m 11s) Loss: 0.0042(0.0058) Grad: 0.0462  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 2m 39s (remain 6m 2s) Loss: 0.0002(0.0058) Grad: 0.0132  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 2m 48s (remain 5m 53s) Loss: 0.0065(0.0057) Grad: 0.0496  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 2m 57s (remain 5m 44s) Loss: 0.0079(0.0058) Grad: 0.1690  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 3m 5s (remain 5m 35s) Loss: 0.0052(0.0058) Grad: 0.0643  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 3m 14s (remain 5m 26s) Loss: 0.0024(0.0058) Grad: 0.0706  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 3m 23s (remain 5m 17s) Loss: 0.0030(0.0057) Grad: 0.0550  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.0007(0.0057) Grad: 0.0304  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 3m 41s (remain 4m 59s) Loss: 0.0012(0.0057) Grad: 0.0255  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.0043(0.0057) Grad: 0.0872  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.0050(0.0057) Grad: 0.0908  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 4m 7s (remain 4m 32s) Loss: 0.0102(0.0057) Grad: 0.1397  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 4m 16s (remain 4m 23s) Loss: 0.0034(0.0057) Grad: 0.0431  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 4m 25s (remain 4m 15s) Loss: 0.0052(0.0058) Grad: 0.0992  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 4m 34s (remain 4m 6s) Loss: 0.0037(0.0057) Grad: 0.0473  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0061(0.0057) Grad: 0.1280  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0017(0.0057) Grad: 0.0480  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 5m 0s (remain 3m 39s) Loss: 0.0108(0.0057) Grad: 0.1385  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 5m 9s (remain 3m 30s) Loss: 0.0198(0.0057) Grad: 0.1858  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 5m 17s (remain 3m 22s) Loss: 0.0042(0.0057) Grad: 0.0534  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 5m 26s (remain 3m 13s) Loss: 0.0025(0.0057) Grad: 0.0697  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0004(0.0057) Grad: 0.0178  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 5m 44s (remain 2m 55s) Loss: 0.0072(0.0057) Grad: 0.1172  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 5m 53s (remain 2m 46s) Loss: 0.0087(0.0057) Grad: 0.0909  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 6m 1s (remain 2m 37s) Loss: 0.0120(0.0057) Grad: 0.1691  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 6m 10s (remain 2m 29s) Loss: 0.0031(0.0056) Grad: 0.0520  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.0019(0.0056) Grad: 0.0421  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.0085(0.0056) Grad: 0.0722  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.0098(0.0056) Grad: 0.1573  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 6m 45s (remain 1m 53s) Loss: 0.0028(0.0056) Grad: 0.0506  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 6m 54s (remain 1m 44s) Loss: 0.0068(0.0056) Grad: 0.1069  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 7m 3s (remain 1m 36s) Loss: 0.0002(0.0056) Grad: 0.0107  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 7m 12s (remain 1m 27s) Loss: 0.0013(0.0055) Grad: 0.0204  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 7m 21s (remain 1m 18s) Loss: 0.0112(0.0055) Grad: 0.1483  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 7m 29s (remain 1m 9s) Loss: 0.0119(0.0055) Grad: 0.1296  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 7m 38s (remain 1m 0s) Loss: 0.0007(0.0055) Grad: 0.0238  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 7m 47s (remain 0m 52s) Loss: 0.0092(0.0055) Grad: 0.0746  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 7m 56s (remain 0m 43s) Loss: 0.0015(0.0055) Grad: 0.0437  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 8m 5s (remain 0m 34s) Loss: 0.0015(0.0055) Grad: 0.0478  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 8m 14s (remain 0m 25s) Loss: 0.0017(0.0055) Grad: 0.0268  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 8m 22s (remain 0m 16s) Loss: 0.0078(0.0055) Grad: 0.0620  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 8m 31s (remain 0m 7s) Loss: 0.0006(0.0055) Grad: 0.0425  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0112(0.0055) Grad: 0.1124  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 41s) Loss: 0.0046(0.0046) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 25s) Loss: 0.0014(0.0027) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0103(0.0040) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0016(0.0046) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0053(0.0049) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0038(0.0050) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0044(0.0049) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0011(0.0047) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0014(0.0046) \n","f1 score : 0.4583333333333333\n","recall score : 0.3371130861170702\n","precision score : 0.715679895901106\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.0055  avg_val_loss: 0.0046  time: 621s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.0055  avg_val_loss: 0.0046  time: 621s\n","Epoch 2 - Score: 0.4583\n","INFO:__main__:Epoch 2 - Score: 0.4583\n","Epoch 2 - Save Best Score: 0.5285 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5285 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 38m 30s) Loss: 0.0042(0.0042) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 9s (remain 8m 54s) Loss: 0.0005(0.0053) Grad: 0.0202  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 18s (remain 8m 43s) Loss: 0.0061(0.0046) Grad: 0.1019  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 27s (remain 8m 25s) Loss: 0.0062(0.0048) Grad: 0.0615  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 0m 36s (remain 8m 12s) Loss: 0.0028(0.0047) Grad: 0.0614  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 0m 44s (remain 8m 1s) Loss: 0.0016(0.0046) Grad: 0.0275  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 0m 53s (remain 7m 51s) Loss: 0.0228(0.0047) Grad: 0.2589  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 2s (remain 7m 41s) Loss: 0.0126(0.0046) Grad: 0.2358  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 1m 11s (remain 7m 31s) Loss: 0.0020(0.0045) Grad: 0.0267  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 1m 19s (remain 7m 22s) Loss: 0.0005(0.0046) Grad: 0.0202  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.0042(0.0046) Grad: 0.0559  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 1m 37s (remain 7m 3s) Loss: 0.0038(0.0046) Grad: 0.0690  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.0044(0.0046) Grad: 0.0694  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 1m 54s (remain 6m 45s) Loss: 0.0024(0.0046) Grad: 0.0573  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.0152(0.0047) Grad: 0.1671  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0043(0.0047) Grad: 0.0493  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.0009(0.0046) Grad: 0.0300  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 2m 29s (remain 6m 9s) Loss: 0.0091(0.0046) Grad: 0.1251  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.0015(0.0046) Grad: 0.0292  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 2m 47s (remain 5m 51s) Loss: 0.0041(0.0046) Grad: 0.0717  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 2m 56s (remain 5m 42s) Loss: 0.0131(0.0046) Grad: 0.1286  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 3m 5s (remain 5m 33s) Loss: 0.0046(0.0046) Grad: 0.0602  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 3m 13s (remain 5m 25s) Loss: 0.0094(0.0046) Grad: 0.2354  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.0009(0.0046) Grad: 0.0227  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0028(0.0046) Grad: 0.0415  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.0071(0.0046) Grad: 0.0823  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 3m 48s (remain 4m 49s) Loss: 0.0220(0.0046) Grad: 0.2260  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 3m 57s (remain 4m 40s) Loss: 0.0014(0.0046) Grad: 0.0191  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 4m 6s (remain 4m 31s) Loss: 0.0171(0.0046) Grad: 0.2655  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0099(0.0047) Grad: 0.0790  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 4m 23s (remain 4m 14s) Loss: 0.0023(0.0047) Grad: 0.0305  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 4m 32s (remain 4m 5s) Loss: 0.0092(0.0047) Grad: 0.0680  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 4m 41s (remain 3m 56s) Loss: 0.0005(0.0047) Grad: 0.0296  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 4m 50s (remain 3m 47s) Loss: 0.0030(0.0047) Grad: 0.0621  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 4m 59s (remain 3m 38s) Loss: 0.0028(0.0047) Grad: 0.0299  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 5m 7s (remain 3m 30s) Loss: 0.0039(0.0047) Grad: 0.0540  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 5m 16s (remain 3m 21s) Loss: 0.0015(0.0047) Grad: 0.0669  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 5m 25s (remain 3m 12s) Loss: 0.0019(0.0047) Grad: 0.0457  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 5m 34s (remain 3m 3s) Loss: 0.0099(0.0047) Grad: 0.0965  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 5m 42s (remain 2m 54s) Loss: 0.0041(0.0046) Grad: 0.0480  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 5m 51s (remain 2m 46s) Loss: 0.0058(0.0046) Grad: 0.0824  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 6m 0s (remain 2m 37s) Loss: 0.0071(0.0046) Grad: 0.1012  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 6m 9s (remain 2m 28s) Loss: 0.0005(0.0046) Grad: 0.0138  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 6m 18s (remain 2m 19s) Loss: 0.0006(0.0046) Grad: 0.0167  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 6m 26s (remain 2m 10s) Loss: 0.0019(0.0046) Grad: 0.0702  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 6m 35s (remain 2m 2s) Loss: 0.0008(0.0046) Grad: 0.0188  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 6m 44s (remain 1m 53s) Loss: 0.0062(0.0046) Grad: 0.0549  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.0041(0.0046) Grad: 0.0724  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 7m 1s (remain 1m 35s) Loss: 0.0001(0.0046) Grad: 0.0043  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 7m 10s (remain 1m 27s) Loss: 0.0001(0.0046) Grad: 0.0048  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 7m 19s (remain 1m 18s) Loss: 0.0025(0.0046) Grad: 0.0444  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 7m 28s (remain 1m 9s) Loss: 0.0009(0.0046) Grad: 0.0350  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.0054(0.0046) Grad: 0.0716  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 7m 45s (remain 0m 51s) Loss: 0.0006(0.0046) Grad: 0.0137  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 7m 54s (remain 0m 43s) Loss: 0.0002(0.0046) Grad: 0.0080  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 8m 3s (remain 0m 34s) Loss: 0.0102(0.0045) Grad: 0.1406  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 8m 12s (remain 0m 25s) Loss: 0.0006(0.0045) Grad: 0.0413  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 8m 21s (remain 0m 16s) Loss: 0.0043(0.0045) Grad: 0.0539  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 8m 29s (remain 0m 7s) Loss: 0.0023(0.0045) Grad: 0.0447  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 8m 37s (remain 0m 0s) Loss: 0.0153(0.0045) Grad: 0.1453  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 50s) Loss: 0.0038(0.0038) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 26s) Loss: 0.0015(0.0024) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0071(0.0036) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0012(0.0042) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0061(0.0045) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0032(0.0046) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0038(0.0045) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0011(0.0043) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0010(0.0042) \n","f1 score : 0.48402572215984485\n","recall score : 0.36331596690162427\n","precision score : 0.7248547844695812\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0045  avg_val_loss: 0.0042  time: 619s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0045  avg_val_loss: 0.0042  time: 619s\n","Epoch 3 - Score: 0.4840\n","INFO:__main__:Epoch 3 - Score: 0.4840\n","Epoch 3 - Save Best Score: 0.5453 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5453 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 38m 13s) Loss: 0.0008(0.0008) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 9s (remain 8m 49s) Loss: 0.0022(0.0040) Grad: 0.0605  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 18s (remain 8m 40s) Loss: 0.0004(0.0037) Grad: 0.0149  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 27s (remain 8m 24s) Loss: 0.0014(0.0038) Grad: 0.0184  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 0m 35s (remain 8m 11s) Loss: 0.0020(0.0040) Grad: 0.0361  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 0m 44s (remain 8m 1s) Loss: 0.0084(0.0041) Grad: 0.1022  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 0m 53s (remain 7m 51s) Loss: 0.0050(0.0042) Grad: 0.1136  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 2s (remain 7m 41s) Loss: 0.0013(0.0041) Grad: 0.0239  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 1m 11s (remain 7m 32s) Loss: 0.0009(0.0041) Grad: 0.0212  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 1m 19s (remain 7m 22s) Loss: 0.0065(0.0041) Grad: 0.0595  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 1m 28s (remain 7m 13s) Loss: 0.0020(0.0041) Grad: 0.0466  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 1m 37s (remain 7m 3s) Loss: 0.0007(0.0041) Grad: 0.0205  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.0011(0.0041) Grad: 0.0227  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 1m 55s (remain 6m 45s) Loss: 0.0046(0.0041) Grad: 0.0670  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.0015(0.0040) Grad: 0.0492  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0007(0.0041) Grad: 0.0217  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.0209(0.0041) Grad: 0.2891  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 2m 30s (remain 6m 9s) Loss: 0.0003(0.0040) Grad: 0.0126  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.0017(0.0040) Grad: 0.0327  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 2m 47s (remain 5m 51s) Loss: 0.0040(0.0040) Grad: 0.0461  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 2m 56s (remain 5m 42s) Loss: 0.0044(0.0040) Grad: 0.1009  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 3m 5s (remain 5m 33s) Loss: 0.0026(0.0040) Grad: 0.0337  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 3m 13s (remain 5m 25s) Loss: 0.0053(0.0040) Grad: 0.0812  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.0011(0.0041) Grad: 0.0189  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0088(0.0040) Grad: 0.0918  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.0048(0.0040) Grad: 0.0646  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 3m 49s (remain 4m 49s) Loss: 0.0059(0.0040) Grad: 0.1201  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 3m 57s (remain 4m 40s) Loss: 0.0060(0.0040) Grad: 0.1054  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 4m 6s (remain 4m 32s) Loss: 0.0006(0.0040) Grad: 0.0181  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0051(0.0040) Grad: 0.1051  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.0024(0.0040) Grad: 0.0334  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 4m 33s (remain 4m 5s) Loss: 0.0035(0.0040) Grad: 0.0881  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 4m 41s (remain 3m 56s) Loss: 0.0001(0.0040) Grad: 0.0057  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 4m 50s (remain 3m 47s) Loss: 0.0055(0.0040) Grad: 0.0767  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.0008(0.0040) Grad: 0.0441  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0051(0.0039) Grad: 0.0597  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 5m 16s (remain 3m 21s) Loss: 0.0032(0.0039) Grad: 0.0327  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 5m 25s (remain 3m 12s) Loss: 0.0032(0.0039) Grad: 0.0345  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 5m 34s (remain 3m 3s) Loss: 0.0005(0.0039) Grad: 0.0135  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.0135(0.0039) Grad: 0.1475  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 5m 51s (remain 2m 46s) Loss: 0.0006(0.0039) Grad: 0.0200  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 6m 0s (remain 2m 37s) Loss: 0.0512(0.0039) Grad: 0.8091  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 6m 9s (remain 2m 28s) Loss: 0.0042(0.0039) Grad: 0.0821  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 6m 18s (remain 2m 19s) Loss: 0.0020(0.0039) Grad: 0.0259  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 6m 27s (remain 2m 11s) Loss: 0.0152(0.0039) Grad: 0.1813  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 6m 35s (remain 2m 2s) Loss: 0.0098(0.0039) Grad: 0.1525  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 6m 44s (remain 1m 53s) Loss: 0.0008(0.0039) Grad: 0.0191  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.0195(0.0039) Grad: 0.2879  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 7m 2s (remain 1m 35s) Loss: 0.0005(0.0039) Grad: 0.0192  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.0058(0.0039) Grad: 0.0605  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 7m 19s (remain 1m 18s) Loss: 0.0003(0.0039) Grad: 0.0109  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 7m 28s (remain 1m 9s) Loss: 0.0012(0.0039) Grad: 0.0371  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.0207(0.0039) Grad: 0.2721  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 7m 46s (remain 0m 51s) Loss: 0.0017(0.0039) Grad: 0.0316  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 7m 55s (remain 0m 43s) Loss: 0.0031(0.0039) Grad: 0.0623  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 8m 3s (remain 0m 34s) Loss: 0.0004(0.0039) Grad: 0.0105  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 8m 12s (remain 0m 25s) Loss: 0.0009(0.0039) Grad: 0.0163  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 8m 21s (remain 0m 16s) Loss: 0.0025(0.0039) Grad: 0.0405  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 8m 30s (remain 0m 7s) Loss: 0.0003(0.0039) Grad: 0.0127  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 8m 38s (remain 0m 0s) Loss: 0.0018(0.0039) Grad: 0.0392  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 5m 9s) Loss: 0.0035(0.0035) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 26s) Loss: 0.0013(0.0024) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0064(0.0035) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0010(0.0041) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0066(0.0044) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0031(0.0045) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0039(0.0044) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0008(0.0042) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0010(0.0041) \n","f1 score : 0.495990376904571\n","recall score : 0.37909898866074165\n","precision score : 0.7171014492753623\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0039  avg_val_loss: 0.0041  time: 620s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0039  avg_val_loss: 0.0041  time: 620s\n","Epoch 4 - Score: 0.4960\n","INFO:__main__:Epoch 4 - Score: 0.4960\n","Epoch 4 - Save Best Score: 0.5515 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.5515 Model\n","========== fold: 1 result ==========\n","INFO:__main__:========== fold: 1 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.495990376904571\n","recall score : 0.37909898866074165\n","precision score : 0.7171014492753623\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.4960\n","INFO:__main__:Score: 0.4960\n","F1 BEST Score: 0.5515\n","INFO:__main__:F1 BEST Score: 0.5515\n","========== fold: 2 training ==========\n","INFO:__main__:========== fold: 2 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 0s (remain 42m 36s) Loss: 0.0515(0.0515) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 9s (remain 9m 9s) Loss: 0.0091(0.0161) Grad: 0.0737  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 18s (remain 8m 40s) Loss: 0.0022(0.0140) Grad: 0.0425  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 27s (remain 8m 24s) Loss: 0.0335(0.0126) Grad: 0.4652  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 0m 35s (remain 8m 12s) Loss: 0.0075(0.0121) Grad: 0.0211  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 0m 44s (remain 8m 1s) Loss: 0.0014(0.0114) Grad: 0.0742  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 0m 53s (remain 7m 50s) Loss: 0.0040(0.0115) Grad: 0.1045  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 2s (remain 7m 41s) Loss: 0.0009(0.0113) Grad: 0.0355  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 1m 11s (remain 7m 32s) Loss: 0.0122(0.0109) Grad: 0.1440  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 1m 19s (remain 7m 22s) Loss: 0.0159(0.0107) Grad: 0.2224  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.0042(0.0105) Grad: 0.0736  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 1m 37s (remain 7m 3s) Loss: 0.0146(0.0103) Grad: 0.1842  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.0023(0.0102) Grad: 0.0833  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 1m 55s (remain 6m 46s) Loss: 0.0051(0.0102) Grad: 0.0815  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 2m 3s (remain 6m 37s) Loss: 0.0027(0.0101) Grad: 0.1799  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 2m 12s (remain 6m 28s) Loss: 0.0040(0.0101) Grad: 0.0576  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 2m 21s (remain 6m 19s) Loss: 0.0210(0.0100) Grad: 0.2604  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 2m 30s (remain 6m 10s) Loss: 0.0075(0.0100) Grad: 0.0440  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 2m 39s (remain 6m 1s) Loss: 0.0062(0.0099) Grad: 0.0640  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 2m 47s (remain 5m 52s) Loss: 0.0324(0.0098) Grad: 0.3493  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 2m 56s (remain 5m 43s) Loss: 0.0237(0.0098) Grad: 0.1204  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 3m 5s (remain 5m 34s) Loss: 0.0020(0.0098) Grad: 0.0588  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 3m 14s (remain 5m 25s) Loss: 0.0032(0.0097) Grad: 0.1070  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.0032(0.0096) Grad: 0.0933  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0040(0.0095) Grad: 0.0686  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 3m 40s (remain 4m 59s) Loss: 0.0054(0.0094) Grad: 0.0510  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.0002(0.0094) Grad: 0.0173  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.0031(0.0093) Grad: 0.0245  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 4m 7s (remain 4m 32s) Loss: 0.0050(0.0093) Grad: 0.1131  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0154(0.0092) Grad: 0.1494  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.0097(0.0092) Grad: 0.0988  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 4m 33s (remain 4m 6s) Loss: 0.0033(0.0092) Grad: 0.0829  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0402(0.0094) Grad: 0.3435  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0223(0.0096) Grad: 0.0595  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.0062(0.0097) Grad: 0.0747  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0105(0.0099) Grad: 0.0624  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 5m 17s (remain 3m 21s) Loss: 0.0301(0.0100) Grad: 0.1338  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 5m 26s (remain 3m 13s) Loss: 0.0104(0.0101) Grad: 0.0606  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0103(0.0103) Grad: 0.0390  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 5m 44s (remain 2m 55s) Loss: 0.0223(0.0104) Grad: 0.0325  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.0159(0.0105) Grad: 0.0497  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 6m 1s (remain 2m 37s) Loss: 0.0222(0.0106) Grad: 0.0064  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 6m 10s (remain 2m 29s) Loss: 0.0017(0.0107) Grad: 0.0762  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.0406(0.0108) Grad: 0.3501  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.0224(0.0109) Grad: 0.0413  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.0063(0.0110) Grad: 0.0768  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 6m 45s (remain 1m 53s) Loss: 0.0223(0.0110) Grad: 0.0601  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 6m 54s (remain 1m 44s) Loss: 0.0158(0.0111) Grad: 0.0173  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 7m 3s (remain 1m 36s) Loss: 0.0158(0.0111) Grad: 0.0183  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 7m 12s (remain 1m 27s) Loss: 0.0108(0.0112) Grad: 0.0955  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 7m 21s (remain 1m 18s) Loss: 0.0159(0.0114) Grad: 0.0374  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 7m 30s (remain 1m 9s) Loss: 0.0224(0.0115) Grad: 0.0538  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 7m 39s (remain 1m 0s) Loss: 0.0157(0.0115) Grad: 0.0201  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 7m 47s (remain 0m 52s) Loss: 0.0159(0.0116) Grad: 0.0434  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 7m 56s (remain 0m 43s) Loss: 0.0116(0.0117) Grad: 0.1546  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 8m 5s (remain 0m 34s) Loss: 0.0110(0.0118) Grad: 0.1097  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 8m 14s (remain 0m 25s) Loss: 0.0033(0.0119) Grad: 0.0728  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 8m 23s (remain 0m 16s) Loss: 0.0105(0.0120) Grad: 0.0651  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 8m 32s (remain 0m 7s) Loss: 0.0299(0.0121) Grad: 0.1272  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0067(0.0121) Grad: 0.1083  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 47s) Loss: 0.0067(0.0067) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 26s) Loss: 0.0159(0.0089) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0131(0.0134) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0260(0.0150) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0107(0.0153) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0067(0.0156) \n","EVAL: [600/737] Elapsed 1m 21s (remain 0m 18s) Loss: 0.0027(0.0155) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0067(0.0147) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0055(0.0144) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.0121  avg_val_loss: 0.0144  time: 622s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.0121  avg_val_loss: 0.0144  time: 622s\n","Epoch 1 - Score: 0.0000\n","INFO:__main__:Epoch 1 - Score: 0.0000\n","Epoch 1 - Save Best Score: 0.0000 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.0000 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 37m 50s) Loss: 0.0019(0.0019) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 9s (remain 8m 53s) Loss: 0.0159(0.0152) Grad: 0.0362  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 18s (remain 8m 34s) Loss: 0.0104(0.0151) Grad: 0.0509  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 27s (remain 8m 24s) Loss: 0.0017(0.0147) Grad: 0.0763  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 0m 35s (remain 8m 12s) Loss: 0.0066(0.0148) Grad: 0.0957  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 0m 44s (remain 8m 0s) Loss: 0.0224(0.0148) Grad: 0.0560  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 0m 53s (remain 7m 50s) Loss: 0.0106(0.0149) Grad: 0.0746  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 2s (remain 7m 41s) Loss: 0.0159(0.0150) Grad: 0.0389  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 1m 11s (remain 7m 31s) Loss: 0.0018(0.0152) Grad: 0.0816  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 1m 19s (remain 7m 21s) Loss: 0.0223(0.0153) Grad: 0.0436  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.0163(0.0156) Grad: 0.1009  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 1m 37s (remain 7m 3s) Loss: 0.0037(0.0155) Grad: 0.0978  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.0067(0.0157) Grad: 0.1056  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 1m 54s (remain 6m 45s) Loss: 0.0107(0.0157) Grad: 0.0862  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.0066(0.0158) Grad: 0.0983  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0020(0.0158) Grad: 0.0949  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.0033(0.0156) Grad: 0.0743  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 2m 29s (remain 6m 9s) Loss: 0.0222(0.0156) Grad: 0.0155  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.0038(0.0156) Grad: 0.1027  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 2m 47s (remain 5m 51s) Loss: 0.0038(0.0156) Grad: 0.1042  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 2m 56s (remain 5m 43s) Loss: 0.0067(0.0156) Grad: 0.1055  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 3m 5s (remain 5m 34s) Loss: 0.0159(0.0156) Grad: 0.0254  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 3m 14s (remain 5m 25s) Loss: 0.0159(0.0157) Grad: 0.0403  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 3m 23s (remain 5m 16s) Loss: 0.0161(0.0157) Grad: 0.0611  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0036(0.0157) Grad: 0.0917  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.0036(0.0157) Grad: 0.0903  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.0305(0.0157) Grad: 0.1840  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.0035(0.0156) Grad: 0.0866  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 4m 7s (remain 4m 32s) Loss: 0.0226(0.0156) Grad: 0.0672  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0069(0.0156) Grad: 0.1170  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.0305(0.0156) Grad: 0.1761  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 4m 33s (remain 4m 5s) Loss: 0.0106(0.0156) Grad: 0.0739  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0062(0.0155) Grad: 0.0668  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 4m 50s (remain 3m 48s) Loss: 0.0518(0.0155) Grad: 0.5455  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.0037(0.0155) Grad: 0.0941  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0159(0.0155) Grad: 0.0472  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 5m 17s (remain 3m 21s) Loss: 0.0158(0.0155) Grad: 0.0260  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 5m 25s (remain 3m 12s) Loss: 0.0224(0.0155) Grad: 0.0559  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 5m 34s (remain 3m 4s) Loss: 0.0016(0.0155) Grad: 0.0678  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.0018(0.0155) Grad: 0.0813  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.0307(0.0155) Grad: 0.2025  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 6m 1s (remain 2m 37s) Loss: 0.0223(0.0155) Grad: 0.0386  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 6m 10s (remain 2m 28s) Loss: 0.0105(0.0155) Grad: 0.0753  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 6m 18s (remain 2m 20s) Loss: 0.0017(0.0155) Grad: 0.0723  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 6m 27s (remain 2m 11s) Loss: 0.0222(0.0155) Grad: 0.0207  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.0036(0.0155) Grad: 0.0905  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 6m 45s (remain 1m 53s) Loss: 0.0398(0.0155) Grad: 0.3147  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.0107(0.0155) Grad: 0.0821  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 7m 2s (remain 1m 35s) Loss: 0.0106(0.0155) Grad: 0.0834  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.0036(0.0154) Grad: 0.0916  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.0104(0.0154) Grad: 0.0579  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 7m 29s (remain 1m 9s) Loss: 0.0307(0.0154) Grad: 0.1880  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.0067(0.0154) Grad: 0.1056  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 7m 46s (remain 0m 51s) Loss: 0.0224(0.0154) Grad: 0.0361  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 7m 55s (remain 0m 43s) Loss: 0.0159(0.0154) Grad: 0.0329  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 8m 4s (remain 0m 34s) Loss: 0.0158(0.0154) Grad: 0.0214  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 8m 13s (remain 0m 25s) Loss: 0.0108(0.0154) Grad: 0.0945  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 8m 22s (remain 0m 16s) Loss: 0.0105(0.0154) Grad: 0.0628  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 8m 30s (remain 0m 7s) Loss: 0.0157(0.0153) Grad: 0.0052  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 8m 38s (remain 0m 0s) Loss: 0.0061(0.0153) Grad: 0.0674  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 37s) Loss: 0.0062(0.0062) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 26s) Loss: 0.0158(0.0085) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0129(0.0133) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0268(0.0151) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0103(0.0154) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0062(0.0157) \n","EVAL: [600/737] Elapsed 1m 21s (remain 0m 18s) Loss: 0.0022(0.0156) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0062(0.0147) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0049(0.0143) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.0153  avg_val_loss: 0.0143  time: 621s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.0153  avg_val_loss: 0.0143  time: 621s\n","Epoch 2 - Score: 0.0000\n","INFO:__main__:Epoch 2 - Score: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 37m 45s) Loss: 0.0227(0.0227) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 9s (remain 8m 45s) Loss: 0.0034(0.0139) Grad: 0.0826  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 18s (remain 8m 30s) Loss: 0.0065(0.0140) Grad: 0.0927  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 26s (remain 8m 19s) Loss: 0.0223(0.0139) Grad: 0.0549  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 0m 35s (remain 8m 8s) Loss: 0.0222(0.0151) Grad: 0.0241  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 0m 44s (remain 7m 59s) Loss: 0.0158(0.0154) Grad: 0.0294  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 0m 53s (remain 7m 48s) Loss: 0.0298(0.0156) Grad: 0.1182  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 2s (remain 7m 40s) Loss: 0.0038(0.0157) Grad: 0.1018  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 1m 10s (remain 7m 31s) Loss: 0.0066(0.0157) Grad: 0.0986  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 1m 19s (remain 7m 21s) Loss: 0.0038(0.0156) Grad: 0.1004  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 1m 28s (remain 7m 13s) Loss: 0.0107(0.0156) Grad: 0.0864  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 1m 37s (remain 7m 4s) Loss: 0.0038(0.0157) Grad: 0.1046  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.0307(0.0155) Grad: 0.2012  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 1m 55s (remain 6m 45s) Loss: 0.0307(0.0153) Grad: 0.2058  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.0158(0.0153) Grad: 0.0294  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0158(0.0154) Grad: 0.0242  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.0104(0.0153) Grad: 0.0637  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 2m 30s (remain 6m 10s) Loss: 0.0159(0.0154) Grad: 0.0449  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 2m 39s (remain 6m 1s) Loss: 0.0017(0.0153) Grad: 0.0742  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 2m 47s (remain 5m 52s) Loss: 0.0104(0.0153) Grad: 0.0631  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 2m 56s (remain 5m 43s) Loss: 0.0067(0.0154) Grad: 0.1080  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 3m 5s (remain 5m 34s) Loss: 0.0158(0.0153) Grad: 0.0181  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 3m 14s (remain 5m 25s) Loss: 0.0064(0.0153) Grad: 0.0861  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 3m 23s (remain 5m 16s) Loss: 0.0224(0.0153) Grad: 0.0358  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 3m 31s (remain 5m 8s) Loss: 0.0224(0.0153) Grad: 0.0580  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 3m 40s (remain 4m 59s) Loss: 0.0226(0.0152) Grad: 0.0882  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.0158(0.0152) Grad: 0.0187  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.0107(0.0153) Grad: 0.0860  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 4m 7s (remain 4m 32s) Loss: 0.0223(0.0153) Grad: 0.0473  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 4m 16s (remain 4m 24s) Loss: 0.0036(0.0153) Grad: 0.0916  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 4m 25s (remain 4m 15s) Loss: 0.0063(0.0152) Grad: 0.0819  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 4m 33s (remain 4m 6s) Loss: 0.0107(0.0153) Grad: 0.0860  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0066(0.0152) Grad: 0.0954  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0223(0.0152) Grad: 0.0677  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 5m 0s (remain 3m 39s) Loss: 0.0396(0.0152) Grad: 0.3085  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 5m 9s (remain 3m 31s) Loss: 0.0158(0.0153) Grad: 0.0340  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 5m 17s (remain 3m 22s) Loss: 0.0504(0.0153) Grad: 0.4776  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 5m 26s (remain 3m 13s) Loss: 0.0106(0.0153) Grad: 0.0829  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0037(0.0153) Grad: 0.0979  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 5m 44s (remain 2m 55s) Loss: 0.0106(0.0153) Grad: 0.0791  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 5m 53s (remain 2m 46s) Loss: 0.0037(0.0153) Grad: 0.0986  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 6m 2s (remain 2m 38s) Loss: 0.0106(0.0153) Grad: 0.0810  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 6m 10s (remain 2m 29s) Loss: 0.0158(0.0154) Grad: 0.0340  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.0299(0.0154) Grad: 0.1192  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.0223(0.0154) Grad: 0.0341  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 6m 37s (remain 2m 2s) Loss: 0.0304(0.0154) Grad: 0.1649  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 6m 46s (remain 1m 53s) Loss: 0.0035(0.0154) Grad: 0.0860  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 6m 55s (remain 1m 45s) Loss: 0.0034(0.0153) Grad: 0.0818  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 7m 3s (remain 1m 36s) Loss: 0.0305(0.0153) Grad: 0.1845  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 7m 12s (remain 1m 27s) Loss: 0.0305(0.0153) Grad: 0.1838  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 7m 21s (remain 1m 18s) Loss: 0.0038(0.0153) Grad: 0.1019  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 7m 30s (remain 1m 9s) Loss: 0.0159(0.0153) Grad: 0.0388  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 7m 39s (remain 1m 0s) Loss: 0.0066(0.0153) Grad: 0.0982  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 7m 48s (remain 0m 52s) Loss: 0.0063(0.0153) Grad: 0.0835  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 7m 56s (remain 0m 43s) Loss: 0.0302(0.0153) Grad: 0.1630  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 8m 5s (remain 0m 34s) Loss: 0.0106(0.0153) Grad: 0.0802  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 8m 14s (remain 0m 25s) Loss: 0.0067(0.0153) Grad: 0.1044  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 8m 23s (remain 0m 16s) Loss: 0.0301(0.0153) Grad: 0.1464  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 8m 32s (remain 0m 7s) Loss: 0.0224(0.0153) Grad: 0.0410  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0065(0.0153) Grad: 0.0910  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 50s) Loss: 0.0065(0.0065) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 26s) Loss: 0.0158(0.0087) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0130(0.0133) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0262(0.0150) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0105(0.0153) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0065(0.0156) \n","EVAL: [600/737] Elapsed 1m 21s (remain 0m 18s) Loss: 0.0025(0.0155) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0065(0.0147) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0052(0.0143) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0153  avg_val_loss: 0.0143  time: 622s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0153  avg_val_loss: 0.0143  time: 622s\n","Epoch 3 - Score: 0.0000\n","INFO:__main__:Epoch 3 - Score: 0.0000\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 38m 24s) Loss: 0.0065(0.0065) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 9s (remain 8m 49s) Loss: 0.0106(0.0147) Grad: 0.0706  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 18s (remain 8m 30s) Loss: 0.0224(0.0149) Grad: 0.0562  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 26s (remain 8m 18s) Loss: 0.0158(0.0151) Grad: 0.0278  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 0m 35s (remain 8m 7s) Loss: 0.0158(0.0149) Grad: 0.0234  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 0m 44s (remain 7m 57s) Loss: 0.0158(0.0150) Grad: 0.0263  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 0m 53s (remain 7m 48s) Loss: 0.0036(0.0149) Grad: 0.0906  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 2s (remain 7m 39s) Loss: 0.0106(0.0150) Grad: 0.0769  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 1m 10s (remain 7m 30s) Loss: 0.0304(0.0148) Grad: 0.1649  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 1m 19s (remain 7m 21s) Loss: 0.0224(0.0147) Grad: 0.0659  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.0064(0.0146) Grad: 0.0851  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 1m 37s (remain 7m 3s) Loss: 0.0064(0.0146) Grad: 0.0853  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.0306(0.0147) Grad: 0.1770  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 1m 54s (remain 6m 45s) Loss: 0.0106(0.0147) Grad: 0.0706  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.0065(0.0146) Grad: 0.0903  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0224(0.0146) Grad: 0.0629  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.0158(0.0147) Grad: 0.0191  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 2m 30s (remain 6m 9s) Loss: 0.0105(0.0146) Grad: 0.0649  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.0159(0.0146) Grad: 0.0175  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 2m 47s (remain 5m 51s) Loss: 0.0064(0.0146) Grad: 0.0891  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 2m 56s (remain 5m 42s) Loss: 0.0931(0.0146) Grad: 1.2781  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 3m 5s (remain 5m 33s) Loss: 0.0224(0.0147) Grad: 0.0538  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 3m 13s (remain 5m 24s) Loss: 0.0400(0.0147) Grad: 0.3173  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.0223(0.0147) Grad: 0.0548  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0036(0.0147) Grad: 0.0921  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.0158(0.0148) Grad: 0.0263  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 3m 49s (remain 4m 49s) Loss: 0.0106(0.0149) Grad: 0.0783  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 3m 57s (remain 4m 40s) Loss: 0.0106(0.0149) Grad: 0.0783  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 4m 6s (remain 4m 32s) Loss: 0.0158(0.0149) Grad: 0.0302  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0159(0.0149) Grad: 0.0287  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.0223(0.0150) Grad: 0.0477  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 4m 33s (remain 4m 5s) Loss: 0.0066(0.0150) Grad: 0.0977  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0066(0.0151) Grad: 0.0999  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 4m 50s (remain 3m 48s) Loss: 0.0222(0.0151) Grad: 0.0457  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.0224(0.0151) Grad: 0.0452  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0158(0.0151) Grad: 0.0302  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 5m 17s (remain 3m 21s) Loss: 0.0037(0.0151) Grad: 0.0958  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 5m 26s (remain 3m 13s) Loss: 0.0106(0.0151) Grad: 0.0776  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0066(0.0152) Grad: 0.0986  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.0066(0.0152) Grad: 0.0986  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.0007(0.0152) Grad: 0.0512  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 6m 1s (remain 2m 37s) Loss: 0.0067(0.0152) Grad: 0.0998  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 6m 10s (remain 2m 28s) Loss: 0.0106(0.0152) Grad: 0.0776  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.0106(0.0152) Grad: 0.0769  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.0158(0.0152) Grad: 0.0294  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.0224(0.0152) Grad: 0.0486  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 6m 45s (remain 1m 53s) Loss: 0.0037(0.0152) Grad: 0.0958  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 6m 54s (remain 1m 44s) Loss: 0.0304(0.0152) Grad: 0.1599  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 7m 3s (remain 1m 36s) Loss: 0.0106(0.0151) Grad: 0.0764  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 7m 12s (remain 1m 27s) Loss: 0.0018(0.0151) Grad: 0.0773  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.0301(0.0151) Grad: 0.1604  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 7m 29s (remain 1m 9s) Loss: 0.0157(0.0151) Grad: 0.0278  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 7m 38s (remain 1m 0s) Loss: 0.0157(0.0151) Grad: 0.0278  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 7m 47s (remain 0m 51s) Loss: 0.0503(0.0151) Grad: 0.4850  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 7m 56s (remain 0m 43s) Loss: 0.0301(0.0151) Grad: 0.1604  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 8m 5s (remain 0m 34s) Loss: 0.0223(0.0151) Grad: 0.0500  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 8m 14s (remain 0m 25s) Loss: 0.0017(0.0151) Grad: 0.0764  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 8m 22s (remain 0m 16s) Loss: 0.0036(0.0151) Grad: 0.0947  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 8m 31s (remain 0m 7s) Loss: 0.0105(0.0152) Grad: 0.0756  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0065(0.0151) Grad: 0.0964  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 38s) Loss: 0.0066(0.0066) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 25s) Loss: 0.0158(0.0087) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0130(0.0133) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0261(0.0150) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0106(0.0153) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0066(0.0156) \n","EVAL: [600/737] Elapsed 1m 21s (remain 0m 18s) Loss: 0.0026(0.0155) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0066(0.0147) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0053(0.0143) \n","f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0151  avg_val_loss: 0.0143  time: 621s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0151  avg_val_loss: 0.0143  time: 621s\n","Epoch 4 - Score: 0.0000\n","INFO:__main__:Epoch 4 - Score: 0.0000\n","========== fold: 2 result ==========\n","INFO:__main__:========== fold: 2 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.0\n","recall score : 0.0\n","precision score : 0.0\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.0000\n","INFO:__main__:Score: 0.0000\n","F1 BEST Score: 0.0000\n","INFO:__main__:F1 BEST Score: 0.0000\n","========== fold: 3 training ==========\n","INFO:__main__:========== fold: 3 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 0s (remain 41m 45s) Loss: 0.0997(0.0997) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 9s (remain 8m 49s) Loss: 0.0290(0.0189) Grad: 0.1749  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 18s (remain 8m 33s) Loss: 0.0019(0.0159) Grad: 0.0724  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 27s (remain 8m 22s) Loss: 0.0082(0.0142) Grad: 0.2382  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 0m 35s (remain 8m 11s) Loss: 0.0102(0.0134) Grad: 0.0414  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 0m 44s (remain 8m 1s) Loss: 0.0227(0.0128) Grad: 0.1028  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 0m 53s (remain 7m 52s) Loss: 0.0057(0.0124) Grad: 0.0462  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 2s (remain 7m 42s) Loss: 0.0052(0.0122) Grad: 0.0440  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 1m 11s (remain 7m 32s) Loss: 0.0056(0.0119) Grad: 0.0369  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 1m 20s (remain 7m 23s) Loss: 0.0094(0.0117) Grad: 0.0877  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 1m 28s (remain 7m 14s) Loss: 0.0158(0.0115) Grad: 0.0841  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 1m 37s (remain 7m 5s) Loss: 0.0512(0.0112) Grad: 0.7602  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 1m 46s (remain 6m 56s) Loss: 0.0030(0.0109) Grad: 0.0276  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 1m 55s (remain 6m 46s) Loss: 0.0012(0.0108) Grad: 0.0288  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 2m 4s (remain 6m 37s) Loss: 0.0046(0.0105) Grad: 0.0623  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 2m 12s (remain 6m 28s) Loss: 0.0088(0.0104) Grad: 0.0558  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 2m 21s (remain 6m 19s) Loss: 0.0021(0.0103) Grad: 0.0643  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 2m 30s (remain 6m 10s) Loss: 0.0060(0.0103) Grad: 0.0618  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 2m 39s (remain 6m 1s) Loss: 0.0080(0.0102) Grad: 0.0570  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 2m 48s (remain 5m 52s) Loss: 0.0027(0.0100) Grad: 0.0431  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 2m 56s (remain 5m 44s) Loss: 0.0022(0.0099) Grad: 0.0457  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 3m 5s (remain 5m 35s) Loss: 0.0114(0.0098) Grad: 0.1414  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 3m 14s (remain 5m 26s) Loss: 0.0007(0.0098) Grad: 0.0496  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 3m 23s (remain 5m 17s) Loss: 0.0013(0.0096) Grad: 0.0256  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.0050(0.0095) Grad: 0.0478  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 3m 41s (remain 4m 59s) Loss: 0.0058(0.0094) Grad: 0.0777  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 3m 50s (remain 4m 50s) Loss: 0.0061(0.0094) Grad: 0.0299  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 3m 58s (remain 4m 42s) Loss: 0.0108(0.0093) Grad: 0.1230  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 4m 7s (remain 4m 33s) Loss: 0.0167(0.0093) Grad: 0.0864  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 4m 16s (remain 4m 24s) Loss: 0.0028(0.0092) Grad: 0.0333  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 4m 25s (remain 4m 15s) Loss: 0.0080(0.0091) Grad: 0.0822  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 4m 34s (remain 4m 6s) Loss: 0.0026(0.0091) Grad: 0.0357  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 4m 43s (remain 3m 57s) Loss: 0.0008(0.0091) Grad: 0.0236  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0155(0.0091) Grad: 0.1710  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 5m 0s (remain 3m 40s) Loss: 0.0094(0.0090) Grad: 0.1055  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 5m 9s (remain 3m 31s) Loss: 0.0006(0.0089) Grad: 0.0118  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 5m 18s (remain 3m 22s) Loss: 0.0117(0.0089) Grad: 0.1011  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 5m 26s (remain 3m 13s) Loss: 0.0053(0.0088) Grad: 0.0600  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0021(0.0088) Grad: 0.0734  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 5m 44s (remain 2m 55s) Loss: 0.0117(0.0088) Grad: 0.0877  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 5m 53s (remain 2m 46s) Loss: 0.0004(0.0088) Grad: 0.0266  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 6m 2s (remain 2m 38s) Loss: 0.0071(0.0087) Grad: 0.0529  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 6m 11s (remain 2m 29s) Loss: 0.0008(0.0086) Grad: 0.0306  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 6m 20s (remain 2m 20s) Loss: 0.0087(0.0086) Grad: 0.0580  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.0065(0.0086) Grad: 0.0522  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 6m 37s (remain 2m 2s) Loss: 0.0004(0.0086) Grad: 0.0215  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 6m 46s (remain 1m 53s) Loss: 0.0092(0.0085) Grad: 0.0702  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 6m 55s (remain 1m 45s) Loss: 0.0086(0.0085) Grad: 0.0719  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 7m 4s (remain 1m 36s) Loss: 0.0066(0.0085) Grad: 0.0829  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 7m 12s (remain 1m 27s) Loss: 0.0109(0.0084) Grad: 0.0999  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 7m 21s (remain 1m 18s) Loss: 0.0027(0.0084) Grad: 0.0368  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 7m 30s (remain 1m 9s) Loss: 0.0049(0.0084) Grad: 0.0649  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 7m 39s (remain 1m 0s) Loss: 0.0048(0.0083) Grad: 0.1219  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 7m 48s (remain 0m 52s) Loss: 0.0076(0.0083) Grad: 0.1013  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 7m 56s (remain 0m 43s) Loss: 0.0045(0.0083) Grad: 0.0440  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 8m 5s (remain 0m 34s) Loss: 0.0020(0.0083) Grad: 0.0703  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 8m 14s (remain 0m 25s) Loss: 0.0028(0.0083) Grad: 0.0313  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 8m 23s (remain 0m 16s) Loss: 0.0026(0.0082) Grad: 0.0380  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 8m 32s (remain 0m 7s) Loss: 0.0070(0.0082) Grad: 0.0667  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 8m 40s (remain 0m 0s) Loss: 0.0025(0.0082) Grad: 0.0281  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 45s) Loss: 0.0094(0.0094) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 26s) Loss: 0.0050(0.0030) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0121(0.0050) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0062(0.0061) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0022(0.0061) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0124(0.0063) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0037(0.0062) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0026(0.0059) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0002(0.0058) \n","f1 score : 0.34443656980864634\n","recall score : 0.22341403616304015\n","precision score : 0.7515463917525773\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.0082  avg_val_loss: 0.0058  time: 622s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.0082  avg_val_loss: 0.0058  time: 622s\n","Epoch 1 - Score: 0.3444\n","INFO:__main__:Epoch 1 - Score: 0.3444\n","Epoch 1 - Save Best Score: 0.4830 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4830 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 38m 4s) Loss: 0.0020(0.0020) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 9s (remain 8m 47s) Loss: 0.0106(0.0055) Grad: 0.1489  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 18s (remain 8m 35s) Loss: 0.0018(0.0055) Grad: 0.0313  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 27s (remain 8m 22s) Loss: 0.0031(0.0058) Grad: 0.0652  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 0m 35s (remain 8m 11s) Loss: 0.0074(0.0058) Grad: 0.0596  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 0m 44s (remain 8m 0s) Loss: 0.0015(0.0057) Grad: 0.0271  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 0m 53s (remain 7m 50s) Loss: 0.0031(0.0060) Grad: 0.1071  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 2s (remain 7m 41s) Loss: 0.0061(0.0060) Grad: 0.0689  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 1m 11s (remain 7m 31s) Loss: 0.0089(0.0059) Grad: 0.1605  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 1m 20s (remain 7m 23s) Loss: 0.0004(0.0058) Grad: 0.0097  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 1m 28s (remain 7m 14s) Loss: 0.0072(0.0058) Grad: 0.1070  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 1m 37s (remain 7m 5s) Loss: 0.0080(0.0057) Grad: 0.0770  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 1m 46s (remain 6m 56s) Loss: 0.0021(0.0057) Grad: 0.0431  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 1m 55s (remain 6m 47s) Loss: 0.0058(0.0058) Grad: 0.0599  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 2m 4s (remain 6m 38s) Loss: 0.0026(0.0058) Grad: 0.0572  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 2m 13s (remain 6m 29s) Loss: 0.0009(0.0057) Grad: 0.0187  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 2m 22s (remain 6m 20s) Loss: 0.0158(0.0057) Grad: 0.1325  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 2m 30s (remain 6m 11s) Loss: 0.0016(0.0056) Grad: 0.0214  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 2m 39s (remain 6m 2s) Loss: 0.0019(0.0056) Grad: 0.0290  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 2m 48s (remain 5m 53s) Loss: 0.0009(0.0057) Grad: 0.0348  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 2m 57s (remain 5m 44s) Loss: 0.0124(0.0056) Grad: 0.2101  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 3m 5s (remain 5m 35s) Loss: 0.0083(0.0056) Grad: 0.0661  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 3m 14s (remain 5m 26s) Loss: 0.0090(0.0056) Grad: 0.0873  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 3m 23s (remain 5m 17s) Loss: 0.0092(0.0057) Grad: 0.0899  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.0020(0.0057) Grad: 0.0537  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 3m 41s (remain 5m 0s) Loss: 0.0117(0.0057) Grad: 0.1504  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 3m 50s (remain 4m 51s) Loss: 0.0057(0.0057) Grad: 0.0655  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 3m 58s (remain 4m 42s) Loss: 0.0005(0.0057) Grad: 0.0232  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 4m 7s (remain 4m 33s) Loss: 0.0137(0.0057) Grad: 0.1485  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 4m 16s (remain 4m 24s) Loss: 0.0086(0.0057) Grad: 0.1015  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 4m 25s (remain 4m 15s) Loss: 0.0007(0.0057) Grad: 0.0360  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 4m 34s (remain 4m 6s) Loss: 0.0054(0.0057) Grad: 0.0413  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 4m 43s (remain 3m 57s) Loss: 0.0020(0.0057) Grad: 0.0506  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0010(0.0057) Grad: 0.0409  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 5m 0s (remain 3m 40s) Loss: 0.0136(0.0057) Grad: 0.1567  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 5m 9s (remain 3m 31s) Loss: 0.0020(0.0057) Grad: 0.0264  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 5m 18s (remain 3m 22s) Loss: 0.0007(0.0057) Grad: 0.0141  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 5m 27s (remain 3m 13s) Loss: 0.0035(0.0057) Grad: 0.0362  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0036(0.0057) Grad: 0.0421  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 5m 44s (remain 2m 55s) Loss: 0.0034(0.0057) Grad: 0.0435  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 5m 53s (remain 2m 46s) Loss: 0.0027(0.0057) Grad: 0.0334  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 6m 2s (remain 2m 38s) Loss: 0.0051(0.0057) Grad: 0.0467  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 6m 11s (remain 2m 29s) Loss: 0.0006(0.0057) Grad: 0.0233  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.0051(0.0057) Grad: 0.0600  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.0018(0.0057) Grad: 0.0267  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 6m 37s (remain 2m 2s) Loss: 0.0069(0.0056) Grad: 0.1077  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 6m 46s (remain 1m 53s) Loss: 0.0035(0.0057) Grad: 0.0765  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 6m 55s (remain 1m 45s) Loss: 0.0032(0.0057) Grad: 0.0608  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 7m 3s (remain 1m 36s) Loss: 0.0042(0.0056) Grad: 0.0270  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 7m 12s (remain 1m 27s) Loss: 0.0175(0.0056) Grad: 0.3129  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 7m 21s (remain 1m 18s) Loss: 0.0081(0.0056) Grad: 0.0789  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 7m 30s (remain 1m 9s) Loss: 0.0015(0.0056) Grad: 0.0281  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 7m 39s (remain 1m 0s) Loss: 0.0016(0.0056) Grad: 0.0366  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 7m 48s (remain 0m 52s) Loss: 0.0022(0.0056) Grad: 0.0413  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 7m 56s (remain 0m 43s) Loss: 0.0042(0.0056) Grad: 0.0532  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 8m 5s (remain 0m 34s) Loss: 0.0336(0.0056) Grad: 0.5509  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 8m 14s (remain 0m 25s) Loss: 0.0007(0.0056) Grad: 0.0194  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 8m 23s (remain 0m 16s) Loss: 0.0023(0.0056) Grad: 0.0260  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 8m 32s (remain 0m 7s) Loss: 0.0025(0.0056) Grad: 0.0356  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 8m 40s (remain 0m 0s) Loss: 0.0021(0.0056) Grad: 0.0720  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 40s) Loss: 0.0077(0.0077) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 26s) Loss: 0.0040(0.0024) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0098(0.0039) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0035(0.0046) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0016(0.0046) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0097(0.0048) \n","EVAL: [600/737] Elapsed 1m 21s (remain 0m 18s) Loss: 0.0038(0.0049) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0027(0.0047) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0004(0.0046) \n","f1 score : 0.4699052856706385\n","recall score : 0.35350904076003675\n","precision score : 0.7005769814758579\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.0056  avg_val_loss: 0.0046  time: 623s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.0056  avg_val_loss: 0.0046  time: 623s\n","Epoch 2 - Score: 0.4699\n","INFO:__main__:Epoch 2 - Score: 0.4699\n","Epoch 2 - Save Best Score: 0.5251 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5251 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 40m 11s) Loss: 0.0015(0.0015) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 9s (remain 8m 52s) Loss: 0.0002(0.0044) Grad: 0.0127  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 18s (remain 8m 39s) Loss: 0.0046(0.0049) Grad: 0.0568  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 27s (remain 8m 25s) Loss: 0.0069(0.0050) Grad: 0.0905  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 0m 36s (remain 8m 13s) Loss: 0.0034(0.0053) Grad: 0.0555  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 0m 44s (remain 8m 3s) Loss: 0.0009(0.0052) Grad: 0.0422  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 0m 53s (remain 7m 54s) Loss: 0.0053(0.0052) Grad: 0.1025  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 2s (remain 7m 44s) Loss: 0.0077(0.0051) Grad: 0.1040  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 1m 11s (remain 7m 34s) Loss: 0.0030(0.0052) Grad: 0.0410  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 1m 20s (remain 7m 24s) Loss: 0.0002(0.0052) Grad: 0.0071  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 1m 29s (remain 7m 15s) Loss: 0.0004(0.0051) Grad: 0.0144  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 1m 37s (remain 7m 6s) Loss: 0.0019(0.0051) Grad: 0.0274  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 1m 46s (remain 6m 56s) Loss: 0.0077(0.0051) Grad: 0.0862  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 1m 55s (remain 6m 47s) Loss: 0.0014(0.0050) Grad: 0.0470  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 2m 4s (remain 6m 38s) Loss: 0.0097(0.0050) Grad: 0.1418  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 2m 13s (remain 6m 29s) Loss: 0.0013(0.0050) Grad: 0.0227  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 2m 21s (remain 6m 20s) Loss: 0.0041(0.0049) Grad: 0.0515  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 2m 30s (remain 6m 11s) Loss: 0.0092(0.0049) Grad: 0.1346  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 2m 39s (remain 6m 2s) Loss: 0.0001(0.0048) Grad: 0.0059  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 2m 48s (remain 5m 53s) Loss: 0.0024(0.0048) Grad: 0.0269  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 2m 57s (remain 5m 44s) Loss: 0.0029(0.0047) Grad: 0.0353  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 3m 6s (remain 5m 35s) Loss: 0.0007(0.0047) Grad: 0.0159  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 3m 14s (remain 5m 26s) Loss: 0.0013(0.0047) Grad: 0.0324  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 3m 23s (remain 5m 17s) Loss: 0.0010(0.0047) Grad: 0.0432  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.0009(0.0047) Grad: 0.0167  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 3m 41s (remain 4m 59s) Loss: 0.0013(0.0046) Grad: 0.0226  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 3m 50s (remain 4m 51s) Loss: 0.0008(0.0046) Grad: 0.0197  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 3m 58s (remain 4m 42s) Loss: 0.0013(0.0046) Grad: 0.0216  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 4m 7s (remain 4m 33s) Loss: 0.0052(0.0046) Grad: 0.0999  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 4m 16s (remain 4m 24s) Loss: 0.0011(0.0046) Grad: 0.0328  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 4m 25s (remain 4m 15s) Loss: 0.0134(0.0046) Grad: 0.2211  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 4m 34s (remain 4m 6s) Loss: 0.0009(0.0046) Grad: 0.0205  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0030(0.0046) Grad: 0.0840  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0008(0.0046) Grad: 0.0178  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 5m 0s (remain 3m 40s) Loss: 0.0058(0.0046) Grad: 0.1053  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 5m 9s (remain 3m 31s) Loss: 0.0042(0.0047) Grad: 0.0654  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 5m 18s (remain 3m 22s) Loss: 0.0109(0.0047) Grad: 0.1316  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 5m 26s (remain 3m 13s) Loss: 0.0170(0.0047) Grad: 0.1486  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0137(0.0047) Grad: 0.2152  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 5m 44s (remain 2m 55s) Loss: 0.0013(0.0047) Grad: 0.0383  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 5m 53s (remain 2m 46s) Loss: 0.0015(0.0047) Grad: 0.0288  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 6m 2s (remain 2m 38s) Loss: 0.0045(0.0047) Grad: 0.0402  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 6m 10s (remain 2m 29s) Loss: 0.0002(0.0047) Grad: 0.0125  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.0027(0.0047) Grad: 0.0487  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.0053(0.0047) Grad: 0.1154  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 6m 37s (remain 2m 2s) Loss: 0.0032(0.0047) Grad: 0.0532  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 6m 46s (remain 1m 53s) Loss: 0.0007(0.0046) Grad: 0.0171  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 6m 55s (remain 1m 45s) Loss: 0.0009(0.0046) Grad: 0.0151  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 7m 4s (remain 1m 36s) Loss: 0.0001(0.0046) Grad: 0.0060  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 7m 12s (remain 1m 27s) Loss: 0.0047(0.0046) Grad: 0.0475  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 7m 21s (remain 1m 18s) Loss: 0.0011(0.0046) Grad: 0.0167  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 7m 30s (remain 1m 9s) Loss: 0.0066(0.0046) Grad: 0.0791  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 7m 39s (remain 1m 0s) Loss: 0.0007(0.0046) Grad: 0.0162  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 7m 48s (remain 0m 52s) Loss: 0.0019(0.0046) Grad: 0.0318  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 7m 57s (remain 0m 43s) Loss: 0.0007(0.0046) Grad: 0.0285  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 8m 5s (remain 0m 34s) Loss: 0.0039(0.0046) Grad: 0.0697  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 8m 14s (remain 0m 25s) Loss: 0.0035(0.0046) Grad: 0.0445  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 8m 23s (remain 0m 16s) Loss: 0.0050(0.0046) Grad: 0.0650  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 8m 32s (remain 0m 7s) Loss: 0.0037(0.0046) Grad: 0.0507  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 8m 40s (remain 0m 0s) Loss: 0.0244(0.0046) Grad: 0.2255  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 46s) Loss: 0.0052(0.0052) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 26s) Loss: 0.0034(0.0022) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0092(0.0035) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0039(0.0042) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0014(0.0042) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0095(0.0044) \n","EVAL: [600/737] Elapsed 1m 21s (remain 0m 18s) Loss: 0.0033(0.0045) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0020(0.0043) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0003(0.0042) \n","f1 score : 0.47628908676744663\n","recall score : 0.35243640821330063\n","precision score : 0.7343550446998723\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0046  avg_val_loss: 0.0042  time: 622s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0046  avg_val_loss: 0.0042  time: 622s\n","Epoch 3 - Score: 0.4763\n","INFO:__main__:Epoch 3 - Score: 0.4763\n","Epoch 3 - Save Best Score: 0.5426 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5426 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 39m 34s) Loss: 0.0041(0.0041) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 9s (remain 8m 54s) Loss: 0.0116(0.0042) Grad: 0.1158  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 18s (remain 8m 43s) Loss: 0.0047(0.0041) Grad: 0.0892  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 27s (remain 8m 27s) Loss: 0.0003(0.0039) Grad: 0.0194  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 0m 36s (remain 8m 15s) Loss: 0.0040(0.0041) Grad: 0.0717  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 0m 45s (remain 8m 4s) Loss: 0.0025(0.0040) Grad: 0.0446  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 0m 53s (remain 7m 54s) Loss: 0.0004(0.0041) Grad: 0.0263  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 2s (remain 7m 43s) Loss: 0.0108(0.0041) Grad: 0.1292  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 1m 11s (remain 7m 33s) Loss: 0.0021(0.0040) Grad: 0.0520  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 1m 20s (remain 7m 23s) Loss: 0.0074(0.0039) Grad: 0.0805  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 1m 29s (remain 7m 14s) Loss: 0.0003(0.0040) Grad: 0.0168  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 1m 37s (remain 7m 5s) Loss: 0.0052(0.0040) Grad: 0.0601  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 1m 46s (remain 6m 56s) Loss: 0.0015(0.0040) Grad: 0.0533  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 1m 55s (remain 6m 47s) Loss: 0.0062(0.0039) Grad: 0.1096  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 2m 4s (remain 6m 38s) Loss: 0.0084(0.0039) Grad: 0.1217  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 2m 13s (remain 6m 29s) Loss: 0.0053(0.0040) Grad: 0.0717  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 2m 21s (remain 6m 19s) Loss: 0.0016(0.0039) Grad: 0.0234  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 2m 30s (remain 6m 11s) Loss: 0.0165(0.0039) Grad: 0.2197  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 2m 39s (remain 6m 2s) Loss: 0.0006(0.0039) Grad: 0.0289  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 2m 48s (remain 5m 53s) Loss: 0.0034(0.0039) Grad: 0.0410  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 2m 57s (remain 5m 44s) Loss: 0.0003(0.0040) Grad: 0.0245  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 3m 5s (remain 5m 35s) Loss: 0.0002(0.0040) Grad: 0.0098  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 3m 14s (remain 5m 26s) Loss: 0.0046(0.0040) Grad: 0.0696  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 3m 23s (remain 5m 17s) Loss: 0.0013(0.0040) Grad: 0.0283  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.0070(0.0040) Grad: 0.0878  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 3m 40s (remain 4m 59s) Loss: 0.0063(0.0040) Grad: 0.0970  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.0046(0.0040) Grad: 0.0763  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.0054(0.0040) Grad: 0.0861  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 4m 7s (remain 4m 33s) Loss: 0.0002(0.0040) Grad: 0.0075  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 4m 16s (remain 4m 24s) Loss: 0.0089(0.0040) Grad: 0.1575  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 4m 25s (remain 4m 15s) Loss: 0.0024(0.0040) Grad: 0.0434  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 4m 33s (remain 4m 6s) Loss: 0.0030(0.0040) Grad: 0.0375  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0034(0.0040) Grad: 0.0647  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0002(0.0040) Grad: 0.0130  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.0019(0.0040) Grad: 0.0295  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0089(0.0040) Grad: 0.1111  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 5m 17s (remain 3m 21s) Loss: 0.0087(0.0040) Grad: 0.1048  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 5m 26s (remain 3m 13s) Loss: 0.0040(0.0040) Grad: 0.0466  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0079(0.0040) Grad: 0.1058  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.0141(0.0040) Grad: 0.1707  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.0019(0.0040) Grad: 0.0453  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 6m 1s (remain 2m 37s) Loss: 0.0013(0.0040) Grad: 0.0282  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 6m 10s (remain 2m 28s) Loss: 0.0079(0.0040) Grad: 0.0880  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.0015(0.0040) Grad: 0.0298  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 6m 27s (remain 2m 11s) Loss: 0.0015(0.0040) Grad: 0.0447  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.0080(0.0040) Grad: 0.1094  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 6m 45s (remain 1m 53s) Loss: 0.0015(0.0040) Grad: 0.0524  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 6m 54s (remain 1m 44s) Loss: 0.0142(0.0040) Grad: 0.1589  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 7m 3s (remain 1m 36s) Loss: 0.0047(0.0040) Grad: 0.0460  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.0049(0.0040) Grad: 0.0733  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.0037(0.0040) Grad: 0.0455  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 7m 29s (remain 1m 9s) Loss: 0.0003(0.0040) Grad: 0.0145  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 7m 38s (remain 1m 0s) Loss: 0.0022(0.0040) Grad: 0.0570  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 7m 47s (remain 0m 52s) Loss: 0.0004(0.0040) Grad: 0.0243  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 7m 56s (remain 0m 43s) Loss: 0.0003(0.0040) Grad: 0.0136  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 8m 4s (remain 0m 34s) Loss: 0.0276(0.0040) Grad: 0.3313  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 8m 13s (remain 0m 25s) Loss: 0.0031(0.0040) Grad: 0.0518  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 8m 22s (remain 0m 16s) Loss: 0.0036(0.0040) Grad: 0.1316  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 8m 31s (remain 0m 7s) Loss: 0.0339(0.0040) Grad: 0.4146  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0013(0.0040) Grad: 0.0292  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 45s) Loss: 0.0058(0.0058) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 26s) Loss: 0.0031(0.0022) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0086(0.0035) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0042(0.0041) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0011(0.0042) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0106(0.0044) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0031(0.0044) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0019(0.0043) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0004(0.0042) \n","f1 score : 0.48880859178962166\n","recall score : 0.3731228930432118\n","precision score : 0.7084666860634274\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0040  avg_val_loss: 0.0042  time: 621s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0040  avg_val_loss: 0.0042  time: 621s\n","Epoch 4 - Score: 0.4888\n","INFO:__main__:Epoch 4 - Score: 0.4888\n","========== fold: 3 result ==========\n","INFO:__main__:========== fold: 3 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.47628908676744663\n","recall score : 0.35243640821330063\n","precision score : 0.7343550446998723\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.4763\n","INFO:__main__:Score: 0.4763\n","F1 BEST Score: 0.5426\n","INFO:__main__:F1 BEST Score: 0.5426\n","========== fold: 4 training ==========\n","INFO:__main__:========== fold: 4 training ==========\n","DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n","INFO:__main__:DebertaV2Config {\n","  \"_name_or_path\": \"microsoft/deberta-v3-base\",\n","  \"attention_dropout\": 0.0,\n","  \"attention_probs_dropout_prob\": 0.0,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout\": 0.0,\n","  \"hidden_dropout_prob\": 0.0,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-07,\n","  \"max_position_embeddings\": 512,\n","  \"max_relative_positions\": -1,\n","  \"model_type\": \"deberta-v2\",\n","  \"norm_rel_ebd\": \"layer_norm\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"output_hidden_states\": true,\n","  \"pad_token_id\": 0,\n","  \"pooler_dropout\": 0,\n","  \"pooler_hidden_act\": \"gelu\",\n","  \"pooler_hidden_size\": 768,\n","  \"pos_att_type\": [\n","    \"p2c\",\n","    \"c2p\"\n","  ],\n","  \"position_biased_input\": false,\n","  \"position_buckets\": 256,\n","  \"relative_attention\": true,\n","  \"share_att_key\": true,\n","  \"transformers_version\": \"4.32.1\",\n","  \"type_vocab_size\": 0,\n","  \"vocab_size\": 128100\n","}\n","\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [1][0/5891] Elapsed 0m 0s (remain 40m 51s) Loss: 0.2208(0.2208) Grad: nan  LR: 0.00002000  \n","Epoch: [1][100/5891] Elapsed 0m 9s (remain 8m 55s) Loss: 0.0341(0.0221) Grad: 0.4081  LR: 0.00002000  \n","Epoch: [1][200/5891] Elapsed 0m 18s (remain 8m 36s) Loss: 0.0162(0.0163) Grad: 0.3505  LR: 0.00002000  \n","Epoch: [1][300/5891] Elapsed 0m 27s (remain 8m 22s) Loss: 0.0092(0.0143) Grad: 0.0300  LR: 0.00001999  \n","Epoch: [1][400/5891] Elapsed 0m 36s (remain 8m 13s) Loss: 0.0073(0.0135) Grad: 0.0515  LR: 0.00001999  \n","Epoch: [1][500/5891] Elapsed 0m 44s (remain 8m 1s) Loss: 0.0105(0.0129) Grad: 0.0687  LR: 0.00001998  \n","Epoch: [1][600/5891] Elapsed 0m 53s (remain 7m 52s) Loss: 0.0038(0.0124) Grad: 0.0830  LR: 0.00001997  \n","Epoch: [1][700/5891] Elapsed 1m 2s (remain 7m 42s) Loss: 0.0007(0.0119) Grad: 0.0309  LR: 0.00001996  \n","Epoch: [1][800/5891] Elapsed 1m 11s (remain 7m 32s) Loss: 0.0020(0.0117) Grad: 0.0817  LR: 0.00001994  \n","Epoch: [1][900/5891] Elapsed 1m 20s (remain 7m 23s) Loss: 0.0102(0.0116) Grad: 0.0722  LR: 0.00001993  \n","Epoch: [1][1000/5891] Elapsed 1m 28s (remain 7m 14s) Loss: 0.0089(0.0114) Grad: 0.0936  LR: 0.00001991  \n","Epoch: [1][1100/5891] Elapsed 1m 37s (remain 7m 5s) Loss: 0.0024(0.0112) Grad: 0.0363  LR: 0.00001989  \n","Epoch: [1][1200/5891] Elapsed 1m 46s (remain 6m 56s) Loss: 0.0166(0.0109) Grad: 0.3472  LR: 0.00001987  \n","Epoch: [1][1300/5891] Elapsed 1m 55s (remain 6m 46s) Loss: 0.0014(0.0108) Grad: 0.0296  LR: 0.00001985  \n","Epoch: [1][1400/5891] Elapsed 2m 4s (remain 6m 37s) Loss: 0.0036(0.0107) Grad: 0.0439  LR: 0.00001983  \n","Epoch: [1][1500/5891] Elapsed 2m 12s (remain 6m 28s) Loss: 0.0048(0.0104) Grad: 0.0543  LR: 0.00001980  \n","Epoch: [1][1600/5891] Elapsed 2m 21s (remain 6m 20s) Loss: 0.0018(0.0104) Grad: 0.0410  LR: 0.00001977  \n","Epoch: [1][1700/5891] Elapsed 2m 30s (remain 6m 11s) Loss: 0.0032(0.0103) Grad: 0.0428  LR: 0.00001974  \n","Epoch: [1][1800/5891] Elapsed 2m 39s (remain 6m 2s) Loss: 0.0180(0.0102) Grad: 0.1376  LR: 0.00001971  \n","Epoch: [1][1900/5891] Elapsed 2m 48s (remain 5m 53s) Loss: 0.0035(0.0100) Grad: 0.0629  LR: 0.00001968  \n","Epoch: [1][2000/5891] Elapsed 2m 57s (remain 5m 44s) Loss: 0.0082(0.0100) Grad: 0.0517  LR: 0.00001965  \n","Epoch: [1][2100/5891] Elapsed 3m 5s (remain 5m 35s) Loss: 0.0022(0.0099) Grad: 0.0402  LR: 0.00001961  \n","Epoch: [1][2200/5891] Elapsed 3m 14s (remain 5m 26s) Loss: 0.0154(0.0098) Grad: 0.0654  LR: 0.00001957  \n","Epoch: [1][2300/5891] Elapsed 3m 23s (remain 5m 17s) Loss: 0.0097(0.0098) Grad: 0.1045  LR: 0.00001953  \n","Epoch: [1][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.0051(0.0097) Grad: 0.0670  LR: 0.00001949  \n","Epoch: [1][2500/5891] Elapsed 3m 41s (remain 4m 59s) Loss: 0.0009(0.0096) Grad: 0.0557  LR: 0.00001945  \n","Epoch: [1][2600/5891] Elapsed 3m 50s (remain 4m 50s) Loss: 0.0088(0.0096) Grad: 0.1355  LR: 0.00001940  \n","Epoch: [1][2700/5891] Elapsed 3m 58s (remain 4m 42s) Loss: 0.0051(0.0095) Grad: 0.0568  LR: 0.00001936  \n","Epoch: [1][2800/5891] Elapsed 4m 7s (remain 4m 33s) Loss: 0.0104(0.0095) Grad: 0.0684  LR: 0.00001931  \n","Epoch: [1][2900/5891] Elapsed 4m 16s (remain 4m 24s) Loss: 0.0041(0.0094) Grad: 0.0454  LR: 0.00001926  \n","Epoch: [1][3000/5891] Elapsed 4m 25s (remain 4m 15s) Loss: 0.0017(0.0094) Grad: 0.0473  LR: 0.00001921  \n","Epoch: [1][3100/5891] Elapsed 4m 34s (remain 4m 6s) Loss: 0.0113(0.0093) Grad: 0.0653  LR: 0.00001916  \n","Epoch: [1][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0014(0.0093) Grad: 0.0183  LR: 0.00001910  \n","Epoch: [1][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0021(0.0092) Grad: 0.0228  LR: 0.00001905  \n","Epoch: [1][3400/5891] Elapsed 5m 0s (remain 3m 40s) Loss: 0.0074(0.0092) Grad: 0.0782  LR: 0.00001899  \n","Epoch: [1][3500/5891] Elapsed 5m 9s (remain 3m 31s) Loss: 0.0145(0.0091) Grad: 0.1118  LR: 0.00001893  \n","Epoch: [1][3600/5891] Elapsed 5m 18s (remain 3m 22s) Loss: 0.0037(0.0091) Grad: 0.0404  LR: 0.00001887  \n","Epoch: [1][3700/5891] Elapsed 5m 26s (remain 3m 13s) Loss: 0.0185(0.0090) Grad: 0.2119  LR: 0.00001881  \n","Epoch: [1][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0290(0.0089) Grad: 0.5439  LR: 0.00001874  \n","Epoch: [1][3900/5891] Elapsed 5m 44s (remain 2m 55s) Loss: 0.0275(0.0089) Grad: 0.2626  LR: 0.00001868  \n","Epoch: [1][4000/5891] Elapsed 5m 53s (remain 2m 46s) Loss: 0.0099(0.0089) Grad: 0.1799  LR: 0.00001861  \n","Epoch: [1][4100/5891] Elapsed 6m 1s (remain 2m 38s) Loss: 0.0017(0.0089) Grad: 0.0603  LR: 0.00001854  \n","Epoch: [1][4200/5891] Elapsed 6m 10s (remain 2m 29s) Loss: 0.0031(0.0088) Grad: 0.0750  LR: 0.00001847  \n","Epoch: [1][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.0026(0.0087) Grad: 0.0208  LR: 0.00001840  \n","Epoch: [1][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.0039(0.0087) Grad: 0.0957  LR: 0.00001833  \n","Epoch: [1][4500/5891] Elapsed 6m 37s (remain 2m 2s) Loss: 0.0039(0.0086) Grad: 0.0788  LR: 0.00001825  \n","Epoch: [1][4600/5891] Elapsed 6m 45s (remain 1m 53s) Loss: 0.0020(0.0086) Grad: 0.0298  LR: 0.00001818  \n","Epoch: [1][4700/5891] Elapsed 6m 54s (remain 1m 45s) Loss: 0.0224(0.0086) Grad: 0.1285  LR: 0.00001810  \n","Epoch: [1][4800/5891] Elapsed 7m 3s (remain 1m 36s) Loss: 0.0053(0.0086) Grad: 0.0493  LR: 0.00001802  \n","Epoch: [1][4900/5891] Elapsed 7m 12s (remain 1m 27s) Loss: 0.0020(0.0085) Grad: 0.0368  LR: 0.00001794  \n","Epoch: [1][5000/5891] Elapsed 7m 21s (remain 1m 18s) Loss: 0.0008(0.0085) Grad: 0.0326  LR: 0.00001786  \n","Epoch: [1][5100/5891] Elapsed 7m 30s (remain 1m 9s) Loss: 0.0018(0.0085) Grad: 0.0383  LR: 0.00001778  \n","Epoch: [1][5200/5891] Elapsed 7m 38s (remain 1m 0s) Loss: 0.0011(0.0084) Grad: 0.0386  LR: 0.00001769  \n","Epoch: [1][5300/5891] Elapsed 7m 47s (remain 0m 52s) Loss: 0.0416(0.0084) Grad: 0.3705  LR: 0.00001760  \n","Epoch: [1][5400/5891] Elapsed 7m 56s (remain 0m 43s) Loss: 0.0089(0.0084) Grad: 0.3441  LR: 0.00001752  \n","Epoch: [1][5500/5891] Elapsed 8m 5s (remain 0m 34s) Loss: 0.0174(0.0083) Grad: 0.2817  LR: 0.00001743  \n","Epoch: [1][5600/5891] Elapsed 8m 14s (remain 0m 25s) Loss: 0.0023(0.0083) Grad: 0.0499  LR: 0.00001734  \n","Epoch: [1][5700/5891] Elapsed 8m 22s (remain 0m 16s) Loss: 0.0029(0.0083) Grad: 0.0255  LR: 0.00001725  \n","Epoch: [1][5800/5891] Elapsed 8m 31s (remain 0m 7s) Loss: 0.0037(0.0083) Grad: 0.0779  LR: 0.00001716  \n","Epoch: [1][5890/5891] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0059(0.0082) Grad: 0.0516  LR: 0.00001707  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 40s) Loss: 0.0004(0.0004) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 25s) Loss: 0.0059(0.0031) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0056(0.0051) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0099(0.0059) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0023(0.0060) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0057(0.0063) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0031(0.0061) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0030(0.0059) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0012(0.0057) \n","f1 score : 0.34465617232808615\n","recall score : 0.22310756972111553\n","precision score : 0.7571502860114404\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 1 - avg_train_loss: 0.0082  avg_val_loss: 0.0057  time: 621s\n","INFO:__main__:Epoch 1 - avg_train_loss: 0.0082  avg_val_loss: 0.0057  time: 621s\n","Epoch 1 - Score: 0.3447\n","INFO:__main__:Epoch 1 - Score: 0.3447\n","Epoch 1 - Save Best Score: 0.4835 Model\n","INFO:__main__:Epoch 1 - Save Best Score: 0.4835 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [2][0/5891] Elapsed 0m 0s (remain 39m 6s) Loss: 0.0047(0.0047) Grad: nan  LR: 0.00001707  \n","Epoch: [2][100/5891] Elapsed 0m 9s (remain 8m 48s) Loss: 0.0094(0.0063) Grad: 0.0867  LR: 0.00001698  \n","Epoch: [2][200/5891] Elapsed 0m 18s (remain 8m 36s) Loss: 0.0042(0.0067) Grad: 0.0373  LR: 0.00001688  \n","Epoch: [2][300/5891] Elapsed 0m 27s (remain 8m 21s) Loss: 0.0029(0.0062) Grad: 0.0858  LR: 0.00001678  \n","Epoch: [2][400/5891] Elapsed 0m 35s (remain 8m 11s) Loss: 0.0032(0.0060) Grad: 0.0432  LR: 0.00001668  \n","Epoch: [2][500/5891] Elapsed 0m 44s (remain 8m 2s) Loss: 0.0071(0.0062) Grad: 0.0572  LR: 0.00001658  \n","Epoch: [2][600/5891] Elapsed 0m 53s (remain 7m 51s) Loss: 0.0044(0.0061) Grad: 0.1079  LR: 0.00001648  \n","Epoch: [2][700/5891] Elapsed 1m 2s (remain 7m 41s) Loss: 0.0050(0.0062) Grad: 0.0791  LR: 0.00001638  \n","Epoch: [2][800/5891] Elapsed 1m 11s (remain 7m 31s) Loss: 0.0023(0.0063) Grad: 0.0438  LR: 0.00001628  \n","Epoch: [2][900/5891] Elapsed 1m 19s (remain 7m 21s) Loss: 0.0142(0.0062) Grad: 0.1475  LR: 0.00001617  \n","Epoch: [2][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.0059(0.0062) Grad: 0.0955  LR: 0.00001607  \n","Epoch: [2][1100/5891] Elapsed 1m 37s (remain 7m 3s) Loss: 0.0015(0.0062) Grad: 0.0407  LR: 0.00001596  \n","Epoch: [2][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.0036(0.0062) Grad: 0.0420  LR: 0.00001585  \n","Epoch: [2][1300/5891] Elapsed 1m 54s (remain 6m 45s) Loss: 0.0241(0.0062) Grad: 0.2964  LR: 0.00001574  \n","Epoch: [2][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.0398(0.0062) Grad: 0.5265  LR: 0.00001563  \n","Epoch: [2][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0010(0.0061) Grad: 0.0132  LR: 0.00001552  \n","Epoch: [2][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.0042(0.0061) Grad: 0.0900  LR: 0.00001541  \n","Epoch: [2][1700/5891] Elapsed 2m 29s (remain 6m 9s) Loss: 0.0083(0.0060) Grad: 0.0666  LR: 0.00001530  \n","Epoch: [2][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.0037(0.0060) Grad: 0.0362  LR: 0.00001519  \n","Epoch: [2][1900/5891] Elapsed 2m 47s (remain 5m 51s) Loss: 0.0042(0.0060) Grad: 0.0555  LR: 0.00001507  \n","Epoch: [2][2000/5891] Elapsed 2m 56s (remain 5m 42s) Loss: 0.0015(0.0060) Grad: 0.0190  LR: 0.00001496  \n","Epoch: [2][2100/5891] Elapsed 3m 5s (remain 5m 34s) Loss: 0.0006(0.0060) Grad: 0.0129  LR: 0.00001484  \n","Epoch: [2][2200/5891] Elapsed 3m 14s (remain 5m 25s) Loss: 0.0019(0.0059) Grad: 0.0220  LR: 0.00001472  \n","Epoch: [2][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.0031(0.0059) Grad: 0.0323  LR: 0.00001461  \n","Epoch: [2][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0027(0.0059) Grad: 0.0514  LR: 0.00001449  \n","Epoch: [2][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.0067(0.0058) Grad: 0.0766  LR: 0.00001437  \n","Epoch: [2][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.0196(0.0058) Grad: 0.2736  LR: 0.00001425  \n","Epoch: [2][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.0012(0.0058) Grad: 0.0269  LR: 0.00001413  \n","Epoch: [2][2800/5891] Elapsed 4m 6s (remain 4m 32s) Loss: 0.0019(0.0058) Grad: 0.0470  LR: 0.00001400  \n","Epoch: [2][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0010(0.0058) Grad: 0.0142  LR: 0.00001388  \n","Epoch: [2][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.0071(0.0058) Grad: 0.0624  LR: 0.00001376  \n","Epoch: [2][3100/5891] Elapsed 4m 33s (remain 4m 5s) Loss: 0.0012(0.0058) Grad: 0.0180  LR: 0.00001363  \n","Epoch: [2][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0050(0.0058) Grad: 0.0630  LR: 0.00001351  \n","Epoch: [2][3300/5891] Elapsed 4m 50s (remain 3m 48s) Loss: 0.0005(0.0058) Grad: 0.0256  LR: 0.00001338  \n","Epoch: [2][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.0045(0.0058) Grad: 0.0661  LR: 0.00001326  \n","Epoch: [2][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0023(0.0058) Grad: 0.0194  LR: 0.00001313  \n","Epoch: [2][3600/5891] Elapsed 5m 17s (remain 3m 21s) Loss: 0.0012(0.0058) Grad: 0.0399  LR: 0.00001301  \n","Epoch: [2][3700/5891] Elapsed 5m 25s (remain 3m 12s) Loss: 0.0060(0.0058) Grad: 0.1041  LR: 0.00001288  \n","Epoch: [2][3800/5891] Elapsed 5m 34s (remain 3m 3s) Loss: 0.0005(0.0058) Grad: 0.0160  LR: 0.00001275  \n","Epoch: [2][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.0074(0.0058) Grad: 0.1280  LR: 0.00001262  \n","Epoch: [2][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.0141(0.0058) Grad: 0.1798  LR: 0.00001249  \n","Epoch: [2][4100/5891] Elapsed 6m 0s (remain 2m 37s) Loss: 0.0099(0.0058) Grad: 0.1126  LR: 0.00001236  \n","Epoch: [2][4200/5891] Elapsed 6m 9s (remain 2m 28s) Loss: 0.0017(0.0057) Grad: 0.0304  LR: 0.00001223  \n","Epoch: [2][4300/5891] Elapsed 6m 18s (remain 2m 19s) Loss: 0.0146(0.0057) Grad: 0.1980  LR: 0.00001210  \n","Epoch: [2][4400/5891] Elapsed 6m 27s (remain 2m 11s) Loss: 0.0051(0.0057) Grad: 0.0896  LR: 0.00001197  \n","Epoch: [2][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.0047(0.0057) Grad: 0.0479  LR: 0.00001184  \n","Epoch: [2][4600/5891] Elapsed 6m 45s (remain 1m 53s) Loss: 0.0074(0.0057) Grad: 0.1230  LR: 0.00001171  \n","Epoch: [2][4700/5891] Elapsed 6m 54s (remain 1m 44s) Loss: 0.0007(0.0057) Grad: 0.0172  LR: 0.00001158  \n","Epoch: [2][4800/5891] Elapsed 7m 2s (remain 1m 35s) Loss: 0.0016(0.0056) Grad: 0.0301  LR: 0.00001145  \n","Epoch: [2][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.0015(0.0056) Grad: 0.0255  LR: 0.00001132  \n","Epoch: [2][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.0036(0.0056) Grad: 0.0700  LR: 0.00001118  \n","Epoch: [2][5100/5891] Elapsed 7m 29s (remain 1m 9s) Loss: 0.0015(0.0056) Grad: 0.0352  LR: 0.00001105  \n","Epoch: [2][5200/5891] Elapsed 7m 38s (remain 1m 0s) Loss: 0.0065(0.0056) Grad: 0.0546  LR: 0.00001092  \n","Epoch: [2][5300/5891] Elapsed 7m 46s (remain 0m 51s) Loss: 0.0012(0.0056) Grad: 0.0511  LR: 0.00001079  \n","Epoch: [2][5400/5891] Elapsed 7m 55s (remain 0m 43s) Loss: 0.0038(0.0056) Grad: 0.0923  LR: 0.00001065  \n","Epoch: [2][5500/5891] Elapsed 8m 4s (remain 0m 34s) Loss: 0.0150(0.0056) Grad: 0.1345  LR: 0.00001052  \n","Epoch: [2][5600/5891] Elapsed 8m 13s (remain 0m 25s) Loss: 0.0016(0.0056) Grad: 0.0285  LR: 0.00001039  \n","Epoch: [2][5700/5891] Elapsed 8m 22s (remain 0m 16s) Loss: 0.0013(0.0056) Grad: 0.0242  LR: 0.00001025  \n","Epoch: [2][5800/5891] Elapsed 8m 31s (remain 0m 7s) Loss: 0.0059(0.0056) Grad: 0.0792  LR: 0.00001012  \n","Epoch: [2][5890/5891] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0017(0.0056) Grad: 0.0444  LR: 0.00001000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 43s) Loss: 0.0004(0.0004) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 25s) Loss: 0.0048(0.0026) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0037(0.0042) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0079(0.0048) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0016(0.0050) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0043(0.0052) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0033(0.0051) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0033(0.0049) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0005(0.0048) \n","f1 score : 0.4036924462456377\n","recall score : 0.2747471651854122\n","precision score : 0.7607127704709377\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 2 - avg_train_loss: 0.0056  avg_val_loss: 0.0048  time: 621s\n","INFO:__main__:Epoch 2 - avg_train_loss: 0.0056  avg_val_loss: 0.0048  time: 621s\n","Epoch 2 - Score: 0.4037\n","INFO:__main__:Epoch 2 - Score: 0.4037\n","Epoch 2 - Save Best Score: 0.5214 Model\n","INFO:__main__:Epoch 2 - Save Best Score: 0.5214 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [3][0/5891] Elapsed 0m 0s (remain 38m 6s) Loss: 0.0013(0.0013) Grad: nan  LR: 0.00001000  \n","Epoch: [3][100/5891] Elapsed 0m 9s (remain 8m 50s) Loss: 0.0002(0.0045) Grad: 0.0043  LR: 0.00000987  \n","Epoch: [3][200/5891] Elapsed 0m 18s (remain 8m 40s) Loss: 0.0046(0.0046) Grad: 0.0545  LR: 0.00000973  \n","Epoch: [3][300/5891] Elapsed 0m 27s (remain 8m 23s) Loss: 0.0011(0.0046) Grad: 0.0200  LR: 0.00000960  \n","Epoch: [3][400/5891] Elapsed 0m 35s (remain 8m 11s) Loss: 0.0065(0.0047) Grad: 0.1210  LR: 0.00000947  \n","Epoch: [3][500/5891] Elapsed 0m 44s (remain 8m 0s) Loss: 0.0064(0.0050) Grad: 0.1123  LR: 0.00000933  \n","Epoch: [3][600/5891] Elapsed 0m 53s (remain 7m 50s) Loss: 0.0043(0.0050) Grad: 0.0526  LR: 0.00000920  \n","Epoch: [3][700/5891] Elapsed 1m 2s (remain 7m 40s) Loss: 0.0113(0.0049) Grad: 0.1507  LR: 0.00000907  \n","Epoch: [3][800/5891] Elapsed 1m 10s (remain 7m 30s) Loss: 0.0072(0.0049) Grad: 0.0878  LR: 0.00000893  \n","Epoch: [3][900/5891] Elapsed 1m 19s (remain 7m 22s) Loss: 0.0246(0.0048) Grad: 0.2759  LR: 0.00000880  \n","Epoch: [3][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.0005(0.0047) Grad: 0.0307  LR: 0.00000867  \n","Epoch: [3][1100/5891] Elapsed 1m 37s (remain 7m 4s) Loss: 0.0025(0.0048) Grad: 0.0570  LR: 0.00000854  \n","Epoch: [3][1200/5891] Elapsed 1m 46s (remain 6m 55s) Loss: 0.0016(0.0047) Grad: 0.0245  LR: 0.00000841  \n","Epoch: [3][1300/5891] Elapsed 1m 55s (remain 6m 45s) Loss: 0.0059(0.0048) Grad: 0.1751  LR: 0.00000827  \n","Epoch: [3][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.0070(0.0048) Grad: 0.0720  LR: 0.00000814  \n","Epoch: [3][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0010(0.0047) Grad: 0.0259  LR: 0.00000801  \n","Epoch: [3][1600/5891] Elapsed 2m 21s (remain 6m 19s) Loss: 0.0325(0.0047) Grad: 0.5586  LR: 0.00000788  \n","Epoch: [3][1700/5891] Elapsed 2m 30s (remain 6m 9s) Loss: 0.0051(0.0047) Grad: 0.0497  LR: 0.00000775  \n","Epoch: [3][1800/5891] Elapsed 2m 39s (remain 6m 1s) Loss: 0.0017(0.0047) Grad: 0.0276  LR: 0.00000762  \n","Epoch: [3][1900/5891] Elapsed 2m 47s (remain 5m 52s) Loss: 0.0006(0.0047) Grad: 0.0120  LR: 0.00000749  \n","Epoch: [3][2000/5891] Elapsed 2m 56s (remain 5m 43s) Loss: 0.0112(0.0047) Grad: 0.1577  LR: 0.00000736  \n","Epoch: [3][2100/5891] Elapsed 3m 5s (remain 5m 34s) Loss: 0.0011(0.0046) Grad: 0.0254  LR: 0.00000724  \n","Epoch: [3][2200/5891] Elapsed 3m 14s (remain 5m 25s) Loss: 0.0026(0.0047) Grad: 0.0639  LR: 0.00000711  \n","Epoch: [3][2300/5891] Elapsed 3m 23s (remain 5m 16s) Loss: 0.0004(0.0047) Grad: 0.0253  LR: 0.00000698  \n","Epoch: [3][2400/5891] Elapsed 3m 32s (remain 5m 8s) Loss: 0.0107(0.0047) Grad: 0.1098  LR: 0.00000685  \n","Epoch: [3][2500/5891] Elapsed 3m 40s (remain 4m 59s) Loss: 0.0087(0.0047) Grad: 0.1017  LR: 0.00000673  \n","Epoch: [3][2600/5891] Elapsed 3m 49s (remain 4m 50s) Loss: 0.0006(0.0047) Grad: 0.0161  LR: 0.00000660  \n","Epoch: [3][2700/5891] Elapsed 3m 58s (remain 4m 41s) Loss: 0.0091(0.0047) Grad: 0.1155  LR: 0.00000648  \n","Epoch: [3][2800/5891] Elapsed 4m 7s (remain 4m 32s) Loss: 0.0151(0.0047) Grad: 0.1793  LR: 0.00000635  \n","Epoch: [3][2900/5891] Elapsed 4m 16s (remain 4m 24s) Loss: 0.0054(0.0047) Grad: 0.0517  LR: 0.00000623  \n","Epoch: [3][3000/5891] Elapsed 4m 25s (remain 4m 15s) Loss: 0.0005(0.0046) Grad: 0.0303  LR: 0.00000610  \n","Epoch: [3][3100/5891] Elapsed 4m 33s (remain 4m 6s) Loss: 0.0016(0.0046) Grad: 0.0249  LR: 0.00000598  \n","Epoch: [3][3200/5891] Elapsed 4m 42s (remain 3m 57s) Loss: 0.0029(0.0046) Grad: 0.0352  LR: 0.00000586  \n","Epoch: [3][3300/5891] Elapsed 4m 51s (remain 3m 48s) Loss: 0.0022(0.0046) Grad: 0.0277  LR: 0.00000574  \n","Epoch: [3][3400/5891] Elapsed 5m 0s (remain 3m 39s) Loss: 0.0339(0.0046) Grad: 0.6138  LR: 0.00000562  \n","Epoch: [3][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0211(0.0047) Grad: 0.3340  LR: 0.00000550  \n","Epoch: [3][3600/5891] Elapsed 5m 17s (remain 3m 22s) Loss: 0.0018(0.0047) Grad: 0.0701  LR: 0.00000538  \n","Epoch: [3][3700/5891] Elapsed 5m 26s (remain 3m 13s) Loss: 0.0033(0.0047) Grad: 0.0462  LR: 0.00000526  \n","Epoch: [3][3800/5891] Elapsed 5m 35s (remain 3m 4s) Loss: 0.0035(0.0046) Grad: 0.0849  LR: 0.00000515  \n","Epoch: [3][3900/5891] Elapsed 5m 44s (remain 2m 55s) Loss: 0.0036(0.0046) Grad: 0.0402  LR: 0.00000503  \n","Epoch: [3][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.0028(0.0046) Grad: 0.0329  LR: 0.00000492  \n","Epoch: [3][4100/5891] Elapsed 6m 1s (remain 2m 37s) Loss: 0.0008(0.0046) Grad: 0.0209  LR: 0.00000480  \n","Epoch: [3][4200/5891] Elapsed 6m 10s (remain 2m 29s) Loss: 0.0038(0.0046) Grad: 0.0494  LR: 0.00000469  \n","Epoch: [3][4300/5891] Elapsed 6m 19s (remain 2m 20s) Loss: 0.0022(0.0046) Grad: 0.0323  LR: 0.00000457  \n","Epoch: [3][4400/5891] Elapsed 6m 28s (remain 2m 11s) Loss: 0.0142(0.0046) Grad: 0.1032  LR: 0.00000446  \n","Epoch: [3][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.0038(0.0046) Grad: 0.0508  LR: 0.00000435  \n","Epoch: [3][4600/5891] Elapsed 6m 45s (remain 1m 53s) Loss: 0.0165(0.0046) Grad: 0.1411  LR: 0.00000424  \n","Epoch: [3][4700/5891] Elapsed 6m 54s (remain 1m 44s) Loss: 0.0008(0.0046) Grad: 0.0384  LR: 0.00000413  \n","Epoch: [3][4800/5891] Elapsed 7m 3s (remain 1m 36s) Loss: 0.0014(0.0046) Grad: 0.0478  LR: 0.00000403  \n","Epoch: [3][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.0098(0.0046) Grad: 0.1024  LR: 0.00000392  \n","Epoch: [3][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.0044(0.0046) Grad: 0.0810  LR: 0.00000382  \n","Epoch: [3][5100/5891] Elapsed 7m 29s (remain 1m 9s) Loss: 0.0018(0.0046) Grad: 0.0516  LR: 0.00000371  \n","Epoch: [3][5200/5891] Elapsed 7m 38s (remain 1m 0s) Loss: 0.0028(0.0046) Grad: 0.0493  LR: 0.00000361  \n","Epoch: [3][5300/5891] Elapsed 7m 47s (remain 0m 52s) Loss: 0.0055(0.0046) Grad: 0.0605  LR: 0.00000351  \n","Epoch: [3][5400/5891] Elapsed 7m 56s (remain 0m 43s) Loss: 0.0090(0.0046) Grad: 0.1057  LR: 0.00000341  \n","Epoch: [3][5500/5891] Elapsed 8m 4s (remain 0m 34s) Loss: 0.0019(0.0046) Grad: 0.0285  LR: 0.00000331  \n","Epoch: [3][5600/5891] Elapsed 8m 13s (remain 0m 25s) Loss: 0.0016(0.0046) Grad: 0.0547  LR: 0.00000321  \n","Epoch: [3][5700/5891] Elapsed 8m 22s (remain 0m 16s) Loss: 0.0055(0.0046) Grad: 0.1074  LR: 0.00000311  \n","Epoch: [3][5800/5891] Elapsed 8m 31s (remain 0m 7s) Loss: 0.0018(0.0046) Grad: 0.0696  LR: 0.00000301  \n","Epoch: [3][5890/5891] Elapsed 8m 39s (remain 0m 0s) Loss: 0.0026(0.0046) Grad: 0.0340  LR: 0.00000293  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 37s) Loss: 0.0003(0.0003) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 25s) Loss: 0.0040(0.0025) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0036(0.0040) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0064(0.0045) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0017(0.0046) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0032(0.0048) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0043(0.0047) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0026(0.0045) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0003(0.0044) \n","f1 score : 0.4413298565840939\n","recall score : 0.3112166717744407\n","precision score : 0.7584017923823749\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 3 - avg_train_loss: 0.0046  avg_val_loss: 0.0044  time: 621s\n","INFO:__main__:Epoch 3 - avg_train_loss: 0.0046  avg_val_loss: 0.0044  time: 621s\n","Epoch 3 - Score: 0.4413\n","INFO:__main__:Epoch 3 - Score: 0.4413\n","Epoch 3 - Save Best Score: 0.5282 Model\n","INFO:__main__:Epoch 3 - Save Best Score: 0.5282 Model\n"]},{"output_type":"stream","name":"stdout","text":["Epoch: [4][0/5891] Elapsed 0m 0s (remain 39m 56s) Loss: 0.0011(0.0011) Grad: nan  LR: 0.00000293  \n","Epoch: [4][100/5891] Elapsed 0m 9s (remain 8m 49s) Loss: 0.0005(0.0043) Grad: 0.0184  LR: 0.00000283  \n","Epoch: [4][200/5891] Elapsed 0m 18s (remain 8m 37s) Loss: 0.0009(0.0040) Grad: 0.0178  LR: 0.00000274  \n","Epoch: [4][300/5891] Elapsed 0m 26s (remain 8m 21s) Loss: 0.0026(0.0040) Grad: 0.0238  LR: 0.00000265  \n","Epoch: [4][400/5891] Elapsed 0m 35s (remain 8m 9s) Loss: 0.0024(0.0041) Grad: 0.0495  LR: 0.00000256  \n","Epoch: [4][500/5891] Elapsed 0m 44s (remain 7m 59s) Loss: 0.0071(0.0040) Grad: 0.0656  LR: 0.00000247  \n","Epoch: [4][600/5891] Elapsed 0m 53s (remain 7m 49s) Loss: 0.0035(0.0039) Grad: 0.0520  LR: 0.00000239  \n","Epoch: [4][700/5891] Elapsed 1m 2s (remain 7m 40s) Loss: 0.0041(0.0040) Grad: 0.0740  LR: 0.00000230  \n","Epoch: [4][800/5891] Elapsed 1m 11s (remain 7m 31s) Loss: 0.0052(0.0039) Grad: 0.0703  LR: 0.00000222  \n","Epoch: [4][900/5891] Elapsed 1m 19s (remain 7m 22s) Loss: 0.0015(0.0039) Grad: 0.0211  LR: 0.00000213  \n","Epoch: [4][1000/5891] Elapsed 1m 28s (remain 7m 12s) Loss: 0.0067(0.0039) Grad: 0.0965  LR: 0.00000205  \n","Epoch: [4][1100/5891] Elapsed 1m 37s (remain 7m 3s) Loss: 0.0006(0.0039) Grad: 0.0156  LR: 0.00000197  \n","Epoch: [4][1200/5891] Elapsed 1m 46s (remain 6m 54s) Loss: 0.0038(0.0040) Grad: 0.0839  LR: 0.00000189  \n","Epoch: [4][1300/5891] Elapsed 1m 54s (remain 6m 45s) Loss: 0.0007(0.0040) Grad: 0.0222  LR: 0.00000181  \n","Epoch: [4][1400/5891] Elapsed 2m 3s (remain 6m 36s) Loss: 0.0085(0.0040) Grad: 0.0952  LR: 0.00000174  \n","Epoch: [4][1500/5891] Elapsed 2m 12s (remain 6m 27s) Loss: 0.0013(0.0041) Grad: 0.0588  LR: 0.00000166  \n","Epoch: [4][1600/5891] Elapsed 2m 21s (remain 6m 18s) Loss: 0.0031(0.0041) Grad: 0.0523  LR: 0.00000159  \n","Epoch: [4][1700/5891] Elapsed 2m 29s (remain 6m 9s) Loss: 0.0021(0.0041) Grad: 0.0263  LR: 0.00000152  \n","Epoch: [4][1800/5891] Elapsed 2m 38s (remain 6m 0s) Loss: 0.0001(0.0041) Grad: 0.0048  LR: 0.00000145  \n","Epoch: [4][1900/5891] Elapsed 2m 47s (remain 5m 51s) Loss: 0.0083(0.0041) Grad: 0.1544  LR: 0.00000138  \n","Epoch: [4][2000/5891] Elapsed 2m 56s (remain 5m 42s) Loss: 0.0025(0.0042) Grad: 0.0298  LR: 0.00000131  \n","Epoch: [4][2100/5891] Elapsed 3m 5s (remain 5m 33s) Loss: 0.0018(0.0042) Grad: 0.0582  LR: 0.00000125  \n","Epoch: [4][2200/5891] Elapsed 3m 13s (remain 5m 25s) Loss: 0.0004(0.0041) Grad: 0.0166  LR: 0.00000119  \n","Epoch: [4][2300/5891] Elapsed 3m 22s (remain 5m 16s) Loss: 0.0024(0.0041) Grad: 0.0534  LR: 0.00000112  \n","Epoch: [4][2400/5891] Elapsed 3m 31s (remain 5m 7s) Loss: 0.0005(0.0041) Grad: 0.0135  LR: 0.00000106  \n","Epoch: [4][2500/5891] Elapsed 3m 40s (remain 4m 58s) Loss: 0.0021(0.0041) Grad: 0.0330  LR: 0.00000100  \n","Epoch: [4][2600/5891] Elapsed 3m 48s (remain 4m 49s) Loss: 0.0088(0.0041) Grad: 0.1168  LR: 0.00000095  \n","Epoch: [4][2700/5891] Elapsed 3m 57s (remain 4m 40s) Loss: 0.0004(0.0040) Grad: 0.0175  LR: 0.00000089  \n","Epoch: [4][2800/5891] Elapsed 4m 6s (remain 4m 32s) Loss: 0.0011(0.0040) Grad: 0.0148  LR: 0.00000084  \n","Epoch: [4][2900/5891] Elapsed 4m 15s (remain 4m 23s) Loss: 0.0002(0.0040) Grad: 0.0095  LR: 0.00000078  \n","Epoch: [4][3000/5891] Elapsed 4m 24s (remain 4m 14s) Loss: 0.0012(0.0040) Grad: 0.0247  LR: 0.00000073  \n","Epoch: [4][3100/5891] Elapsed 4m 33s (remain 4m 5s) Loss: 0.0016(0.0040) Grad: 0.0383  LR: 0.00000068  \n","Epoch: [4][3200/5891] Elapsed 4m 41s (remain 3m 56s) Loss: 0.0035(0.0040) Grad: 0.0478  LR: 0.00000064  \n","Epoch: [4][3300/5891] Elapsed 4m 50s (remain 3m 48s) Loss: 0.0075(0.0040) Grad: 0.0786  LR: 0.00000059  \n","Epoch: [4][3400/5891] Elapsed 4m 59s (remain 3m 39s) Loss: 0.0015(0.0040) Grad: 0.0315  LR: 0.00000055  \n","Epoch: [4][3500/5891] Elapsed 5m 8s (remain 3m 30s) Loss: 0.0078(0.0040) Grad: 0.1148  LR: 0.00000050  \n","Epoch: [4][3600/5891] Elapsed 5m 16s (remain 3m 21s) Loss: 0.0014(0.0040) Grad: 0.0375  LR: 0.00000046  \n","Epoch: [4][3700/5891] Elapsed 5m 25s (remain 3m 12s) Loss: 0.0019(0.0040) Grad: 0.0313  LR: 0.00000042  \n","Epoch: [4][3800/5891] Elapsed 5m 34s (remain 3m 3s) Loss: 0.0007(0.0040) Grad: 0.0409  LR: 0.00000039  \n","Epoch: [4][3900/5891] Elapsed 5m 43s (remain 2m 55s) Loss: 0.0010(0.0040) Grad: 0.0203  LR: 0.00000035  \n","Epoch: [4][4000/5891] Elapsed 5m 52s (remain 2m 46s) Loss: 0.0035(0.0040) Grad: 0.0516  LR: 0.00000032  \n","Epoch: [4][4100/5891] Elapsed 6m 1s (remain 2m 37s) Loss: 0.0047(0.0040) Grad: 0.0642  LR: 0.00000028  \n","Epoch: [4][4200/5891] Elapsed 6m 9s (remain 2m 28s) Loss: 0.0084(0.0040) Grad: 0.1973  LR: 0.00000025  \n","Epoch: [4][4300/5891] Elapsed 6m 18s (remain 2m 19s) Loss: 0.0057(0.0040) Grad: 0.0917  LR: 0.00000022  \n","Epoch: [4][4400/5891] Elapsed 6m 27s (remain 2m 11s) Loss: 0.0013(0.0040) Grad: 0.0278  LR: 0.00000020  \n","Epoch: [4][4500/5891] Elapsed 6m 36s (remain 2m 2s) Loss: 0.0023(0.0040) Grad: 0.0324  LR: 0.00000017  \n","Epoch: [4][4600/5891] Elapsed 6m 44s (remain 1m 53s) Loss: 0.0004(0.0040) Grad: 0.0134  LR: 0.00000015  \n","Epoch: [4][4700/5891] Elapsed 6m 53s (remain 1m 44s) Loss: 0.0086(0.0039) Grad: 0.0919  LR: 0.00000013  \n","Epoch: [4][4800/5891] Elapsed 7m 2s (remain 1m 35s) Loss: 0.0047(0.0039) Grad: 0.0817  LR: 0.00000011  \n","Epoch: [4][4900/5891] Elapsed 7m 11s (remain 1m 27s) Loss: 0.0008(0.0039) Grad: 0.0139  LR: 0.00000009  \n","Epoch: [4][5000/5891] Elapsed 7m 20s (remain 1m 18s) Loss: 0.0024(0.0039) Grad: 0.0718  LR: 0.00000007  \n","Epoch: [4][5100/5891] Elapsed 7m 28s (remain 1m 9s) Loss: 0.0025(0.0040) Grad: 0.0416  LR: 0.00000006  \n","Epoch: [4][5200/5891] Elapsed 7m 37s (remain 1m 0s) Loss: 0.0065(0.0039) Grad: 0.0826  LR: 0.00000004  \n","Epoch: [4][5300/5891] Elapsed 7m 46s (remain 0m 51s) Loss: 0.0034(0.0040) Grad: 0.0822  LR: 0.00000003  \n","Epoch: [4][5400/5891] Elapsed 7m 55s (remain 0m 43s) Loss: 0.0015(0.0040) Grad: 0.0357  LR: 0.00000002  \n","Epoch: [4][5500/5891] Elapsed 8m 4s (remain 0m 34s) Loss: 0.0061(0.0040) Grad: 0.0856  LR: 0.00000001  \n","Epoch: [4][5600/5891] Elapsed 8m 13s (remain 0m 25s) Loss: 0.0095(0.0040) Grad: 0.1393  LR: 0.00000001  \n","Epoch: [4][5700/5891] Elapsed 8m 21s (remain 0m 16s) Loss: 0.0029(0.0040) Grad: 0.0508  LR: 0.00000000  \n","Epoch: [4][5800/5891] Elapsed 8m 30s (remain 0m 7s) Loss: 0.0008(0.0040) Grad: 0.0269  LR: 0.00000000  \n","Epoch: [4][5890/5891] Elapsed 8m 38s (remain 0m 0s) Loss: 0.0101(0.0040) Grad: 0.1637  LR: 0.00000000  \n","EVAL: [0/737] Elapsed 0m 0s (remain 4m 44s) Loss: 0.0003(0.0003) \n","EVAL: [100/737] Elapsed 0m 13s (remain 1m 25s) Loss: 0.0041(0.0025) \n","EVAL: [200/737] Elapsed 0m 26s (remain 1m 11s) Loss: 0.0027(0.0038) \n","EVAL: [300/737] Elapsed 0m 40s (remain 0m 58s) Loss: 0.0059(0.0043) \n","EVAL: [400/737] Elapsed 0m 53s (remain 0m 45s) Loss: 0.0017(0.0045) \n","EVAL: [500/737] Elapsed 1m 7s (remain 0m 31s) Loss: 0.0029(0.0047) \n","EVAL: [600/737] Elapsed 1m 20s (remain 0m 18s) Loss: 0.0050(0.0046) \n","EVAL: [700/737] Elapsed 1m 34s (remain 0m 4s) Loss: 0.0028(0.0044) \n","EVAL: [736/737] Elapsed 1m 39s (remain 0m 0s) Loss: 0.0003(0.0043) \n","f1 score : 0.47867444001227366\n","recall score : 0.35856573705179284\n","precision score : 0.7197785296831745\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 4 - avg_train_loss: 0.0040  avg_val_loss: 0.0043  time: 620s\n","INFO:__main__:Epoch 4 - avg_train_loss: 0.0040  avg_val_loss: 0.0043  time: 620s\n","Epoch 4 - Score: 0.4787\n","INFO:__main__:Epoch 4 - Score: 0.4787\n","Epoch 4 - Save Best Score: 0.5345 Model\n","INFO:__main__:Epoch 4 - Save Best Score: 0.5345 Model\n","========== fold: 4 result ==========\n","INFO:__main__:========== fold: 4 result ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.47867444001227366\n","recall score : 0.35856573705179284\n","precision score : 0.7197785296831745\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.4787\n","INFO:__main__:Score: 0.4787\n","F1 BEST Score: 0.5345\n","INFO:__main__:F1 BEST Score: 0.5345\n","========== CV ==========\n","INFO:__main__:========== CV ==========\n"]},{"output_type":"stream","name":"stdout","text":["f1 score : 0.4173678015606609\n","recall score : 0.2934019797125433\n","precision score : 0.7227296746433155\n"]},{"output_type":"stream","name":"stderr","text":["Score: 0.4174\n","INFO:__main__:Score: 0.4174\n","F1 BEST Score: 0.4846\n","INFO:__main__:F1 BEST Score: 0.4846\n"]}]},{"cell_type":"code","source":["from google.colab import runtime\n","runtime.unassign()"],"metadata":{"id":"OotP5Fy0pmIk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"uj-f85L1tntx"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[],"gpuType":"A100","machine_shape":"hm","authorship_tag":"ABX9TyOA/GSDFXub/xLC3QUtWRWF"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"818b9179fa9f4fb0b38288772d9d41dd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dee828389b7d48d8aad92c74abdf45e4","IPY_MODEL_93533d041a76472598296d839a0adbae","IPY_MODEL_bc09b428eb9543d0a5e696155b835dd4"],"layout":"IPY_MODEL_9c30403f2cdb41239b05ae99f5840454"}},"dee828389b7d48d8aad92c74abdf45e4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e110a57be1c040ec9029d9f5adf6515f","placeholder":"​","style":"IPY_MODEL_222e25829d22482db7054bda281e537d","value":"Downloading (…)okenizer_config.json: 100%"}},"93533d041a76472598296d839a0adbae":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7dfc386dd18545a6a89e98712d0caee3","max":52,"min":0,"orientation":"horizontal","style":"IPY_MODEL_bd5b1e9b01a543b5b0f233f65211e739","value":52}},"bc09b428eb9543d0a5e696155b835dd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_35b86a9a30054c0a850987841d91d22f","placeholder":"​","style":"IPY_MODEL_dc1fd44e5f1e47ecb1297e9efd360b51","value":" 52.0/52.0 [00:00&lt;00:00, 4.74kB/s]"}},"9c30403f2cdb41239b05ae99f5840454":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e110a57be1c040ec9029d9f5adf6515f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"222e25829d22482db7054bda281e537d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7dfc386dd18545a6a89e98712d0caee3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bd5b1e9b01a543b5b0f233f65211e739":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"35b86a9a30054c0a850987841d91d22f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc1fd44e5f1e47ecb1297e9efd360b51":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8861f834d6184fc0ab6124b3268d107c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3cb2be1cfff946e08a010f111ef963a9","IPY_MODEL_ee827dbdc0c14efc9f77faeb9b500304","IPY_MODEL_1d7d82350521422d92295e12946eda38"],"layout":"IPY_MODEL_6e8c9433f95c48b082e6b38d062f0d71"}},"3cb2be1cfff946e08a010f111ef963a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e33d2927a6a484ba8e287468ccd8f35","placeholder":"​","style":"IPY_MODEL_186a627494d04be3ae518e637b12858b","value":"Downloading (…)lve/main/config.json: 100%"}},"ee827dbdc0c14efc9f77faeb9b500304":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_54d14046e8194ae0afa0172978b79c79","max":579,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0212059ce02c4775aa4f6d4fa8a986ec","value":579}},"1d7d82350521422d92295e12946eda38":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ff13ea8f58d449728868d6095c90c1a6","placeholder":"​","style":"IPY_MODEL_22e805d89ab34890a2aa524b69e45805","value":" 579/579 [00:00&lt;00:00, 58.4kB/s]"}},"6e8c9433f95c48b082e6b38d062f0d71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e33d2927a6a484ba8e287468ccd8f35":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"186a627494d04be3ae518e637b12858b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"54d14046e8194ae0afa0172978b79c79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0212059ce02c4775aa4f6d4fa8a986ec":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ff13ea8f58d449728868d6095c90c1a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"22e805d89ab34890a2aa524b69e45805":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8f5c94de514f469783333e5599727b13":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_09647192d6d3434f8e2ae88893dcf335","IPY_MODEL_ff77f8500a884fb58f68d8233d7aec5d","IPY_MODEL_81281e39d73d492083dc199521d75344"],"layout":"IPY_MODEL_adcc792e668647ab8e03e22295e4c8cc"}},"09647192d6d3434f8e2ae88893dcf335":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_27374433b56447c782aaa28e515fb6e3","placeholder":"​","style":"IPY_MODEL_2df97483482941468b7a2b8239d81c66","value":"Downloading spm.model: 100%"}},"ff77f8500a884fb58f68d8233d7aec5d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8f0a5744a84424bbfe438c8c341a35d","max":2464616,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f5ba7c0ddc384881b7548d60da0db52c","value":2464616}},"81281e39d73d492083dc199521d75344":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f1542b28b6b14e5280c5df540eefdf62","placeholder":"​","style":"IPY_MODEL_c549d1f03c42430085fba5d9425af756","value":" 2.46M/2.46M [00:00&lt;00:00, 14.5MB/s]"}},"adcc792e668647ab8e03e22295e4c8cc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27374433b56447c782aaa28e515fb6e3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2df97483482941468b7a2b8239d81c66":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a8f0a5744a84424bbfe438c8c341a35d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5ba7c0ddc384881b7548d60da0db52c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f1542b28b6b14e5280c5df540eefdf62":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c549d1f03c42430085fba5d9425af756":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5020b2fec9f54586a8c91c4e27b6443e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_723b6eafe6364207af42679bef0a8162","IPY_MODEL_1826559c33bf4f54bf44743c547c93f6","IPY_MODEL_def7d62d62f74a1d9abebe98ca24c290"],"layout":"IPY_MODEL_86de5ad7938b49d5a9c6f2d5501ff4af"}},"723b6eafe6364207af42679bef0a8162":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_54764225c1164a38bfea9bbb19d7cda8","placeholder":"​","style":"IPY_MODEL_d9b3f6f2b61c426295b1e7c4e3e9ed15","value":"Downloading pytorch_model.bin: 100%"}},"1826559c33bf4f54bf44743c547c93f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7c3fb7c061ea43ccb9eba71dbd4354a8","max":371146213,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c041fde973454bbbb76b9f2b94e4c9ea","value":371146213}},"def7d62d62f74a1d9abebe98ca24c290":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a8e6d20db88f4da7b8067620ba7e1f26","placeholder":"​","style":"IPY_MODEL_9d3c2aeb41354c1ba0a5a0e5eed69923","value":" 371M/371M [00:06&lt;00:00, 50.6MB/s]"}},"86de5ad7938b49d5a9c6f2d5501ff4af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"54764225c1164a38bfea9bbb19d7cda8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d9b3f6f2b61c426295b1e7c4e3e9ed15":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7c3fb7c061ea43ccb9eba71dbd4354a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c041fde973454bbbb76b9f2b94e4c9ea":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a8e6d20db88f4da7b8067620ba7e1f26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9d3c2aeb41354c1ba0a5a0e5eed69923":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}